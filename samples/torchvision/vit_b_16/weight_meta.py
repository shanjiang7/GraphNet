class Program_weight_tensor_meta_L_x_:
    name = "L_x_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.500
    std = 0.288
    data = None


class Program_weight_tensor_meta_L_self_modules_conv_proj_parameters_weight_:
    name = "L_self_modules_conv_proj_parameters_weight_"
    shape = [768, 3, 16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.009
    data = None


class Program_weight_tensor_meta_L_self_modules_conv_proj_parameters_bias_:
    name = "L_self_modules_conv_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_parameters_class_token_:
    name = "L_self_parameters_class_token_"
    shape = [1, 1, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.016
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_parameters_pos_embedding_:
    name = "L_self_modules_encoder_parameters_pos_embedding_"
    shape = [1, 197, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.030
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.013
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.141
    std = 0.190
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.024
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.013
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.079
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.191
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.036
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.010
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.127
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.016
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.205
    std = 0.214
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.032
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.011
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.155
    std = 0.148
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.296
    std = 0.248
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.029
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.016
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.008
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.187
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.346
    std = 0.264
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.027
    std = 0.014
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.007
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.202
    std = 0.170
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.024
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.380
    std = 0.257
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.025
    std = 0.011
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.006
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.225
    std = 0.170
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.418
    std = 0.229
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.025
    std = 0.009
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.008
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.233
    std = 0.150
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.478
    std = 0.225
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.027
    std = 0.013
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.253
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.529
    std = 0.186
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.110
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.031
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.011
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.219
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.572
    std = 0.128
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.011
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.025
    std = 0.007
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.012
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.231
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.575
    std = 0.101
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.114
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.026
    std = 0.005
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.262
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.546
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.014
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.027
    std = 0.009
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.009
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_ln_parameters_weight_:
    name = "L_self_modules_encoder_modules_ln_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.689
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_ln_parameters_bias_:
    name = "L_self_modules_encoder_modules_ln_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_heads_modules_head_parameters_weight_:
    name = "L_self_modules_heads_modules_head_parameters_weight_"
    shape = [1000, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_heads_modules_head_parameters_bias_:
    name = "L_self_modules_heads_modules_head_parameters_bias_"
    shape = [1000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.021
    data = None
