class Program_weight_tensor_meta_L_x_:
    name = "L_x_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.501
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_conv_proj_parameters_weight_:
    name = "L_self_modules_conv_proj_parameters_weight_"
    shape = [1024, 3, 16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_conv_proj_parameters_bias_:
    name = "L_self_modules_conv_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_parameters_class_token_:
    name = "L_self_parameters_class_token_"
    shape = [1, 1, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_parameters_pos_embedding_:
    name = "L_self_modules_encoder_parameters_pos_embedding_"
    shape = [1, 197, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_12_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_13_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_14_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_15_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_16_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_17_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_18_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_19_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_20_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_21_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_22_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_1_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_1_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_2_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_ln_2_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_0_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_0_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_3_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_23_modules_mlp_modules_3_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_ln_parameters_weight_:
    name = "L_self_modules_encoder_modules_ln_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_ln_parameters_bias_:
    name = "L_self_modules_encoder_modules_ln_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_heads_modules_head_parameters_weight_:
    name = "L_self_modules_heads_modules_head_parameters_weight_"
    shape = [1000, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_heads_modules_head_parameters_bias_:
    name = "L_self_modules_heads_modules_head_parameters_bias_"
    shape = [1000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
