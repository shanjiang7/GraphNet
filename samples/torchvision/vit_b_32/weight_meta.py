class Program_weight_tensor_meta_L_x_:
    name = "L_x_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.499
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_conv_proj_parameters_weight_:
    name = "L_self_modules_conv_proj_parameters_weight_"
    shape = [768, 3, 32, 32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_conv_proj_parameters_bias_:
    name = "L_self_modules_conv_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_parameters_class_token_:
    name = "L_self_parameters_class_token_"
    shape = [1, 1, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_parameters_pos_embedding_:
    name = "L_self_modules_encoder_parameters_pos_embedding_"
    shape = [1, 50, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_0_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_1_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_2_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_3_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_4_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_5_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_6_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_7_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_8_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_9_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_10_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_1_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_self_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_ln_2_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_0_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_weight_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_bias_:
    name = "L_self_modules_encoder_modules_layers_modules_encoder_layer_11_modules_mlp_modules_3_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_ln_parameters_weight_:
    name = "L_self_modules_encoder_modules_ln_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_ln_parameters_bias_:
    name = "L_self_modules_encoder_modules_ln_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_heads_modules_head_parameters_weight_:
    name = "L_self_modules_heads_modules_head_parameters_weight_"
    shape = [1000, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_heads_modules_head_parameters_bias_:
    name = "L_self_modules_heads_modules_head_parameters_bias_"
    shape = [1000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
