import torch

from torch import device


class GraphModule(torch.nn.Module):
    def forward(
        self,
        L_inputs_: torch.Tensor,
        L_self_modules_backbone_modules_patch_embed_modules_projection_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_patch_embed_modules_projection_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_patch_embed_modules_norm_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_patch_embed_modules_norm_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_reduction_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_reduction_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_reduction_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_: torch.Tensor,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_norm3_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_backbone_modules_norm3_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_1_buffers_running_mean_: torch.Tensor,
        L_self_modules_head_modules_deconv_layers_modules_1_buffers_running_var_: torch.Tensor,
        L_self_modules_head_modules_deconv_layers_modules_1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_3_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_4_buffers_running_mean_: torch.Tensor,
        L_self_modules_head_modules_deconv_layers_modules_4_buffers_running_var_: torch.Tensor,
        L_self_modules_head_modules_deconv_layers_modules_4_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_4_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_6_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_7_buffers_running_mean_: torch.Tensor,
        L_self_modules_head_modules_deconv_layers_modules_7_buffers_running_var_: torch.Tensor,
        L_self_modules_head_modules_deconv_layers_modules_7_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_deconv_layers_modules_7_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_final_layer_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_head_modules_final_layer_parameters_bias_: torch.nn.parameter.Parameter,
    ):
        l_inputs_ = L_inputs_
        l_self_modules_backbone_modules_patch_embed_modules_projection_parameters_weight_ = L_self_modules_backbone_modules_patch_embed_modules_projection_parameters_weight_
        l_self_modules_backbone_modules_patch_embed_modules_projection_parameters_bias_ = L_self_modules_backbone_modules_patch_embed_modules_projection_parameters_bias_
        l_self_modules_backbone_modules_patch_embed_modules_norm_parameters_weight_ = (
            L_self_modules_backbone_modules_patch_embed_modules_norm_parameters_weight_
        )
        l_self_modules_backbone_modules_patch_embed_modules_norm_parameters_bias_ = (
            L_self_modules_backbone_modules_patch_embed_modules_norm_parameters_bias_
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_reduction_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_reduction_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_reduction_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_reduction_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_reduction_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_reduction_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = L_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_
        l_self_modules_backbone_modules_norm3_parameters_weight_ = (
            L_self_modules_backbone_modules_norm3_parameters_weight_
        )
        l_self_modules_backbone_modules_norm3_parameters_bias_ = (
            L_self_modules_backbone_modules_norm3_parameters_bias_
        )
        l_self_modules_head_modules_deconv_layers_modules_0_parameters_weight_ = (
            L_self_modules_head_modules_deconv_layers_modules_0_parameters_weight_
        )
        l_self_modules_head_modules_deconv_layers_modules_1_buffers_running_mean_ = (
            L_self_modules_head_modules_deconv_layers_modules_1_buffers_running_mean_
        )
        l_self_modules_head_modules_deconv_layers_modules_1_buffers_running_var_ = (
            L_self_modules_head_modules_deconv_layers_modules_1_buffers_running_var_
        )
        l_self_modules_head_modules_deconv_layers_modules_1_parameters_weight_ = (
            L_self_modules_head_modules_deconv_layers_modules_1_parameters_weight_
        )
        l_self_modules_head_modules_deconv_layers_modules_1_parameters_bias_ = (
            L_self_modules_head_modules_deconv_layers_modules_1_parameters_bias_
        )
        l_self_modules_head_modules_deconv_layers_modules_3_parameters_weight_ = (
            L_self_modules_head_modules_deconv_layers_modules_3_parameters_weight_
        )
        l_self_modules_head_modules_deconv_layers_modules_4_buffers_running_mean_ = (
            L_self_modules_head_modules_deconv_layers_modules_4_buffers_running_mean_
        )
        l_self_modules_head_modules_deconv_layers_modules_4_buffers_running_var_ = (
            L_self_modules_head_modules_deconv_layers_modules_4_buffers_running_var_
        )
        l_self_modules_head_modules_deconv_layers_modules_4_parameters_weight_ = (
            L_self_modules_head_modules_deconv_layers_modules_4_parameters_weight_
        )
        l_self_modules_head_modules_deconv_layers_modules_4_parameters_bias_ = (
            L_self_modules_head_modules_deconv_layers_modules_4_parameters_bias_
        )
        l_self_modules_head_modules_deconv_layers_modules_6_parameters_weight_ = (
            L_self_modules_head_modules_deconv_layers_modules_6_parameters_weight_
        )
        l_self_modules_head_modules_deconv_layers_modules_7_buffers_running_mean_ = (
            L_self_modules_head_modules_deconv_layers_modules_7_buffers_running_mean_
        )
        l_self_modules_head_modules_deconv_layers_modules_7_buffers_running_var_ = (
            L_self_modules_head_modules_deconv_layers_modules_7_buffers_running_var_
        )
        l_self_modules_head_modules_deconv_layers_modules_7_parameters_weight_ = (
            L_self_modules_head_modules_deconv_layers_modules_7_parameters_weight_
        )
        l_self_modules_head_modules_deconv_layers_modules_7_parameters_bias_ = (
            L_self_modules_head_modules_deconv_layers_modules_7_parameters_bias_
        )
        l_self_modules_head_modules_final_layer_parameters_weight_ = (
            L_self_modules_head_modules_final_layer_parameters_weight_
        )
        l_self_modules_head_modules_final_layer_parameters_bias_ = (
            L_self_modules_head_modules_final_layer_parameters_bias_
        )
        x = torch.conv2d(
            l_inputs_,
            l_self_modules_backbone_modules_patch_embed_modules_projection_parameters_weight_,
            l_self_modules_backbone_modules_patch_embed_modules_projection_parameters_bias_,
            (4, 4),
            (0, 0),
            (1, 1),
            1,
        )
        l_inputs_ = l_self_modules_backbone_modules_patch_embed_modules_projection_parameters_weight_ = l_self_modules_backbone_modules_patch_embed_modules_projection_parameters_bias_ = (None)
        flatten = x.flatten(2)
        x = None
        x_1 = flatten.transpose(1, 2)
        flatten = None
        x_2 = torch.nn.functional.layer_norm(
            x_1,
            (128,),
            l_self_modules_backbone_modules_patch_embed_modules_norm_parameters_weight_,
            l_self_modules_backbone_modules_patch_embed_modules_norm_parameters_bias_,
            1e-05,
        )
        x_1 = (
            l_self_modules_backbone_modules_patch_embed_modules_norm_parameters_weight_
        ) = (
            l_self_modules_backbone_modules_patch_embed_modules_norm_parameters_bias_
        ) = None
        x_3 = torch.nn.functional.dropout(x_2, 0.0, False, False)
        x_2 = None
        x_4 = torch.nn.functional.layer_norm(
            x_3,
            (128,),
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm1_parameters_bias_ = (None)
        query = x_4.view(1, 64, 48, 128)
        x_4 = None
        query_1 = torch._C._nn.pad(query, (0, 0, 0, 1, 0, 6), "constant", None)
        query = None
        x_5 = query_1.view(1, 10, 7, 7, 7, 128)
        query_1 = None
        permute = x_5.permute(0, 1, 3, 2, 4, 5)
        x_5 = None
        windows = permute.contiguous()
        permute = None
        windows_1 = windows.view(-1, 7, 7, 128)
        windows = None
        query_windows = windows_1.view(-1, 49, 128)
        windows_1 = None
        linear = torch._C._nn.linear(
            query_windows,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape = linear.reshape(70, 49, 3, 4, 32)
        linear = None
        qkv = reshape.permute(2, 0, 3, 1, 4)
        reshape = None
        q = qkv[0]
        k = qkv[1]
        v = qkv[2]
        qkv = None
        q_1 = q * 0.1767766952966369
        q = None
        transpose_1 = k.transpose(-2, -1)
        k = None
        attn = q_1 @ transpose_1
        q_1 = transpose_1 = None
        view_4 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_3 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_4
        ]
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_4
        ) = None
        relative_position_bias = getitem_3.view(49, 49, -1)
        getitem_3 = None
        permute_2 = relative_position_bias.permute(2, 0, 1)
        relative_position_bias = None
        relative_position_bias_1 = permute_2.contiguous()
        permute_2 = None
        unsqueeze = relative_position_bias_1.unsqueeze(0)
        relative_position_bias_1 = None
        attn_1 = attn + unsqueeze
        attn = unsqueeze = None
        attn_2 = torch.nn.functional.softmax(attn_1, -1, _stacklevel=5)
        attn_1 = None
        attn_3 = torch.nn.functional.dropout(attn_2, 0.0, False, False)
        attn_2 = None
        matmul_1 = attn_3 @ v
        attn_3 = v = None
        transpose_2 = matmul_1.transpose(1, 2)
        matmul_1 = None
        x_6 = transpose_2.reshape(70, 49, 128)
        transpose_2 = None
        x_7 = torch._C._nn.linear(
            x_6,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_6 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_8 = torch.nn.functional.dropout(x_7, 0.0, False, False)
        x_7 = None
        attn_windows = x_8.view(-1, 7, 7, 128)
        x_8 = None
        x_9 = attn_windows.view(1, 10, 7, 7, 7, -1)
        attn_windows = None
        permute_3 = x_9.permute(0, 1, 3, 2, 4, 5)
        x_9 = None
        contiguous_2 = permute_3.contiguous()
        permute_3 = None
        x_10 = contiguous_2.view(1, 70, 49, -1)
        contiguous_2 = None
        getitem_4 = x_10[
            (
                slice(None, None, None),
                slice(None, 64, None),
                slice(None, 48, None),
                slice(None, None, None),
            )
        ]
        x_10 = None
        x_11 = getitem_4.contiguous()
        getitem_4 = None
        x_12 = x_11.view(1, 3072, 128)
        x_11 = None
        x_13 = x_12 + x_3
        x_12 = x_3 = None
        x_14 = torch.nn.functional.layer_norm(
            x_13,
            (128,),
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_norm2_parameters_bias_ = (None)
        input_1 = torch._C._nn.linear(
            x_14,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_14 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_2 = torch._C._nn.gelu(input_1, approximate="none")
        input_1 = None
        input_3 = torch.nn.functional.dropout(input_2, 0.0, False, False)
        input_2 = None
        input_4 = torch._C._nn.linear(
            input_3,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_3 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_5 = torch.nn.functional.dropout(input_4, 0.0, False, False)
        input_4 = None
        output = x_13 + input_5
        x_13 = input_5 = None
        x_15 = torch.nn.functional.layer_norm(
            output,
            (128,),
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm1_parameters_bias_ = (None)
        query_2 = x_15.view(1, 64, 48, 128)
        x_15 = None
        query_3 = torch._C._nn.pad(query_2, (0, 0, 0, 1, 0, 6), "constant", None)
        query_2 = None
        shifted_query = torch.roll(query_3, shifts=(-3, -3), dims=(1, 2))
        query_3 = None
        img_mask = torch.zeros((1, 70, 49, 1), device=device(type="cuda", index=0))
        img_mask[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem = img_mask
        setitem = None
        img_mask[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_1 = img_mask
        setitem_1 = None
        img_mask[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_2 = img_mask
        setitem_2 = None
        img_mask[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_3 = img_mask
        setitem_3 = None
        img_mask[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_4 = img_mask
        setitem_4 = None
        img_mask[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_5 = img_mask
        setitem_5 = None
        img_mask[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_6 = img_mask
        setitem_6 = None
        img_mask[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_7 = img_mask
        setitem_7 = None
        img_mask[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_8 = img_mask
        setitem_8 = None
        x_16 = img_mask.view(1, 10, 7, 7, 7, 1)
        img_mask = None
        permute_4 = x_16.permute(0, 1, 3, 2, 4, 5)
        x_16 = None
        windows_2 = permute_4.contiguous()
        permute_4 = None
        windows_3 = windows_2.view(-1, 7, 7, 1)
        windows_2 = None
        mask_windows = windows_3.view(-1, 49)
        windows_3 = None
        unsqueeze_1 = mask_windows.unsqueeze(1)
        unsqueeze_2 = mask_windows.unsqueeze(2)
        mask_windows = None
        attn_mask = unsqueeze_1 - unsqueeze_2
        unsqueeze_1 = unsqueeze_2 = None
        ne = attn_mask != 0
        masked_fill = attn_mask.masked_fill(ne, -100.0)
        ne = None
        eq = attn_mask == 0
        attn_mask = None
        attn_mask_1 = masked_fill.masked_fill(eq, 0.0)
        masked_fill = eq = None
        x_17 = shifted_query.view(1, 10, 7, 7, 7, 128)
        shifted_query = None
        permute_5 = x_17.permute(0, 1, 3, 2, 4, 5)
        x_17 = None
        windows_4 = permute_5.contiguous()
        permute_5 = None
        windows_5 = windows_4.view(-1, 7, 7, 128)
        windows_4 = None
        query_windows_1 = windows_5.view(-1, 49, 128)
        windows_5 = None
        linear_4 = torch._C._nn.linear(
            query_windows_1,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_1 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_2 = linear_4.reshape(70, 49, 3, 4, 32)
        linear_4 = None
        qkv_1 = reshape_2.permute(2, 0, 3, 1, 4)
        reshape_2 = None
        q_2 = qkv_1[0]
        k_1 = qkv_1[1]
        v_1 = qkv_1[2]
        qkv_1 = None
        q_3 = q_2 * 0.1767766952966369
        q_2 = None
        transpose_3 = k_1.transpose(-2, -1)
        k_1 = None
        attn_4 = q_3 @ transpose_3
        q_3 = transpose_3 = None
        view_17 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_8 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_17
        ]
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_17
        ) = None
        relative_position_bias_2 = getitem_8.view(49, 49, -1)
        getitem_8 = None
        permute_7 = relative_position_bias_2.permute(2, 0, 1)
        relative_position_bias_2 = None
        relative_position_bias_3 = permute_7.contiguous()
        permute_7 = None
        unsqueeze_3 = relative_position_bias_3.unsqueeze(0)
        relative_position_bias_3 = None
        attn_5 = attn_4 + unsqueeze_3
        attn_4 = unsqueeze_3 = None
        view_19 = attn_5.view(1, 70, 4, 49, 49)
        attn_5 = None
        unsqueeze_4 = attn_mask_1.unsqueeze(1)
        attn_mask_1 = None
        unsqueeze_5 = unsqueeze_4.unsqueeze(0)
        unsqueeze_4 = None
        attn_6 = view_19 + unsqueeze_5
        view_19 = unsqueeze_5 = None
        attn_7 = attn_6.view(-1, 4, 49, 49)
        attn_6 = None
        attn_8 = torch.nn.functional.softmax(attn_7, -1, _stacklevel=5)
        attn_7 = None
        attn_9 = torch.nn.functional.dropout(attn_8, 0.0, False, False)
        attn_8 = None
        matmul_3 = attn_9 @ v_1
        attn_9 = v_1 = None
        transpose_4 = matmul_3.transpose(1, 2)
        matmul_3 = None
        x_18 = transpose_4.reshape(70, 49, 128)
        transpose_4 = None
        x_19 = torch._C._nn.linear(
            x_18,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_18 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_20 = torch.nn.functional.dropout(x_19, 0.0, False, False)
        x_19 = None
        attn_windows_1 = x_20.view(-1, 7, 7, 128)
        x_20 = None
        x_21 = attn_windows_1.view(1, 10, 7, 7, 7, -1)
        attn_windows_1 = None
        permute_8 = x_21.permute(0, 1, 3, 2, 4, 5)
        x_21 = None
        contiguous_7 = permute_8.contiguous()
        permute_8 = None
        x_22 = contiguous_7.view(1, 70, 49, -1)
        contiguous_7 = None
        x_23 = torch.roll(x_22, shifts=(3, 3), dims=(1, 2))
        x_22 = None
        getitem_9 = x_23[
            (
                slice(None, None, None),
                slice(None, 64, None),
                slice(None, 48, None),
                slice(None, None, None),
            )
        ]
        x_23 = None
        x_24 = getitem_9.contiguous()
        getitem_9 = None
        x_25 = x_24.view(1, 3072, 128)
        x_24 = None
        x_26 = x_25 + output
        x_25 = output = None
        x_27 = torch.nn.functional.layer_norm(
            x_26,
            (128,),
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_norm2_parameters_bias_ = (None)
        input_6 = torch._C._nn.linear(
            x_27,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_27 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_7 = torch._C._nn.gelu(input_6, approximate="none")
        input_6 = None
        input_8 = torch.nn.functional.dropout(input_7, 0.0, False, False)
        input_7 = None
        input_9 = torch._C._nn.linear(
            input_8,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_8 = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_10 = torch.nn.functional.dropout(input_9, 0.0, False, False)
        input_9 = None
        output_1 = x_26 + input_10
        x_26 = input_10 = None
        view_25 = output_1.view(1, 64, 48, 128)
        output_1 = None
        x_28 = view_25.permute([0, 3, 1, 2])
        view_25 = None
        x_29 = torch.nn.functional.unfold(x_28, (2, 2), (1, 1), (0, 0), (2, 2))
        x_28 = None
        x_30 = x_29.transpose(1, 2)
        x_29 = None
        x_31 = torch.nn.functional.layer_norm(
            x_30,
            (512,),
            l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_bias_,
            1e-05,
        )
        x_30 = l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_norm_parameters_bias_ = (None)
        x_32 = torch._C._nn.linear(
            x_31,
            l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_reduction_parameters_weight_,
            None,
        )
        x_31 = l_self_modules_backbone_modules_stages_modules_0_modules_downsample_modules_reduction_parameters_weight_ = (None)
        x_33 = torch.nn.functional.layer_norm(
            x_32,
            (256,),
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm1_parameters_bias_ = (None)
        query_4 = x_33.view(1, 32, 24, 256)
        x_33 = None
        query_5 = torch._C._nn.pad(query_4, (0, 0, 0, 4, 0, 3), "constant", None)
        query_4 = None
        x_34 = query_5.view(1, 5, 7, 4, 7, 256)
        query_5 = None
        permute_10 = x_34.permute(0, 1, 3, 2, 4, 5)
        x_34 = None
        windows_6 = permute_10.contiguous()
        permute_10 = None
        windows_7 = windows_6.view(-1, 7, 7, 256)
        windows_6 = None
        query_windows_2 = windows_7.view(-1, 49, 256)
        windows_7 = None
        linear_9 = torch._C._nn.linear(
            query_windows_2,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_2 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_4 = linear_9.reshape(20, 49, 3, 8, 32)
        linear_9 = None
        qkv_2 = reshape_4.permute(2, 0, 3, 1, 4)
        reshape_4 = None
        q_4 = qkv_2[0]
        k_2 = qkv_2[1]
        v_2 = qkv_2[2]
        qkv_2 = None
        q_5 = q_4 * 0.1767766952966369
        q_4 = None
        transpose_6 = k_2.transpose(-2, -1)
        k_2 = None
        attn_10 = q_5 @ transpose_6
        q_5 = transpose_6 = None
        view_30 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_13 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_30
        ]
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_30
        ) = None
        relative_position_bias_4 = getitem_13.view(49, 49, -1)
        getitem_13 = None
        permute_12 = relative_position_bias_4.permute(2, 0, 1)
        relative_position_bias_4 = None
        relative_position_bias_5 = permute_12.contiguous()
        permute_12 = None
        unsqueeze_6 = relative_position_bias_5.unsqueeze(0)
        relative_position_bias_5 = None
        attn_11 = attn_10 + unsqueeze_6
        attn_10 = unsqueeze_6 = None
        attn_12 = torch.nn.functional.softmax(attn_11, -1, _stacklevel=5)
        attn_11 = None
        attn_13 = torch.nn.functional.dropout(attn_12, 0.0, False, False)
        attn_12 = None
        matmul_5 = attn_13 @ v_2
        attn_13 = v_2 = None
        transpose_7 = matmul_5.transpose(1, 2)
        matmul_5 = None
        x_35 = transpose_7.reshape(20, 49, 256)
        transpose_7 = None
        x_36 = torch._C._nn.linear(
            x_35,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_35 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_37 = torch.nn.functional.dropout(x_36, 0.0, False, False)
        x_36 = None
        attn_windows_2 = x_37.view(-1, 7, 7, 256)
        x_37 = None
        x_38 = attn_windows_2.view(1, 5, 4, 7, 7, -1)
        attn_windows_2 = None
        permute_13 = x_38.permute(0, 1, 3, 2, 4, 5)
        x_38 = None
        contiguous_11 = permute_13.contiguous()
        permute_13 = None
        x_39 = contiguous_11.view(1, 35, 28, -1)
        contiguous_11 = None
        getitem_14 = x_39[
            (
                slice(None, None, None),
                slice(None, 32, None),
                slice(None, 24, None),
                slice(None, None, None),
            )
        ]
        x_39 = None
        x_40 = getitem_14.contiguous()
        getitem_14 = None
        x_41 = x_40.view(1, 768, 256)
        x_40 = None
        x_42 = x_41 + x_32
        x_41 = x_32 = None
        x_43 = torch.nn.functional.layer_norm(
            x_42,
            (256,),
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_norm2_parameters_bias_ = (None)
        input_11 = torch._C._nn.linear(
            x_43,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_43 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_12 = torch._C._nn.gelu(input_11, approximate="none")
        input_11 = None
        input_13 = torch.nn.functional.dropout(input_12, 0.0, False, False)
        input_12 = None
        input_14 = torch._C._nn.linear(
            input_13,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_13 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_15 = torch.nn.functional.dropout(input_14, 0.0, False, False)
        input_14 = None
        output_2 = x_42 + input_15
        x_42 = input_15 = None
        x_44 = torch.nn.functional.layer_norm(
            output_2,
            (256,),
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm1_parameters_bias_ = (None)
        query_6 = x_44.view(1, 32, 24, 256)
        x_44 = None
        query_7 = torch._C._nn.pad(query_6, (0, 0, 0, 4, 0, 3), "constant", None)
        query_6 = None
        shifted_query_1 = torch.roll(query_7, shifts=(-3, -3), dims=(1, 2))
        query_7 = None
        img_mask_1 = torch.zeros((1, 35, 28, 1), device=device(type="cuda", index=0))
        img_mask_1[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_9 = img_mask_1
        setitem_9 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_10 = img_mask_1
        setitem_10 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_11 = img_mask_1
        setitem_11 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_12 = img_mask_1
        setitem_12 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_13 = img_mask_1
        setitem_13 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_14 = img_mask_1
        setitem_14 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_15 = img_mask_1
        setitem_15 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_16 = img_mask_1
        setitem_16 = None
        img_mask_1[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_17 = img_mask_1
        setitem_17 = None
        x_45 = img_mask_1.view(1, 5, 7, 4, 7, 1)
        img_mask_1 = None
        permute_14 = x_45.permute(0, 1, 3, 2, 4, 5)
        x_45 = None
        windows_8 = permute_14.contiguous()
        permute_14 = None
        windows_9 = windows_8.view(-1, 7, 7, 1)
        windows_8 = None
        mask_windows_1 = windows_9.view(-1, 49)
        windows_9 = None
        unsqueeze_7 = mask_windows_1.unsqueeze(1)
        unsqueeze_8 = mask_windows_1.unsqueeze(2)
        mask_windows_1 = None
        attn_mask_2 = unsqueeze_7 - unsqueeze_8
        unsqueeze_7 = unsqueeze_8 = None
        ne_1 = attn_mask_2 != 0
        masked_fill_2 = attn_mask_2.masked_fill(ne_1, -100.0)
        ne_1 = None
        eq_1 = attn_mask_2 == 0
        attn_mask_2 = None
        attn_mask_3 = masked_fill_2.masked_fill(eq_1, 0.0)
        masked_fill_2 = eq_1 = None
        x_46 = shifted_query_1.view(1, 5, 7, 4, 7, 256)
        shifted_query_1 = None
        permute_15 = x_46.permute(0, 1, 3, 2, 4, 5)
        x_46 = None
        windows_10 = permute_15.contiguous()
        permute_15 = None
        windows_11 = windows_10.view(-1, 7, 7, 256)
        windows_10 = None
        query_windows_3 = windows_11.view(-1, 49, 256)
        windows_11 = None
        linear_13 = torch._C._nn.linear(
            query_windows_3,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_3 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_6 = linear_13.reshape(20, 49, 3, 8, 32)
        linear_13 = None
        qkv_3 = reshape_6.permute(2, 0, 3, 1, 4)
        reshape_6 = None
        q_6 = qkv_3[0]
        k_3 = qkv_3[1]
        v_3 = qkv_3[2]
        qkv_3 = None
        q_7 = q_6 * 0.1767766952966369
        q_6 = None
        transpose_8 = k_3.transpose(-2, -1)
        k_3 = None
        attn_14 = q_7 @ transpose_8
        q_7 = transpose_8 = None
        view_43 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_18 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_43
        ]
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_43
        ) = None
        relative_position_bias_6 = getitem_18.view(49, 49, -1)
        getitem_18 = None
        permute_17 = relative_position_bias_6.permute(2, 0, 1)
        relative_position_bias_6 = None
        relative_position_bias_7 = permute_17.contiguous()
        permute_17 = None
        unsqueeze_9 = relative_position_bias_7.unsqueeze(0)
        relative_position_bias_7 = None
        attn_15 = attn_14 + unsqueeze_9
        attn_14 = unsqueeze_9 = None
        view_45 = attn_15.view(1, 20, 8, 49, 49)
        attn_15 = None
        unsqueeze_10 = attn_mask_3.unsqueeze(1)
        attn_mask_3 = None
        unsqueeze_11 = unsqueeze_10.unsqueeze(0)
        unsqueeze_10 = None
        attn_16 = view_45 + unsqueeze_11
        view_45 = unsqueeze_11 = None
        attn_17 = attn_16.view(-1, 8, 49, 49)
        attn_16 = None
        attn_18 = torch.nn.functional.softmax(attn_17, -1, _stacklevel=5)
        attn_17 = None
        attn_19 = torch.nn.functional.dropout(attn_18, 0.0, False, False)
        attn_18 = None
        matmul_7 = attn_19 @ v_3
        attn_19 = v_3 = None
        transpose_9 = matmul_7.transpose(1, 2)
        matmul_7 = None
        x_47 = transpose_9.reshape(20, 49, 256)
        transpose_9 = None
        x_48 = torch._C._nn.linear(
            x_47,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_47 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_49 = torch.nn.functional.dropout(x_48, 0.0, False, False)
        x_48 = None
        attn_windows_3 = x_49.view(-1, 7, 7, 256)
        x_49 = None
        x_50 = attn_windows_3.view(1, 5, 4, 7, 7, -1)
        attn_windows_3 = None
        permute_18 = x_50.permute(0, 1, 3, 2, 4, 5)
        x_50 = None
        contiguous_16 = permute_18.contiguous()
        permute_18 = None
        x_51 = contiguous_16.view(1, 35, 28, -1)
        contiguous_16 = None
        x_52 = torch.roll(x_51, shifts=(3, 3), dims=(1, 2))
        x_51 = None
        getitem_19 = x_52[
            (
                slice(None, None, None),
                slice(None, 32, None),
                slice(None, 24, None),
                slice(None, None, None),
            )
        ]
        x_52 = None
        x_53 = getitem_19.contiguous()
        getitem_19 = None
        x_54 = x_53.view(1, 768, 256)
        x_53 = None
        x_55 = x_54 + output_2
        x_54 = output_2 = None
        x_56 = torch.nn.functional.layer_norm(
            x_55,
            (256,),
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_norm2_parameters_bias_ = (None)
        input_16 = torch._C._nn.linear(
            x_56,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_56 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_17 = torch._C._nn.gelu(input_16, approximate="none")
        input_16 = None
        input_18 = torch.nn.functional.dropout(input_17, 0.0, False, False)
        input_17 = None
        input_19 = torch._C._nn.linear(
            input_18,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_18 = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_20 = torch.nn.functional.dropout(input_19, 0.0, False, False)
        input_19 = None
        output_3 = x_55 + input_20
        x_55 = input_20 = None
        view_51 = output_3.view(1, 32, 24, 256)
        output_3 = None
        x_57 = view_51.permute([0, 3, 1, 2])
        view_51 = None
        x_58 = torch.nn.functional.unfold(x_57, (2, 2), (1, 1), (0, 0), (2, 2))
        x_57 = None
        x_59 = x_58.transpose(1, 2)
        x_58 = None
        x_60 = torch.nn.functional.layer_norm(
            x_59,
            (1024,),
            l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_bias_,
            1e-05,
        )
        x_59 = l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_norm_parameters_bias_ = (None)
        x_61 = torch._C._nn.linear(
            x_60,
            l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_reduction_parameters_weight_,
            None,
        )
        x_60 = l_self_modules_backbone_modules_stages_modules_1_modules_downsample_modules_reduction_parameters_weight_ = (None)
        x_62 = torch.nn.functional.layer_norm(
            x_61,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm1_parameters_bias_ = (None)
        query_8 = x_62.view(1, 16, 12, 512)
        x_62 = None
        query_9 = torch._C._nn.pad(query_8, (0, 0, 0, 2, 0, 5), "constant", None)
        query_8 = None
        x_63 = query_9.view(1, 3, 7, 2, 7, 512)
        query_9 = None
        permute_20 = x_63.permute(0, 1, 3, 2, 4, 5)
        x_63 = None
        windows_12 = permute_20.contiguous()
        permute_20 = None
        windows_13 = windows_12.view(-1, 7, 7, 512)
        windows_12 = None
        query_windows_4 = windows_13.view(-1, 49, 512)
        windows_13 = None
        linear_18 = torch._C._nn.linear(
            query_windows_4,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_4 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_8 = linear_18.reshape(6, 49, 3, 16, 32)
        linear_18 = None
        qkv_4 = reshape_8.permute(2, 0, 3, 1, 4)
        reshape_8 = None
        q_8 = qkv_4[0]
        k_4 = qkv_4[1]
        v_4 = qkv_4[2]
        qkv_4 = None
        q_9 = q_8 * 0.1767766952966369
        q_8 = None
        transpose_11 = k_4.transpose(-2, -1)
        k_4 = None
        attn_20 = q_9 @ transpose_11
        q_9 = transpose_11 = None
        view_56 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_23 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_56
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_56
        ) = None
        relative_position_bias_8 = getitem_23.view(49, 49, -1)
        getitem_23 = None
        permute_22 = relative_position_bias_8.permute(2, 0, 1)
        relative_position_bias_8 = None
        relative_position_bias_9 = permute_22.contiguous()
        permute_22 = None
        unsqueeze_12 = relative_position_bias_9.unsqueeze(0)
        relative_position_bias_9 = None
        attn_21 = attn_20 + unsqueeze_12
        attn_20 = unsqueeze_12 = None
        attn_22 = torch.nn.functional.softmax(attn_21, -1, _stacklevel=5)
        attn_21 = None
        attn_23 = torch.nn.functional.dropout(attn_22, 0.0, False, False)
        attn_22 = None
        matmul_9 = attn_23 @ v_4
        attn_23 = v_4 = None
        transpose_12 = matmul_9.transpose(1, 2)
        matmul_9 = None
        x_64 = transpose_12.reshape(6, 49, 512)
        transpose_12 = None
        x_65 = torch._C._nn.linear(
            x_64,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_64 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_66 = torch.nn.functional.dropout(x_65, 0.0, False, False)
        x_65 = None
        attn_windows_4 = x_66.view(-1, 7, 7, 512)
        x_66 = None
        x_67 = attn_windows_4.view(1, 3, 2, 7, 7, -1)
        attn_windows_4 = None
        permute_23 = x_67.permute(0, 1, 3, 2, 4, 5)
        x_67 = None
        contiguous_20 = permute_23.contiguous()
        permute_23 = None
        x_68 = contiguous_20.view(1, 21, 14, -1)
        contiguous_20 = None
        getitem_24 = x_68[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_68 = None
        x_69 = getitem_24.contiguous()
        getitem_24 = None
        x_70 = x_69.view(1, 192, 512)
        x_69 = None
        x_71 = x_70 + x_61
        x_70 = x_61 = None
        x_72 = torch.nn.functional.layer_norm(
            x_71,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_norm2_parameters_bias_ = (None)
        input_21 = torch._C._nn.linear(
            x_72,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_72 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_22 = torch._C._nn.gelu(input_21, approximate="none")
        input_21 = None
        input_23 = torch.nn.functional.dropout(input_22, 0.0, False, False)
        input_22 = None
        input_24 = torch._C._nn.linear(
            input_23,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_23 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_25 = torch.nn.functional.dropout(input_24, 0.0, False, False)
        input_24 = None
        output_4 = x_71 + input_25
        x_71 = input_25 = None
        x_73 = torch.nn.functional.layer_norm(
            output_4,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm1_parameters_bias_ = (None)
        query_10 = x_73.view(1, 16, 12, 512)
        x_73 = None
        query_11 = torch._C._nn.pad(query_10, (0, 0, 0, 2, 0, 5), "constant", None)
        query_10 = None
        shifted_query_2 = torch.roll(query_11, shifts=(-3, -3), dims=(1, 2))
        query_11 = None
        img_mask_2 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_2[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_18 = img_mask_2
        setitem_18 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_19 = img_mask_2
        setitem_19 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_20 = img_mask_2
        setitem_20 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_21 = img_mask_2
        setitem_21 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_22 = img_mask_2
        setitem_22 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_23 = img_mask_2
        setitem_23 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_24 = img_mask_2
        setitem_24 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_25 = img_mask_2
        setitem_25 = None
        img_mask_2[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_26 = img_mask_2
        setitem_26 = None
        x_74 = img_mask_2.view(1, 3, 7, 2, 7, 1)
        img_mask_2 = None
        permute_24 = x_74.permute(0, 1, 3, 2, 4, 5)
        x_74 = None
        windows_14 = permute_24.contiguous()
        permute_24 = None
        windows_15 = windows_14.view(-1, 7, 7, 1)
        windows_14 = None
        mask_windows_2 = windows_15.view(-1, 49)
        windows_15 = None
        unsqueeze_13 = mask_windows_2.unsqueeze(1)
        unsqueeze_14 = mask_windows_2.unsqueeze(2)
        mask_windows_2 = None
        attn_mask_4 = unsqueeze_13 - unsqueeze_14
        unsqueeze_13 = unsqueeze_14 = None
        ne_2 = attn_mask_4 != 0
        masked_fill_4 = attn_mask_4.masked_fill(ne_2, -100.0)
        ne_2 = None
        eq_2 = attn_mask_4 == 0
        attn_mask_4 = None
        attn_mask_5 = masked_fill_4.masked_fill(eq_2, 0.0)
        masked_fill_4 = eq_2 = None
        x_75 = shifted_query_2.view(1, 3, 7, 2, 7, 512)
        shifted_query_2 = None
        permute_25 = x_75.permute(0, 1, 3, 2, 4, 5)
        x_75 = None
        windows_16 = permute_25.contiguous()
        permute_25 = None
        windows_17 = windows_16.view(-1, 7, 7, 512)
        windows_16 = None
        query_windows_5 = windows_17.view(-1, 49, 512)
        windows_17 = None
        linear_22 = torch._C._nn.linear(
            query_windows_5,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_5 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_10 = linear_22.reshape(6, 49, 3, 16, 32)
        linear_22 = None
        qkv_5 = reshape_10.permute(2, 0, 3, 1, 4)
        reshape_10 = None
        q_10 = qkv_5[0]
        k_5 = qkv_5[1]
        v_5 = qkv_5[2]
        qkv_5 = None
        q_11 = q_10 * 0.1767766952966369
        q_10 = None
        transpose_13 = k_5.transpose(-2, -1)
        k_5 = None
        attn_24 = q_11 @ transpose_13
        q_11 = transpose_13 = None
        view_69 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_28 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_69
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_69
        ) = None
        relative_position_bias_10 = getitem_28.view(49, 49, -1)
        getitem_28 = None
        permute_27 = relative_position_bias_10.permute(2, 0, 1)
        relative_position_bias_10 = None
        relative_position_bias_11 = permute_27.contiguous()
        permute_27 = None
        unsqueeze_15 = relative_position_bias_11.unsqueeze(0)
        relative_position_bias_11 = None
        attn_25 = attn_24 + unsqueeze_15
        attn_24 = unsqueeze_15 = None
        view_71 = attn_25.view(1, 6, 16, 49, 49)
        attn_25 = None
        unsqueeze_16 = attn_mask_5.unsqueeze(1)
        attn_mask_5 = None
        unsqueeze_17 = unsqueeze_16.unsqueeze(0)
        unsqueeze_16 = None
        attn_26 = view_71 + unsqueeze_17
        view_71 = unsqueeze_17 = None
        attn_27 = attn_26.view(-1, 16, 49, 49)
        attn_26 = None
        attn_28 = torch.nn.functional.softmax(attn_27, -1, _stacklevel=5)
        attn_27 = None
        attn_29 = torch.nn.functional.dropout(attn_28, 0.0, False, False)
        attn_28 = None
        matmul_11 = attn_29 @ v_5
        attn_29 = v_5 = None
        transpose_14 = matmul_11.transpose(1, 2)
        matmul_11 = None
        x_76 = transpose_14.reshape(6, 49, 512)
        transpose_14 = None
        x_77 = torch._C._nn.linear(
            x_76,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_76 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_78 = torch.nn.functional.dropout(x_77, 0.0, False, False)
        x_77 = None
        attn_windows_5 = x_78.view(-1, 7, 7, 512)
        x_78 = None
        x_79 = attn_windows_5.view(1, 3, 2, 7, 7, -1)
        attn_windows_5 = None
        permute_28 = x_79.permute(0, 1, 3, 2, 4, 5)
        x_79 = None
        contiguous_25 = permute_28.contiguous()
        permute_28 = None
        x_80 = contiguous_25.view(1, 21, 14, -1)
        contiguous_25 = None
        x_81 = torch.roll(x_80, shifts=(3, 3), dims=(1, 2))
        x_80 = None
        getitem_29 = x_81[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_81 = None
        x_82 = getitem_29.contiguous()
        getitem_29 = None
        x_83 = x_82.view(1, 192, 512)
        x_82 = None
        x_84 = x_83 + output_4
        x_83 = output_4 = None
        x_85 = torch.nn.functional.layer_norm(
            x_84,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_norm2_parameters_bias_ = (None)
        input_26 = torch._C._nn.linear(
            x_85,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_85 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_27 = torch._C._nn.gelu(input_26, approximate="none")
        input_26 = None
        input_28 = torch.nn.functional.dropout(input_27, 0.0, False, False)
        input_27 = None
        input_29 = torch._C._nn.linear(
            input_28,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_28 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_30 = torch.nn.functional.dropout(input_29, 0.0, False, False)
        input_29 = None
        output_5 = x_84 + input_30
        x_84 = input_30 = None
        x_86 = torch.nn.functional.layer_norm(
            output_5,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm1_parameters_bias_ = (None)
        query_12 = x_86.view(1, 16, 12, 512)
        x_86 = None
        query_13 = torch._C._nn.pad(query_12, (0, 0, 0, 2, 0, 5), "constant", None)
        query_12 = None
        x_87 = query_13.view(1, 3, 7, 2, 7, 512)
        query_13 = None
        permute_29 = x_87.permute(0, 1, 3, 2, 4, 5)
        x_87 = None
        windows_18 = permute_29.contiguous()
        permute_29 = None
        windows_19 = windows_18.view(-1, 7, 7, 512)
        windows_18 = None
        query_windows_6 = windows_19.view(-1, 49, 512)
        windows_19 = None
        linear_26 = torch._C._nn.linear(
            query_windows_6,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_6 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_12 = linear_26.reshape(6, 49, 3, 16, 32)
        linear_26 = None
        qkv_6 = reshape_12.permute(2, 0, 3, 1, 4)
        reshape_12 = None
        q_12 = qkv_6[0]
        k_6 = qkv_6[1]
        v_6 = qkv_6[2]
        qkv_6 = None
        q_13 = q_12 * 0.1767766952966369
        q_12 = None
        transpose_15 = k_6.transpose(-2, -1)
        k_6 = None
        attn_30 = q_13 @ transpose_15
        q_13 = transpose_15 = None
        view_81 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_33 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_81
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_81
        ) = None
        relative_position_bias_12 = getitem_33.view(49, 49, -1)
        getitem_33 = None
        permute_31 = relative_position_bias_12.permute(2, 0, 1)
        relative_position_bias_12 = None
        relative_position_bias_13 = permute_31.contiguous()
        permute_31 = None
        unsqueeze_18 = relative_position_bias_13.unsqueeze(0)
        relative_position_bias_13 = None
        attn_31 = attn_30 + unsqueeze_18
        attn_30 = unsqueeze_18 = None
        attn_32 = torch.nn.functional.softmax(attn_31, -1, _stacklevel=5)
        attn_31 = None
        attn_33 = torch.nn.functional.dropout(attn_32, 0.0, False, False)
        attn_32 = None
        matmul_13 = attn_33 @ v_6
        attn_33 = v_6 = None
        transpose_16 = matmul_13.transpose(1, 2)
        matmul_13 = None
        x_88 = transpose_16.reshape(6, 49, 512)
        transpose_16 = None
        x_89 = torch._C._nn.linear(
            x_88,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_88 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_90 = torch.nn.functional.dropout(x_89, 0.0, False, False)
        x_89 = None
        attn_windows_6 = x_90.view(-1, 7, 7, 512)
        x_90 = None
        x_91 = attn_windows_6.view(1, 3, 2, 7, 7, -1)
        attn_windows_6 = None
        permute_32 = x_91.permute(0, 1, 3, 2, 4, 5)
        x_91 = None
        contiguous_29 = permute_32.contiguous()
        permute_32 = None
        x_92 = contiguous_29.view(1, 21, 14, -1)
        contiguous_29 = None
        getitem_34 = x_92[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_92 = None
        x_93 = getitem_34.contiguous()
        getitem_34 = None
        x_94 = x_93.view(1, 192, 512)
        x_93 = None
        x_95 = x_94 + output_5
        x_94 = output_5 = None
        x_96 = torch.nn.functional.layer_norm(
            x_95,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_norm2_parameters_bias_ = (None)
        input_31 = torch._C._nn.linear(
            x_96,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_96 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_32 = torch._C._nn.gelu(input_31, approximate="none")
        input_31 = None
        input_33 = torch.nn.functional.dropout(input_32, 0.0, False, False)
        input_32 = None
        input_34 = torch._C._nn.linear(
            input_33,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_33 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_2_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_35 = torch.nn.functional.dropout(input_34, 0.0, False, False)
        input_34 = None
        output_6 = x_95 + input_35
        x_95 = input_35 = None
        x_97 = torch.nn.functional.layer_norm(
            output_6,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm1_parameters_bias_ = (None)
        query_14 = x_97.view(1, 16, 12, 512)
        x_97 = None
        query_15 = torch._C._nn.pad(query_14, (0, 0, 0, 2, 0, 5), "constant", None)
        query_14 = None
        shifted_query_3 = torch.roll(query_15, shifts=(-3, -3), dims=(1, 2))
        query_15 = None
        img_mask_3 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_3[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_27 = img_mask_3
        setitem_27 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_28 = img_mask_3
        setitem_28 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_29 = img_mask_3
        setitem_29 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_30 = img_mask_3
        setitem_30 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_31 = img_mask_3
        setitem_31 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_32 = img_mask_3
        setitem_32 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_33 = img_mask_3
        setitem_33 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_34 = img_mask_3
        setitem_34 = None
        img_mask_3[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_35 = img_mask_3
        setitem_35 = None
        x_98 = img_mask_3.view(1, 3, 7, 2, 7, 1)
        img_mask_3 = None
        permute_33 = x_98.permute(0, 1, 3, 2, 4, 5)
        x_98 = None
        windows_20 = permute_33.contiguous()
        permute_33 = None
        windows_21 = windows_20.view(-1, 7, 7, 1)
        windows_20 = None
        mask_windows_3 = windows_21.view(-1, 49)
        windows_21 = None
        unsqueeze_19 = mask_windows_3.unsqueeze(1)
        unsqueeze_20 = mask_windows_3.unsqueeze(2)
        mask_windows_3 = None
        attn_mask_6 = unsqueeze_19 - unsqueeze_20
        unsqueeze_19 = unsqueeze_20 = None
        ne_3 = attn_mask_6 != 0
        masked_fill_6 = attn_mask_6.masked_fill(ne_3, -100.0)
        ne_3 = None
        eq_3 = attn_mask_6 == 0
        attn_mask_6 = None
        attn_mask_7 = masked_fill_6.masked_fill(eq_3, 0.0)
        masked_fill_6 = eq_3 = None
        x_99 = shifted_query_3.view(1, 3, 7, 2, 7, 512)
        shifted_query_3 = None
        permute_34 = x_99.permute(0, 1, 3, 2, 4, 5)
        x_99 = None
        windows_22 = permute_34.contiguous()
        permute_34 = None
        windows_23 = windows_22.view(-1, 7, 7, 512)
        windows_22 = None
        query_windows_7 = windows_23.view(-1, 49, 512)
        windows_23 = None
        linear_30 = torch._C._nn.linear(
            query_windows_7,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_7 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_14 = linear_30.reshape(6, 49, 3, 16, 32)
        linear_30 = None
        qkv_7 = reshape_14.permute(2, 0, 3, 1, 4)
        reshape_14 = None
        q_14 = qkv_7[0]
        k_7 = qkv_7[1]
        v_7 = qkv_7[2]
        qkv_7 = None
        q_15 = q_14 * 0.1767766952966369
        q_14 = None
        transpose_17 = k_7.transpose(-2, -1)
        k_7 = None
        attn_34 = q_15 @ transpose_17
        q_15 = transpose_17 = None
        view_94 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_38 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_94
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_94
        ) = None
        relative_position_bias_14 = getitem_38.view(49, 49, -1)
        getitem_38 = None
        permute_36 = relative_position_bias_14.permute(2, 0, 1)
        relative_position_bias_14 = None
        relative_position_bias_15 = permute_36.contiguous()
        permute_36 = None
        unsqueeze_21 = relative_position_bias_15.unsqueeze(0)
        relative_position_bias_15 = None
        attn_35 = attn_34 + unsqueeze_21
        attn_34 = unsqueeze_21 = None
        view_96 = attn_35.view(1, 6, 16, 49, 49)
        attn_35 = None
        unsqueeze_22 = attn_mask_7.unsqueeze(1)
        attn_mask_7 = None
        unsqueeze_23 = unsqueeze_22.unsqueeze(0)
        unsqueeze_22 = None
        attn_36 = view_96 + unsqueeze_23
        view_96 = unsqueeze_23 = None
        attn_37 = attn_36.view(-1, 16, 49, 49)
        attn_36 = None
        attn_38 = torch.nn.functional.softmax(attn_37, -1, _stacklevel=5)
        attn_37 = None
        attn_39 = torch.nn.functional.dropout(attn_38, 0.0, False, False)
        attn_38 = None
        matmul_15 = attn_39 @ v_7
        attn_39 = v_7 = None
        transpose_18 = matmul_15.transpose(1, 2)
        matmul_15 = None
        x_100 = transpose_18.reshape(6, 49, 512)
        transpose_18 = None
        x_101 = torch._C._nn.linear(
            x_100,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_100 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_102 = torch.nn.functional.dropout(x_101, 0.0, False, False)
        x_101 = None
        attn_windows_7 = x_102.view(-1, 7, 7, 512)
        x_102 = None
        x_103 = attn_windows_7.view(1, 3, 2, 7, 7, -1)
        attn_windows_7 = None
        permute_37 = x_103.permute(0, 1, 3, 2, 4, 5)
        x_103 = None
        contiguous_34 = permute_37.contiguous()
        permute_37 = None
        x_104 = contiguous_34.view(1, 21, 14, -1)
        contiguous_34 = None
        x_105 = torch.roll(x_104, shifts=(3, 3), dims=(1, 2))
        x_104 = None
        getitem_39 = x_105[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_105 = None
        x_106 = getitem_39.contiguous()
        getitem_39 = None
        x_107 = x_106.view(1, 192, 512)
        x_106 = None
        x_108 = x_107 + output_6
        x_107 = output_6 = None
        x_109 = torch.nn.functional.layer_norm(
            x_108,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_norm2_parameters_bias_ = (None)
        input_36 = torch._C._nn.linear(
            x_109,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_109 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_37 = torch._C._nn.gelu(input_36, approximate="none")
        input_36 = None
        input_38 = torch.nn.functional.dropout(input_37, 0.0, False, False)
        input_37 = None
        input_39 = torch._C._nn.linear(
            input_38,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_38 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_3_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_40 = torch.nn.functional.dropout(input_39, 0.0, False, False)
        input_39 = None
        output_7 = x_108 + input_40
        x_108 = input_40 = None
        x_110 = torch.nn.functional.layer_norm(
            output_7,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm1_parameters_bias_ = (None)
        query_16 = x_110.view(1, 16, 12, 512)
        x_110 = None
        query_17 = torch._C._nn.pad(query_16, (0, 0, 0, 2, 0, 5), "constant", None)
        query_16 = None
        x_111 = query_17.view(1, 3, 7, 2, 7, 512)
        query_17 = None
        permute_38 = x_111.permute(0, 1, 3, 2, 4, 5)
        x_111 = None
        windows_24 = permute_38.contiguous()
        permute_38 = None
        windows_25 = windows_24.view(-1, 7, 7, 512)
        windows_24 = None
        query_windows_8 = windows_25.view(-1, 49, 512)
        windows_25 = None
        linear_34 = torch._C._nn.linear(
            query_windows_8,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_8 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_16 = linear_34.reshape(6, 49, 3, 16, 32)
        linear_34 = None
        qkv_8 = reshape_16.permute(2, 0, 3, 1, 4)
        reshape_16 = None
        q_16 = qkv_8[0]
        k_8 = qkv_8[1]
        v_8 = qkv_8[2]
        qkv_8 = None
        q_17 = q_16 * 0.1767766952966369
        q_16 = None
        transpose_19 = k_8.transpose(-2, -1)
        k_8 = None
        attn_40 = q_17 @ transpose_19
        q_17 = transpose_19 = None
        view_106 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_43 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_106
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_106
        ) = None
        relative_position_bias_16 = getitem_43.view(49, 49, -1)
        getitem_43 = None
        permute_40 = relative_position_bias_16.permute(2, 0, 1)
        relative_position_bias_16 = None
        relative_position_bias_17 = permute_40.contiguous()
        permute_40 = None
        unsqueeze_24 = relative_position_bias_17.unsqueeze(0)
        relative_position_bias_17 = None
        attn_41 = attn_40 + unsqueeze_24
        attn_40 = unsqueeze_24 = None
        attn_42 = torch.nn.functional.softmax(attn_41, -1, _stacklevel=5)
        attn_41 = None
        attn_43 = torch.nn.functional.dropout(attn_42, 0.0, False, False)
        attn_42 = None
        matmul_17 = attn_43 @ v_8
        attn_43 = v_8 = None
        transpose_20 = matmul_17.transpose(1, 2)
        matmul_17 = None
        x_112 = transpose_20.reshape(6, 49, 512)
        transpose_20 = None
        x_113 = torch._C._nn.linear(
            x_112,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_112 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_114 = torch.nn.functional.dropout(x_113, 0.0, False, False)
        x_113 = None
        attn_windows_8 = x_114.view(-1, 7, 7, 512)
        x_114 = None
        x_115 = attn_windows_8.view(1, 3, 2, 7, 7, -1)
        attn_windows_8 = None
        permute_41 = x_115.permute(0, 1, 3, 2, 4, 5)
        x_115 = None
        contiguous_38 = permute_41.contiguous()
        permute_41 = None
        x_116 = contiguous_38.view(1, 21, 14, -1)
        contiguous_38 = None
        getitem_44 = x_116[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_116 = None
        x_117 = getitem_44.contiguous()
        getitem_44 = None
        x_118 = x_117.view(1, 192, 512)
        x_117 = None
        x_119 = x_118 + output_7
        x_118 = output_7 = None
        x_120 = torch.nn.functional.layer_norm(
            x_119,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_norm2_parameters_bias_ = (None)
        input_41 = torch._C._nn.linear(
            x_120,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_120 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_42 = torch._C._nn.gelu(input_41, approximate="none")
        input_41 = None
        input_43 = torch.nn.functional.dropout(input_42, 0.0, False, False)
        input_42 = None
        input_44 = torch._C._nn.linear(
            input_43,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_43 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_4_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_45 = torch.nn.functional.dropout(input_44, 0.0, False, False)
        input_44 = None
        output_8 = x_119 + input_45
        x_119 = input_45 = None
        x_121 = torch.nn.functional.layer_norm(
            output_8,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm1_parameters_bias_ = (None)
        query_18 = x_121.view(1, 16, 12, 512)
        x_121 = None
        query_19 = torch._C._nn.pad(query_18, (0, 0, 0, 2, 0, 5), "constant", None)
        query_18 = None
        shifted_query_4 = torch.roll(query_19, shifts=(-3, -3), dims=(1, 2))
        query_19 = None
        img_mask_4 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_4[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_36 = img_mask_4
        setitem_36 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_37 = img_mask_4
        setitem_37 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_38 = img_mask_4
        setitem_38 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_39 = img_mask_4
        setitem_39 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_40 = img_mask_4
        setitem_40 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_41 = img_mask_4
        setitem_41 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_42 = img_mask_4
        setitem_42 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_43 = img_mask_4
        setitem_43 = None
        img_mask_4[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_44 = img_mask_4
        setitem_44 = None
        x_122 = img_mask_4.view(1, 3, 7, 2, 7, 1)
        img_mask_4 = None
        permute_42 = x_122.permute(0, 1, 3, 2, 4, 5)
        x_122 = None
        windows_26 = permute_42.contiguous()
        permute_42 = None
        windows_27 = windows_26.view(-1, 7, 7, 1)
        windows_26 = None
        mask_windows_4 = windows_27.view(-1, 49)
        windows_27 = None
        unsqueeze_25 = mask_windows_4.unsqueeze(1)
        unsqueeze_26 = mask_windows_4.unsqueeze(2)
        mask_windows_4 = None
        attn_mask_8 = unsqueeze_25 - unsqueeze_26
        unsqueeze_25 = unsqueeze_26 = None
        ne_4 = attn_mask_8 != 0
        masked_fill_8 = attn_mask_8.masked_fill(ne_4, -100.0)
        ne_4 = None
        eq_4 = attn_mask_8 == 0
        attn_mask_8 = None
        attn_mask_9 = masked_fill_8.masked_fill(eq_4, 0.0)
        masked_fill_8 = eq_4 = None
        x_123 = shifted_query_4.view(1, 3, 7, 2, 7, 512)
        shifted_query_4 = None
        permute_43 = x_123.permute(0, 1, 3, 2, 4, 5)
        x_123 = None
        windows_28 = permute_43.contiguous()
        permute_43 = None
        windows_29 = windows_28.view(-1, 7, 7, 512)
        windows_28 = None
        query_windows_9 = windows_29.view(-1, 49, 512)
        windows_29 = None
        linear_38 = torch._C._nn.linear(
            query_windows_9,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_9 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_18 = linear_38.reshape(6, 49, 3, 16, 32)
        linear_38 = None
        qkv_9 = reshape_18.permute(2, 0, 3, 1, 4)
        reshape_18 = None
        q_18 = qkv_9[0]
        k_9 = qkv_9[1]
        v_9 = qkv_9[2]
        qkv_9 = None
        q_19 = q_18 * 0.1767766952966369
        q_18 = None
        transpose_21 = k_9.transpose(-2, -1)
        k_9 = None
        attn_44 = q_19 @ transpose_21
        q_19 = transpose_21 = None
        view_119 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_48 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_119
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_119
        ) = None
        relative_position_bias_18 = getitem_48.view(49, 49, -1)
        getitem_48 = None
        permute_45 = relative_position_bias_18.permute(2, 0, 1)
        relative_position_bias_18 = None
        relative_position_bias_19 = permute_45.contiguous()
        permute_45 = None
        unsqueeze_27 = relative_position_bias_19.unsqueeze(0)
        relative_position_bias_19 = None
        attn_45 = attn_44 + unsqueeze_27
        attn_44 = unsqueeze_27 = None
        view_121 = attn_45.view(1, 6, 16, 49, 49)
        attn_45 = None
        unsqueeze_28 = attn_mask_9.unsqueeze(1)
        attn_mask_9 = None
        unsqueeze_29 = unsqueeze_28.unsqueeze(0)
        unsqueeze_28 = None
        attn_46 = view_121 + unsqueeze_29
        view_121 = unsqueeze_29 = None
        attn_47 = attn_46.view(-1, 16, 49, 49)
        attn_46 = None
        attn_48 = torch.nn.functional.softmax(attn_47, -1, _stacklevel=5)
        attn_47 = None
        attn_49 = torch.nn.functional.dropout(attn_48, 0.0, False, False)
        attn_48 = None
        matmul_19 = attn_49 @ v_9
        attn_49 = v_9 = None
        transpose_22 = matmul_19.transpose(1, 2)
        matmul_19 = None
        x_124 = transpose_22.reshape(6, 49, 512)
        transpose_22 = None
        x_125 = torch._C._nn.linear(
            x_124,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_124 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_126 = torch.nn.functional.dropout(x_125, 0.0, False, False)
        x_125 = None
        attn_windows_9 = x_126.view(-1, 7, 7, 512)
        x_126 = None
        x_127 = attn_windows_9.view(1, 3, 2, 7, 7, -1)
        attn_windows_9 = None
        permute_46 = x_127.permute(0, 1, 3, 2, 4, 5)
        x_127 = None
        contiguous_43 = permute_46.contiguous()
        permute_46 = None
        x_128 = contiguous_43.view(1, 21, 14, -1)
        contiguous_43 = None
        x_129 = torch.roll(x_128, shifts=(3, 3), dims=(1, 2))
        x_128 = None
        getitem_49 = x_129[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_129 = None
        x_130 = getitem_49.contiguous()
        getitem_49 = None
        x_131 = x_130.view(1, 192, 512)
        x_130 = None
        x_132 = x_131 + output_8
        x_131 = output_8 = None
        x_133 = torch.nn.functional.layer_norm(
            x_132,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_norm2_parameters_bias_ = (None)
        input_46 = torch._C._nn.linear(
            x_133,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_133 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_47 = torch._C._nn.gelu(input_46, approximate="none")
        input_46 = None
        input_48 = torch.nn.functional.dropout(input_47, 0.0, False, False)
        input_47 = None
        input_49 = torch._C._nn.linear(
            input_48,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_48 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_5_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_50 = torch.nn.functional.dropout(input_49, 0.0, False, False)
        input_49 = None
        output_9 = x_132 + input_50
        x_132 = input_50 = None
        x_134 = torch.nn.functional.layer_norm(
            output_9,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm1_parameters_bias_ = (None)
        query_20 = x_134.view(1, 16, 12, 512)
        x_134 = None
        query_21 = torch._C._nn.pad(query_20, (0, 0, 0, 2, 0, 5), "constant", None)
        query_20 = None
        x_135 = query_21.view(1, 3, 7, 2, 7, 512)
        query_21 = None
        permute_47 = x_135.permute(0, 1, 3, 2, 4, 5)
        x_135 = None
        windows_30 = permute_47.contiguous()
        permute_47 = None
        windows_31 = windows_30.view(-1, 7, 7, 512)
        windows_30 = None
        query_windows_10 = windows_31.view(-1, 49, 512)
        windows_31 = None
        linear_42 = torch._C._nn.linear(
            query_windows_10,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_10 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_20 = linear_42.reshape(6, 49, 3, 16, 32)
        linear_42 = None
        qkv_10 = reshape_20.permute(2, 0, 3, 1, 4)
        reshape_20 = None
        q_20 = qkv_10[0]
        k_10 = qkv_10[1]
        v_10 = qkv_10[2]
        qkv_10 = None
        q_21 = q_20 * 0.1767766952966369
        q_20 = None
        transpose_23 = k_10.transpose(-2, -1)
        k_10 = None
        attn_50 = q_21 @ transpose_23
        q_21 = transpose_23 = None
        view_131 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_53 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_131
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_131
        ) = None
        relative_position_bias_20 = getitem_53.view(49, 49, -1)
        getitem_53 = None
        permute_49 = relative_position_bias_20.permute(2, 0, 1)
        relative_position_bias_20 = None
        relative_position_bias_21 = permute_49.contiguous()
        permute_49 = None
        unsqueeze_30 = relative_position_bias_21.unsqueeze(0)
        relative_position_bias_21 = None
        attn_51 = attn_50 + unsqueeze_30
        attn_50 = unsqueeze_30 = None
        attn_52 = torch.nn.functional.softmax(attn_51, -1, _stacklevel=5)
        attn_51 = None
        attn_53 = torch.nn.functional.dropout(attn_52, 0.0, False, False)
        attn_52 = None
        matmul_21 = attn_53 @ v_10
        attn_53 = v_10 = None
        transpose_24 = matmul_21.transpose(1, 2)
        matmul_21 = None
        x_136 = transpose_24.reshape(6, 49, 512)
        transpose_24 = None
        x_137 = torch._C._nn.linear(
            x_136,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_136 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_138 = torch.nn.functional.dropout(x_137, 0.0, False, False)
        x_137 = None
        attn_windows_10 = x_138.view(-1, 7, 7, 512)
        x_138 = None
        x_139 = attn_windows_10.view(1, 3, 2, 7, 7, -1)
        attn_windows_10 = None
        permute_50 = x_139.permute(0, 1, 3, 2, 4, 5)
        x_139 = None
        contiguous_47 = permute_50.contiguous()
        permute_50 = None
        x_140 = contiguous_47.view(1, 21, 14, -1)
        contiguous_47 = None
        getitem_54 = x_140[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_140 = None
        x_141 = getitem_54.contiguous()
        getitem_54 = None
        x_142 = x_141.view(1, 192, 512)
        x_141 = None
        x_143 = x_142 + output_9
        x_142 = output_9 = None
        x_144 = torch.nn.functional.layer_norm(
            x_143,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_norm2_parameters_bias_ = (None)
        input_51 = torch._C._nn.linear(
            x_144,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_144 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_52 = torch._C._nn.gelu(input_51, approximate="none")
        input_51 = None
        input_53 = torch.nn.functional.dropout(input_52, 0.0, False, False)
        input_52 = None
        input_54 = torch._C._nn.linear(
            input_53,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_53 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_6_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_55 = torch.nn.functional.dropout(input_54, 0.0, False, False)
        input_54 = None
        output_10 = x_143 + input_55
        x_143 = input_55 = None
        x_145 = torch.nn.functional.layer_norm(
            output_10,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm1_parameters_bias_ = (None)
        query_22 = x_145.view(1, 16, 12, 512)
        x_145 = None
        query_23 = torch._C._nn.pad(query_22, (0, 0, 0, 2, 0, 5), "constant", None)
        query_22 = None
        shifted_query_5 = torch.roll(query_23, shifts=(-3, -3), dims=(1, 2))
        query_23 = None
        img_mask_5 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_5[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_45 = img_mask_5
        setitem_45 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_46 = img_mask_5
        setitem_46 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_47 = img_mask_5
        setitem_47 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_48 = img_mask_5
        setitem_48 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_49 = img_mask_5
        setitem_49 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_50 = img_mask_5
        setitem_50 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_51 = img_mask_5
        setitem_51 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_52 = img_mask_5
        setitem_52 = None
        img_mask_5[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_53 = img_mask_5
        setitem_53 = None
        x_146 = img_mask_5.view(1, 3, 7, 2, 7, 1)
        img_mask_5 = None
        permute_51 = x_146.permute(0, 1, 3, 2, 4, 5)
        x_146 = None
        windows_32 = permute_51.contiguous()
        permute_51 = None
        windows_33 = windows_32.view(-1, 7, 7, 1)
        windows_32 = None
        mask_windows_5 = windows_33.view(-1, 49)
        windows_33 = None
        unsqueeze_31 = mask_windows_5.unsqueeze(1)
        unsqueeze_32 = mask_windows_5.unsqueeze(2)
        mask_windows_5 = None
        attn_mask_10 = unsqueeze_31 - unsqueeze_32
        unsqueeze_31 = unsqueeze_32 = None
        ne_5 = attn_mask_10 != 0
        masked_fill_10 = attn_mask_10.masked_fill(ne_5, -100.0)
        ne_5 = None
        eq_5 = attn_mask_10 == 0
        attn_mask_10 = None
        attn_mask_11 = masked_fill_10.masked_fill(eq_5, 0.0)
        masked_fill_10 = eq_5 = None
        x_147 = shifted_query_5.view(1, 3, 7, 2, 7, 512)
        shifted_query_5 = None
        permute_52 = x_147.permute(0, 1, 3, 2, 4, 5)
        x_147 = None
        windows_34 = permute_52.contiguous()
        permute_52 = None
        windows_35 = windows_34.view(-1, 7, 7, 512)
        windows_34 = None
        query_windows_11 = windows_35.view(-1, 49, 512)
        windows_35 = None
        linear_46 = torch._C._nn.linear(
            query_windows_11,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_11 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_22 = linear_46.reshape(6, 49, 3, 16, 32)
        linear_46 = None
        qkv_11 = reshape_22.permute(2, 0, 3, 1, 4)
        reshape_22 = None
        q_22 = qkv_11[0]
        k_11 = qkv_11[1]
        v_11 = qkv_11[2]
        qkv_11 = None
        q_23 = q_22 * 0.1767766952966369
        q_22 = None
        transpose_25 = k_11.transpose(-2, -1)
        k_11 = None
        attn_54 = q_23 @ transpose_25
        q_23 = transpose_25 = None
        view_144 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_58 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_144
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_144
        ) = None
        relative_position_bias_22 = getitem_58.view(49, 49, -1)
        getitem_58 = None
        permute_54 = relative_position_bias_22.permute(2, 0, 1)
        relative_position_bias_22 = None
        relative_position_bias_23 = permute_54.contiguous()
        permute_54 = None
        unsqueeze_33 = relative_position_bias_23.unsqueeze(0)
        relative_position_bias_23 = None
        attn_55 = attn_54 + unsqueeze_33
        attn_54 = unsqueeze_33 = None
        view_146 = attn_55.view(1, 6, 16, 49, 49)
        attn_55 = None
        unsqueeze_34 = attn_mask_11.unsqueeze(1)
        attn_mask_11 = None
        unsqueeze_35 = unsqueeze_34.unsqueeze(0)
        unsqueeze_34 = None
        attn_56 = view_146 + unsqueeze_35
        view_146 = unsqueeze_35 = None
        attn_57 = attn_56.view(-1, 16, 49, 49)
        attn_56 = None
        attn_58 = torch.nn.functional.softmax(attn_57, -1, _stacklevel=5)
        attn_57 = None
        attn_59 = torch.nn.functional.dropout(attn_58, 0.0, False, False)
        attn_58 = None
        matmul_23 = attn_59 @ v_11
        attn_59 = v_11 = None
        transpose_26 = matmul_23.transpose(1, 2)
        matmul_23 = None
        x_148 = transpose_26.reshape(6, 49, 512)
        transpose_26 = None
        x_149 = torch._C._nn.linear(
            x_148,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_148 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_150 = torch.nn.functional.dropout(x_149, 0.0, False, False)
        x_149 = None
        attn_windows_11 = x_150.view(-1, 7, 7, 512)
        x_150 = None
        x_151 = attn_windows_11.view(1, 3, 2, 7, 7, -1)
        attn_windows_11 = None
        permute_55 = x_151.permute(0, 1, 3, 2, 4, 5)
        x_151 = None
        contiguous_52 = permute_55.contiguous()
        permute_55 = None
        x_152 = contiguous_52.view(1, 21, 14, -1)
        contiguous_52 = None
        x_153 = torch.roll(x_152, shifts=(3, 3), dims=(1, 2))
        x_152 = None
        getitem_59 = x_153[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_153 = None
        x_154 = getitem_59.contiguous()
        getitem_59 = None
        x_155 = x_154.view(1, 192, 512)
        x_154 = None
        x_156 = x_155 + output_10
        x_155 = output_10 = None
        x_157 = torch.nn.functional.layer_norm(
            x_156,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_norm2_parameters_bias_ = (None)
        input_56 = torch._C._nn.linear(
            x_157,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_157 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_57 = torch._C._nn.gelu(input_56, approximate="none")
        input_56 = None
        input_58 = torch.nn.functional.dropout(input_57, 0.0, False, False)
        input_57 = None
        input_59 = torch._C._nn.linear(
            input_58,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_58 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_7_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_60 = torch.nn.functional.dropout(input_59, 0.0, False, False)
        input_59 = None
        output_11 = x_156 + input_60
        x_156 = input_60 = None
        x_158 = torch.nn.functional.layer_norm(
            output_11,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm1_parameters_bias_ = (None)
        query_24 = x_158.view(1, 16, 12, 512)
        x_158 = None
        query_25 = torch._C._nn.pad(query_24, (0, 0, 0, 2, 0, 5), "constant", None)
        query_24 = None
        x_159 = query_25.view(1, 3, 7, 2, 7, 512)
        query_25 = None
        permute_56 = x_159.permute(0, 1, 3, 2, 4, 5)
        x_159 = None
        windows_36 = permute_56.contiguous()
        permute_56 = None
        windows_37 = windows_36.view(-1, 7, 7, 512)
        windows_36 = None
        query_windows_12 = windows_37.view(-1, 49, 512)
        windows_37 = None
        linear_50 = torch._C._nn.linear(
            query_windows_12,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_12 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_24 = linear_50.reshape(6, 49, 3, 16, 32)
        linear_50 = None
        qkv_12 = reshape_24.permute(2, 0, 3, 1, 4)
        reshape_24 = None
        q_24 = qkv_12[0]
        k_12 = qkv_12[1]
        v_12 = qkv_12[2]
        qkv_12 = None
        q_25 = q_24 * 0.1767766952966369
        q_24 = None
        transpose_27 = k_12.transpose(-2, -1)
        k_12 = None
        attn_60 = q_25 @ transpose_27
        q_25 = transpose_27 = None
        view_156 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_63 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_156
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_156
        ) = None
        relative_position_bias_24 = getitem_63.view(49, 49, -1)
        getitem_63 = None
        permute_58 = relative_position_bias_24.permute(2, 0, 1)
        relative_position_bias_24 = None
        relative_position_bias_25 = permute_58.contiguous()
        permute_58 = None
        unsqueeze_36 = relative_position_bias_25.unsqueeze(0)
        relative_position_bias_25 = None
        attn_61 = attn_60 + unsqueeze_36
        attn_60 = unsqueeze_36 = None
        attn_62 = torch.nn.functional.softmax(attn_61, -1, _stacklevel=5)
        attn_61 = None
        attn_63 = torch.nn.functional.dropout(attn_62, 0.0, False, False)
        attn_62 = None
        matmul_25 = attn_63 @ v_12
        attn_63 = v_12 = None
        transpose_28 = matmul_25.transpose(1, 2)
        matmul_25 = None
        x_160 = transpose_28.reshape(6, 49, 512)
        transpose_28 = None
        x_161 = torch._C._nn.linear(
            x_160,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_160 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_162 = torch.nn.functional.dropout(x_161, 0.0, False, False)
        x_161 = None
        attn_windows_12 = x_162.view(-1, 7, 7, 512)
        x_162 = None
        x_163 = attn_windows_12.view(1, 3, 2, 7, 7, -1)
        attn_windows_12 = None
        permute_59 = x_163.permute(0, 1, 3, 2, 4, 5)
        x_163 = None
        contiguous_56 = permute_59.contiguous()
        permute_59 = None
        x_164 = contiguous_56.view(1, 21, 14, -1)
        contiguous_56 = None
        getitem_64 = x_164[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_164 = None
        x_165 = getitem_64.contiguous()
        getitem_64 = None
        x_166 = x_165.view(1, 192, 512)
        x_165 = None
        x_167 = x_166 + output_11
        x_166 = output_11 = None
        x_168 = torch.nn.functional.layer_norm(
            x_167,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_norm2_parameters_bias_ = (None)
        input_61 = torch._C._nn.linear(
            x_168,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_168 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_62 = torch._C._nn.gelu(input_61, approximate="none")
        input_61 = None
        input_63 = torch.nn.functional.dropout(input_62, 0.0, False, False)
        input_62 = None
        input_64 = torch._C._nn.linear(
            input_63,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_63 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_8_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_65 = torch.nn.functional.dropout(input_64, 0.0, False, False)
        input_64 = None
        output_12 = x_167 + input_65
        x_167 = input_65 = None
        x_169 = torch.nn.functional.layer_norm(
            output_12,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm1_parameters_bias_ = (None)
        query_26 = x_169.view(1, 16, 12, 512)
        x_169 = None
        query_27 = torch._C._nn.pad(query_26, (0, 0, 0, 2, 0, 5), "constant", None)
        query_26 = None
        shifted_query_6 = torch.roll(query_27, shifts=(-3, -3), dims=(1, 2))
        query_27 = None
        img_mask_6 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_6[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_54 = img_mask_6
        setitem_54 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_55 = img_mask_6
        setitem_55 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_56 = img_mask_6
        setitem_56 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_57 = img_mask_6
        setitem_57 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_58 = img_mask_6
        setitem_58 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_59 = img_mask_6
        setitem_59 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_60 = img_mask_6
        setitem_60 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_61 = img_mask_6
        setitem_61 = None
        img_mask_6[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_62 = img_mask_6
        setitem_62 = None
        x_170 = img_mask_6.view(1, 3, 7, 2, 7, 1)
        img_mask_6 = None
        permute_60 = x_170.permute(0, 1, 3, 2, 4, 5)
        x_170 = None
        windows_38 = permute_60.contiguous()
        permute_60 = None
        windows_39 = windows_38.view(-1, 7, 7, 1)
        windows_38 = None
        mask_windows_6 = windows_39.view(-1, 49)
        windows_39 = None
        unsqueeze_37 = mask_windows_6.unsqueeze(1)
        unsqueeze_38 = mask_windows_6.unsqueeze(2)
        mask_windows_6 = None
        attn_mask_12 = unsqueeze_37 - unsqueeze_38
        unsqueeze_37 = unsqueeze_38 = None
        ne_6 = attn_mask_12 != 0
        masked_fill_12 = attn_mask_12.masked_fill(ne_6, -100.0)
        ne_6 = None
        eq_6 = attn_mask_12 == 0
        attn_mask_12 = None
        attn_mask_13 = masked_fill_12.masked_fill(eq_6, 0.0)
        masked_fill_12 = eq_6 = None
        x_171 = shifted_query_6.view(1, 3, 7, 2, 7, 512)
        shifted_query_6 = None
        permute_61 = x_171.permute(0, 1, 3, 2, 4, 5)
        x_171 = None
        windows_40 = permute_61.contiguous()
        permute_61 = None
        windows_41 = windows_40.view(-1, 7, 7, 512)
        windows_40 = None
        query_windows_13 = windows_41.view(-1, 49, 512)
        windows_41 = None
        linear_54 = torch._C._nn.linear(
            query_windows_13,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_13 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_26 = linear_54.reshape(6, 49, 3, 16, 32)
        linear_54 = None
        qkv_13 = reshape_26.permute(2, 0, 3, 1, 4)
        reshape_26 = None
        q_26 = qkv_13[0]
        k_13 = qkv_13[1]
        v_13 = qkv_13[2]
        qkv_13 = None
        q_27 = q_26 * 0.1767766952966369
        q_26 = None
        transpose_29 = k_13.transpose(-2, -1)
        k_13 = None
        attn_64 = q_27 @ transpose_29
        q_27 = transpose_29 = None
        view_169 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_68 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_169
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_169
        ) = None
        relative_position_bias_26 = getitem_68.view(49, 49, -1)
        getitem_68 = None
        permute_63 = relative_position_bias_26.permute(2, 0, 1)
        relative_position_bias_26 = None
        relative_position_bias_27 = permute_63.contiguous()
        permute_63 = None
        unsqueeze_39 = relative_position_bias_27.unsqueeze(0)
        relative_position_bias_27 = None
        attn_65 = attn_64 + unsqueeze_39
        attn_64 = unsqueeze_39 = None
        view_171 = attn_65.view(1, 6, 16, 49, 49)
        attn_65 = None
        unsqueeze_40 = attn_mask_13.unsqueeze(1)
        attn_mask_13 = None
        unsqueeze_41 = unsqueeze_40.unsqueeze(0)
        unsqueeze_40 = None
        attn_66 = view_171 + unsqueeze_41
        view_171 = unsqueeze_41 = None
        attn_67 = attn_66.view(-1, 16, 49, 49)
        attn_66 = None
        attn_68 = torch.nn.functional.softmax(attn_67, -1, _stacklevel=5)
        attn_67 = None
        attn_69 = torch.nn.functional.dropout(attn_68, 0.0, False, False)
        attn_68 = None
        matmul_27 = attn_69 @ v_13
        attn_69 = v_13 = None
        transpose_30 = matmul_27.transpose(1, 2)
        matmul_27 = None
        x_172 = transpose_30.reshape(6, 49, 512)
        transpose_30 = None
        x_173 = torch._C._nn.linear(
            x_172,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_172 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_174 = torch.nn.functional.dropout(x_173, 0.0, False, False)
        x_173 = None
        attn_windows_13 = x_174.view(-1, 7, 7, 512)
        x_174 = None
        x_175 = attn_windows_13.view(1, 3, 2, 7, 7, -1)
        attn_windows_13 = None
        permute_64 = x_175.permute(0, 1, 3, 2, 4, 5)
        x_175 = None
        contiguous_61 = permute_64.contiguous()
        permute_64 = None
        x_176 = contiguous_61.view(1, 21, 14, -1)
        contiguous_61 = None
        x_177 = torch.roll(x_176, shifts=(3, 3), dims=(1, 2))
        x_176 = None
        getitem_69 = x_177[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_177 = None
        x_178 = getitem_69.contiguous()
        getitem_69 = None
        x_179 = x_178.view(1, 192, 512)
        x_178 = None
        x_180 = x_179 + output_12
        x_179 = output_12 = None
        x_181 = torch.nn.functional.layer_norm(
            x_180,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_norm2_parameters_bias_ = (None)
        input_66 = torch._C._nn.linear(
            x_181,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_181 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_67 = torch._C._nn.gelu(input_66, approximate="none")
        input_66 = None
        input_68 = torch.nn.functional.dropout(input_67, 0.0, False, False)
        input_67 = None
        input_69 = torch._C._nn.linear(
            input_68,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_68 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_9_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_70 = torch.nn.functional.dropout(input_69, 0.0, False, False)
        input_69 = None
        output_13 = x_180 + input_70
        x_180 = input_70 = None
        x_182 = torch.nn.functional.layer_norm(
            output_13,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm1_parameters_bias_ = (None)
        query_28 = x_182.view(1, 16, 12, 512)
        x_182 = None
        query_29 = torch._C._nn.pad(query_28, (0, 0, 0, 2, 0, 5), "constant", None)
        query_28 = None
        x_183 = query_29.view(1, 3, 7, 2, 7, 512)
        query_29 = None
        permute_65 = x_183.permute(0, 1, 3, 2, 4, 5)
        x_183 = None
        windows_42 = permute_65.contiguous()
        permute_65 = None
        windows_43 = windows_42.view(-1, 7, 7, 512)
        windows_42 = None
        query_windows_14 = windows_43.view(-1, 49, 512)
        windows_43 = None
        linear_58 = torch._C._nn.linear(
            query_windows_14,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_14 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_28 = linear_58.reshape(6, 49, 3, 16, 32)
        linear_58 = None
        qkv_14 = reshape_28.permute(2, 0, 3, 1, 4)
        reshape_28 = None
        q_28 = qkv_14[0]
        k_14 = qkv_14[1]
        v_14 = qkv_14[2]
        qkv_14 = None
        q_29 = q_28 * 0.1767766952966369
        q_28 = None
        transpose_31 = k_14.transpose(-2, -1)
        k_14 = None
        attn_70 = q_29 @ transpose_31
        q_29 = transpose_31 = None
        view_181 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_73 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_181
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_181
        ) = None
        relative_position_bias_28 = getitem_73.view(49, 49, -1)
        getitem_73 = None
        permute_67 = relative_position_bias_28.permute(2, 0, 1)
        relative_position_bias_28 = None
        relative_position_bias_29 = permute_67.contiguous()
        permute_67 = None
        unsqueeze_42 = relative_position_bias_29.unsqueeze(0)
        relative_position_bias_29 = None
        attn_71 = attn_70 + unsqueeze_42
        attn_70 = unsqueeze_42 = None
        attn_72 = torch.nn.functional.softmax(attn_71, -1, _stacklevel=5)
        attn_71 = None
        attn_73 = torch.nn.functional.dropout(attn_72, 0.0, False, False)
        attn_72 = None
        matmul_29 = attn_73 @ v_14
        attn_73 = v_14 = None
        transpose_32 = matmul_29.transpose(1, 2)
        matmul_29 = None
        x_184 = transpose_32.reshape(6, 49, 512)
        transpose_32 = None
        x_185 = torch._C._nn.linear(
            x_184,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_184 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_186 = torch.nn.functional.dropout(x_185, 0.0, False, False)
        x_185 = None
        attn_windows_14 = x_186.view(-1, 7, 7, 512)
        x_186 = None
        x_187 = attn_windows_14.view(1, 3, 2, 7, 7, -1)
        attn_windows_14 = None
        permute_68 = x_187.permute(0, 1, 3, 2, 4, 5)
        x_187 = None
        contiguous_65 = permute_68.contiguous()
        permute_68 = None
        x_188 = contiguous_65.view(1, 21, 14, -1)
        contiguous_65 = None
        getitem_74 = x_188[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_188 = None
        x_189 = getitem_74.contiguous()
        getitem_74 = None
        x_190 = x_189.view(1, 192, 512)
        x_189 = None
        x_191 = x_190 + output_13
        x_190 = output_13 = None
        x_192 = torch.nn.functional.layer_norm(
            x_191,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_norm2_parameters_bias_ = (None)
        input_71 = torch._C._nn.linear(
            x_192,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_192 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_72 = torch._C._nn.gelu(input_71, approximate="none")
        input_71 = None
        input_73 = torch.nn.functional.dropout(input_72, 0.0, False, False)
        input_72 = None
        input_74 = torch._C._nn.linear(
            input_73,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_73 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_10_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_75 = torch.nn.functional.dropout(input_74, 0.0, False, False)
        input_74 = None
        output_14 = x_191 + input_75
        x_191 = input_75 = None
        x_193 = torch.nn.functional.layer_norm(
            output_14,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm1_parameters_bias_ = (None)
        query_30 = x_193.view(1, 16, 12, 512)
        x_193 = None
        query_31 = torch._C._nn.pad(query_30, (0, 0, 0, 2, 0, 5), "constant", None)
        query_30 = None
        shifted_query_7 = torch.roll(query_31, shifts=(-3, -3), dims=(1, 2))
        query_31 = None
        img_mask_7 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_7[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_63 = img_mask_7
        setitem_63 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_64 = img_mask_7
        setitem_64 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_65 = img_mask_7
        setitem_65 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_66 = img_mask_7
        setitem_66 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_67 = img_mask_7
        setitem_67 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_68 = img_mask_7
        setitem_68 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_69 = img_mask_7
        setitem_69 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_70 = img_mask_7
        setitem_70 = None
        img_mask_7[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_71 = img_mask_7
        setitem_71 = None
        x_194 = img_mask_7.view(1, 3, 7, 2, 7, 1)
        img_mask_7 = None
        permute_69 = x_194.permute(0, 1, 3, 2, 4, 5)
        x_194 = None
        windows_44 = permute_69.contiguous()
        permute_69 = None
        windows_45 = windows_44.view(-1, 7, 7, 1)
        windows_44 = None
        mask_windows_7 = windows_45.view(-1, 49)
        windows_45 = None
        unsqueeze_43 = mask_windows_7.unsqueeze(1)
        unsqueeze_44 = mask_windows_7.unsqueeze(2)
        mask_windows_7 = None
        attn_mask_14 = unsqueeze_43 - unsqueeze_44
        unsqueeze_43 = unsqueeze_44 = None
        ne_7 = attn_mask_14 != 0
        masked_fill_14 = attn_mask_14.masked_fill(ne_7, -100.0)
        ne_7 = None
        eq_7 = attn_mask_14 == 0
        attn_mask_14 = None
        attn_mask_15 = masked_fill_14.masked_fill(eq_7, 0.0)
        masked_fill_14 = eq_7 = None
        x_195 = shifted_query_7.view(1, 3, 7, 2, 7, 512)
        shifted_query_7 = None
        permute_70 = x_195.permute(0, 1, 3, 2, 4, 5)
        x_195 = None
        windows_46 = permute_70.contiguous()
        permute_70 = None
        windows_47 = windows_46.view(-1, 7, 7, 512)
        windows_46 = None
        query_windows_15 = windows_47.view(-1, 49, 512)
        windows_47 = None
        linear_62 = torch._C._nn.linear(
            query_windows_15,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_15 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_30 = linear_62.reshape(6, 49, 3, 16, 32)
        linear_62 = None
        qkv_15 = reshape_30.permute(2, 0, 3, 1, 4)
        reshape_30 = None
        q_30 = qkv_15[0]
        k_15 = qkv_15[1]
        v_15 = qkv_15[2]
        qkv_15 = None
        q_31 = q_30 * 0.1767766952966369
        q_30 = None
        transpose_33 = k_15.transpose(-2, -1)
        k_15 = None
        attn_74 = q_31 @ transpose_33
        q_31 = transpose_33 = None
        view_194 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_78 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_194
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_194
        ) = None
        relative_position_bias_30 = getitem_78.view(49, 49, -1)
        getitem_78 = None
        permute_72 = relative_position_bias_30.permute(2, 0, 1)
        relative_position_bias_30 = None
        relative_position_bias_31 = permute_72.contiguous()
        permute_72 = None
        unsqueeze_45 = relative_position_bias_31.unsqueeze(0)
        relative_position_bias_31 = None
        attn_75 = attn_74 + unsqueeze_45
        attn_74 = unsqueeze_45 = None
        view_196 = attn_75.view(1, 6, 16, 49, 49)
        attn_75 = None
        unsqueeze_46 = attn_mask_15.unsqueeze(1)
        attn_mask_15 = None
        unsqueeze_47 = unsqueeze_46.unsqueeze(0)
        unsqueeze_46 = None
        attn_76 = view_196 + unsqueeze_47
        view_196 = unsqueeze_47 = None
        attn_77 = attn_76.view(-1, 16, 49, 49)
        attn_76 = None
        attn_78 = torch.nn.functional.softmax(attn_77, -1, _stacklevel=5)
        attn_77 = None
        attn_79 = torch.nn.functional.dropout(attn_78, 0.0, False, False)
        attn_78 = None
        matmul_31 = attn_79 @ v_15
        attn_79 = v_15 = None
        transpose_34 = matmul_31.transpose(1, 2)
        matmul_31 = None
        x_196 = transpose_34.reshape(6, 49, 512)
        transpose_34 = None
        x_197 = torch._C._nn.linear(
            x_196,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_196 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_198 = torch.nn.functional.dropout(x_197, 0.0, False, False)
        x_197 = None
        attn_windows_15 = x_198.view(-1, 7, 7, 512)
        x_198 = None
        x_199 = attn_windows_15.view(1, 3, 2, 7, 7, -1)
        attn_windows_15 = None
        permute_73 = x_199.permute(0, 1, 3, 2, 4, 5)
        x_199 = None
        contiguous_70 = permute_73.contiguous()
        permute_73 = None
        x_200 = contiguous_70.view(1, 21, 14, -1)
        contiguous_70 = None
        x_201 = torch.roll(x_200, shifts=(3, 3), dims=(1, 2))
        x_200 = None
        getitem_79 = x_201[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_201 = None
        x_202 = getitem_79.contiguous()
        getitem_79 = None
        x_203 = x_202.view(1, 192, 512)
        x_202 = None
        x_204 = x_203 + output_14
        x_203 = output_14 = None
        x_205 = torch.nn.functional.layer_norm(
            x_204,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_norm2_parameters_bias_ = (None)
        input_76 = torch._C._nn.linear(
            x_205,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_205 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_77 = torch._C._nn.gelu(input_76, approximate="none")
        input_76 = None
        input_78 = torch.nn.functional.dropout(input_77, 0.0, False, False)
        input_77 = None
        input_79 = torch._C._nn.linear(
            input_78,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_78 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_11_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_80 = torch.nn.functional.dropout(input_79, 0.0, False, False)
        input_79 = None
        output_15 = x_204 + input_80
        x_204 = input_80 = None
        x_206 = torch.nn.functional.layer_norm(
            output_15,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm1_parameters_bias_ = (None)
        query_32 = x_206.view(1, 16, 12, 512)
        x_206 = None
        query_33 = torch._C._nn.pad(query_32, (0, 0, 0, 2, 0, 5), "constant", None)
        query_32 = None
        x_207 = query_33.view(1, 3, 7, 2, 7, 512)
        query_33 = None
        permute_74 = x_207.permute(0, 1, 3, 2, 4, 5)
        x_207 = None
        windows_48 = permute_74.contiguous()
        permute_74 = None
        windows_49 = windows_48.view(-1, 7, 7, 512)
        windows_48 = None
        query_windows_16 = windows_49.view(-1, 49, 512)
        windows_49 = None
        linear_66 = torch._C._nn.linear(
            query_windows_16,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_16 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_32 = linear_66.reshape(6, 49, 3, 16, 32)
        linear_66 = None
        qkv_16 = reshape_32.permute(2, 0, 3, 1, 4)
        reshape_32 = None
        q_32 = qkv_16[0]
        k_16 = qkv_16[1]
        v_16 = qkv_16[2]
        qkv_16 = None
        q_33 = q_32 * 0.1767766952966369
        q_32 = None
        transpose_35 = k_16.transpose(-2, -1)
        k_16 = None
        attn_80 = q_33 @ transpose_35
        q_33 = transpose_35 = None
        view_206 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_83 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_206
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_206
        ) = None
        relative_position_bias_32 = getitem_83.view(49, 49, -1)
        getitem_83 = None
        permute_76 = relative_position_bias_32.permute(2, 0, 1)
        relative_position_bias_32 = None
        relative_position_bias_33 = permute_76.contiguous()
        permute_76 = None
        unsqueeze_48 = relative_position_bias_33.unsqueeze(0)
        relative_position_bias_33 = None
        attn_81 = attn_80 + unsqueeze_48
        attn_80 = unsqueeze_48 = None
        attn_82 = torch.nn.functional.softmax(attn_81, -1, _stacklevel=5)
        attn_81 = None
        attn_83 = torch.nn.functional.dropout(attn_82, 0.0, False, False)
        attn_82 = None
        matmul_33 = attn_83 @ v_16
        attn_83 = v_16 = None
        transpose_36 = matmul_33.transpose(1, 2)
        matmul_33 = None
        x_208 = transpose_36.reshape(6, 49, 512)
        transpose_36 = None
        x_209 = torch._C._nn.linear(
            x_208,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_208 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_210 = torch.nn.functional.dropout(x_209, 0.0, False, False)
        x_209 = None
        attn_windows_16 = x_210.view(-1, 7, 7, 512)
        x_210 = None
        x_211 = attn_windows_16.view(1, 3, 2, 7, 7, -1)
        attn_windows_16 = None
        permute_77 = x_211.permute(0, 1, 3, 2, 4, 5)
        x_211 = None
        contiguous_74 = permute_77.contiguous()
        permute_77 = None
        x_212 = contiguous_74.view(1, 21, 14, -1)
        contiguous_74 = None
        getitem_84 = x_212[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_212 = None
        x_213 = getitem_84.contiguous()
        getitem_84 = None
        x_214 = x_213.view(1, 192, 512)
        x_213 = None
        x_215 = x_214 + output_15
        x_214 = output_15 = None
        x_216 = torch.nn.functional.layer_norm(
            x_215,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_norm2_parameters_bias_ = (None)
        input_81 = torch._C._nn.linear(
            x_216,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_216 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_82 = torch._C._nn.gelu(input_81, approximate="none")
        input_81 = None
        input_83 = torch.nn.functional.dropout(input_82, 0.0, False, False)
        input_82 = None
        input_84 = torch._C._nn.linear(
            input_83,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_83 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_12_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_85 = torch.nn.functional.dropout(input_84, 0.0, False, False)
        input_84 = None
        output_16 = x_215 + input_85
        x_215 = input_85 = None
        x_217 = torch.nn.functional.layer_norm(
            output_16,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm1_parameters_bias_ = (None)
        query_34 = x_217.view(1, 16, 12, 512)
        x_217 = None
        query_35 = torch._C._nn.pad(query_34, (0, 0, 0, 2, 0, 5), "constant", None)
        query_34 = None
        shifted_query_8 = torch.roll(query_35, shifts=(-3, -3), dims=(1, 2))
        query_35 = None
        img_mask_8 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_8[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_72 = img_mask_8
        setitem_72 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_73 = img_mask_8
        setitem_73 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_74 = img_mask_8
        setitem_74 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_75 = img_mask_8
        setitem_75 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_76 = img_mask_8
        setitem_76 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_77 = img_mask_8
        setitem_77 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_78 = img_mask_8
        setitem_78 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_79 = img_mask_8
        setitem_79 = None
        img_mask_8[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_80 = img_mask_8
        setitem_80 = None
        x_218 = img_mask_8.view(1, 3, 7, 2, 7, 1)
        img_mask_8 = None
        permute_78 = x_218.permute(0, 1, 3, 2, 4, 5)
        x_218 = None
        windows_50 = permute_78.contiguous()
        permute_78 = None
        windows_51 = windows_50.view(-1, 7, 7, 1)
        windows_50 = None
        mask_windows_8 = windows_51.view(-1, 49)
        windows_51 = None
        unsqueeze_49 = mask_windows_8.unsqueeze(1)
        unsqueeze_50 = mask_windows_8.unsqueeze(2)
        mask_windows_8 = None
        attn_mask_16 = unsqueeze_49 - unsqueeze_50
        unsqueeze_49 = unsqueeze_50 = None
        ne_8 = attn_mask_16 != 0
        masked_fill_16 = attn_mask_16.masked_fill(ne_8, -100.0)
        ne_8 = None
        eq_8 = attn_mask_16 == 0
        attn_mask_16 = None
        attn_mask_17 = masked_fill_16.masked_fill(eq_8, 0.0)
        masked_fill_16 = eq_8 = None
        x_219 = shifted_query_8.view(1, 3, 7, 2, 7, 512)
        shifted_query_8 = None
        permute_79 = x_219.permute(0, 1, 3, 2, 4, 5)
        x_219 = None
        windows_52 = permute_79.contiguous()
        permute_79 = None
        windows_53 = windows_52.view(-1, 7, 7, 512)
        windows_52 = None
        query_windows_17 = windows_53.view(-1, 49, 512)
        windows_53 = None
        linear_70 = torch._C._nn.linear(
            query_windows_17,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_17 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_34 = linear_70.reshape(6, 49, 3, 16, 32)
        linear_70 = None
        qkv_17 = reshape_34.permute(2, 0, 3, 1, 4)
        reshape_34 = None
        q_34 = qkv_17[0]
        k_17 = qkv_17[1]
        v_17 = qkv_17[2]
        qkv_17 = None
        q_35 = q_34 * 0.1767766952966369
        q_34 = None
        transpose_37 = k_17.transpose(-2, -1)
        k_17 = None
        attn_84 = q_35 @ transpose_37
        q_35 = transpose_37 = None
        view_219 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_88 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_219
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_219
        ) = None
        relative_position_bias_34 = getitem_88.view(49, 49, -1)
        getitem_88 = None
        permute_81 = relative_position_bias_34.permute(2, 0, 1)
        relative_position_bias_34 = None
        relative_position_bias_35 = permute_81.contiguous()
        permute_81 = None
        unsqueeze_51 = relative_position_bias_35.unsqueeze(0)
        relative_position_bias_35 = None
        attn_85 = attn_84 + unsqueeze_51
        attn_84 = unsqueeze_51 = None
        view_221 = attn_85.view(1, 6, 16, 49, 49)
        attn_85 = None
        unsqueeze_52 = attn_mask_17.unsqueeze(1)
        attn_mask_17 = None
        unsqueeze_53 = unsqueeze_52.unsqueeze(0)
        unsqueeze_52 = None
        attn_86 = view_221 + unsqueeze_53
        view_221 = unsqueeze_53 = None
        attn_87 = attn_86.view(-1, 16, 49, 49)
        attn_86 = None
        attn_88 = torch.nn.functional.softmax(attn_87, -1, _stacklevel=5)
        attn_87 = None
        attn_89 = torch.nn.functional.dropout(attn_88, 0.0, False, False)
        attn_88 = None
        matmul_35 = attn_89 @ v_17
        attn_89 = v_17 = None
        transpose_38 = matmul_35.transpose(1, 2)
        matmul_35 = None
        x_220 = transpose_38.reshape(6, 49, 512)
        transpose_38 = None
        x_221 = torch._C._nn.linear(
            x_220,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_220 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_222 = torch.nn.functional.dropout(x_221, 0.0, False, False)
        x_221 = None
        attn_windows_17 = x_222.view(-1, 7, 7, 512)
        x_222 = None
        x_223 = attn_windows_17.view(1, 3, 2, 7, 7, -1)
        attn_windows_17 = None
        permute_82 = x_223.permute(0, 1, 3, 2, 4, 5)
        x_223 = None
        contiguous_79 = permute_82.contiguous()
        permute_82 = None
        x_224 = contiguous_79.view(1, 21, 14, -1)
        contiguous_79 = None
        x_225 = torch.roll(x_224, shifts=(3, 3), dims=(1, 2))
        x_224 = None
        getitem_89 = x_225[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_225 = None
        x_226 = getitem_89.contiguous()
        getitem_89 = None
        x_227 = x_226.view(1, 192, 512)
        x_226 = None
        x_228 = x_227 + output_16
        x_227 = output_16 = None
        x_229 = torch.nn.functional.layer_norm(
            x_228,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_norm2_parameters_bias_ = (None)
        input_86 = torch._C._nn.linear(
            x_229,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_229 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_87 = torch._C._nn.gelu(input_86, approximate="none")
        input_86 = None
        input_88 = torch.nn.functional.dropout(input_87, 0.0, False, False)
        input_87 = None
        input_89 = torch._C._nn.linear(
            input_88,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_88 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_13_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_90 = torch.nn.functional.dropout(input_89, 0.0, False, False)
        input_89 = None
        output_17 = x_228 + input_90
        x_228 = input_90 = None
        x_230 = torch.nn.functional.layer_norm(
            output_17,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm1_parameters_bias_ = (None)
        query_36 = x_230.view(1, 16, 12, 512)
        x_230 = None
        query_37 = torch._C._nn.pad(query_36, (0, 0, 0, 2, 0, 5), "constant", None)
        query_36 = None
        x_231 = query_37.view(1, 3, 7, 2, 7, 512)
        query_37 = None
        permute_83 = x_231.permute(0, 1, 3, 2, 4, 5)
        x_231 = None
        windows_54 = permute_83.contiguous()
        permute_83 = None
        windows_55 = windows_54.view(-1, 7, 7, 512)
        windows_54 = None
        query_windows_18 = windows_55.view(-1, 49, 512)
        windows_55 = None
        linear_74 = torch._C._nn.linear(
            query_windows_18,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_18 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_36 = linear_74.reshape(6, 49, 3, 16, 32)
        linear_74 = None
        qkv_18 = reshape_36.permute(2, 0, 3, 1, 4)
        reshape_36 = None
        q_36 = qkv_18[0]
        k_18 = qkv_18[1]
        v_18 = qkv_18[2]
        qkv_18 = None
        q_37 = q_36 * 0.1767766952966369
        q_36 = None
        transpose_39 = k_18.transpose(-2, -1)
        k_18 = None
        attn_90 = q_37 @ transpose_39
        q_37 = transpose_39 = None
        view_231 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_93 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_231
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_231
        ) = None
        relative_position_bias_36 = getitem_93.view(49, 49, -1)
        getitem_93 = None
        permute_85 = relative_position_bias_36.permute(2, 0, 1)
        relative_position_bias_36 = None
        relative_position_bias_37 = permute_85.contiguous()
        permute_85 = None
        unsqueeze_54 = relative_position_bias_37.unsqueeze(0)
        relative_position_bias_37 = None
        attn_91 = attn_90 + unsqueeze_54
        attn_90 = unsqueeze_54 = None
        attn_92 = torch.nn.functional.softmax(attn_91, -1, _stacklevel=5)
        attn_91 = None
        attn_93 = torch.nn.functional.dropout(attn_92, 0.0, False, False)
        attn_92 = None
        matmul_37 = attn_93 @ v_18
        attn_93 = v_18 = None
        transpose_40 = matmul_37.transpose(1, 2)
        matmul_37 = None
        x_232 = transpose_40.reshape(6, 49, 512)
        transpose_40 = None
        x_233 = torch._C._nn.linear(
            x_232,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_232 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_234 = torch.nn.functional.dropout(x_233, 0.0, False, False)
        x_233 = None
        attn_windows_18 = x_234.view(-1, 7, 7, 512)
        x_234 = None
        x_235 = attn_windows_18.view(1, 3, 2, 7, 7, -1)
        attn_windows_18 = None
        permute_86 = x_235.permute(0, 1, 3, 2, 4, 5)
        x_235 = None
        contiguous_83 = permute_86.contiguous()
        permute_86 = None
        x_236 = contiguous_83.view(1, 21, 14, -1)
        contiguous_83 = None
        getitem_94 = x_236[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_236 = None
        x_237 = getitem_94.contiguous()
        getitem_94 = None
        x_238 = x_237.view(1, 192, 512)
        x_237 = None
        x_239 = x_238 + output_17
        x_238 = output_17 = None
        x_240 = torch.nn.functional.layer_norm(
            x_239,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_norm2_parameters_bias_ = (None)
        input_91 = torch._C._nn.linear(
            x_240,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_240 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_92 = torch._C._nn.gelu(input_91, approximate="none")
        input_91 = None
        input_93 = torch.nn.functional.dropout(input_92, 0.0, False, False)
        input_92 = None
        input_94 = torch._C._nn.linear(
            input_93,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_93 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_14_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_95 = torch.nn.functional.dropout(input_94, 0.0, False, False)
        input_94 = None
        output_18 = x_239 + input_95
        x_239 = input_95 = None
        x_241 = torch.nn.functional.layer_norm(
            output_18,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm1_parameters_bias_ = (None)
        query_38 = x_241.view(1, 16, 12, 512)
        x_241 = None
        query_39 = torch._C._nn.pad(query_38, (0, 0, 0, 2, 0, 5), "constant", None)
        query_38 = None
        shifted_query_9 = torch.roll(query_39, shifts=(-3, -3), dims=(1, 2))
        query_39 = None
        img_mask_9 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_9[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_81 = img_mask_9
        setitem_81 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_82 = img_mask_9
        setitem_82 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_83 = img_mask_9
        setitem_83 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_84 = img_mask_9
        setitem_84 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_85 = img_mask_9
        setitem_85 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_86 = img_mask_9
        setitem_86 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_87 = img_mask_9
        setitem_87 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_88 = img_mask_9
        setitem_88 = None
        img_mask_9[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_89 = img_mask_9
        setitem_89 = None
        x_242 = img_mask_9.view(1, 3, 7, 2, 7, 1)
        img_mask_9 = None
        permute_87 = x_242.permute(0, 1, 3, 2, 4, 5)
        x_242 = None
        windows_56 = permute_87.contiguous()
        permute_87 = None
        windows_57 = windows_56.view(-1, 7, 7, 1)
        windows_56 = None
        mask_windows_9 = windows_57.view(-1, 49)
        windows_57 = None
        unsqueeze_55 = mask_windows_9.unsqueeze(1)
        unsqueeze_56 = mask_windows_9.unsqueeze(2)
        mask_windows_9 = None
        attn_mask_18 = unsqueeze_55 - unsqueeze_56
        unsqueeze_55 = unsqueeze_56 = None
        ne_9 = attn_mask_18 != 0
        masked_fill_18 = attn_mask_18.masked_fill(ne_9, -100.0)
        ne_9 = None
        eq_9 = attn_mask_18 == 0
        attn_mask_18 = None
        attn_mask_19 = masked_fill_18.masked_fill(eq_9, 0.0)
        masked_fill_18 = eq_9 = None
        x_243 = shifted_query_9.view(1, 3, 7, 2, 7, 512)
        shifted_query_9 = None
        permute_88 = x_243.permute(0, 1, 3, 2, 4, 5)
        x_243 = None
        windows_58 = permute_88.contiguous()
        permute_88 = None
        windows_59 = windows_58.view(-1, 7, 7, 512)
        windows_58 = None
        query_windows_19 = windows_59.view(-1, 49, 512)
        windows_59 = None
        linear_78 = torch._C._nn.linear(
            query_windows_19,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_19 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_38 = linear_78.reshape(6, 49, 3, 16, 32)
        linear_78 = None
        qkv_19 = reshape_38.permute(2, 0, 3, 1, 4)
        reshape_38 = None
        q_38 = qkv_19[0]
        k_19 = qkv_19[1]
        v_19 = qkv_19[2]
        qkv_19 = None
        q_39 = q_38 * 0.1767766952966369
        q_38 = None
        transpose_41 = k_19.transpose(-2, -1)
        k_19 = None
        attn_94 = q_39 @ transpose_41
        q_39 = transpose_41 = None
        view_244 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_98 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_244
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_244
        ) = None
        relative_position_bias_38 = getitem_98.view(49, 49, -1)
        getitem_98 = None
        permute_90 = relative_position_bias_38.permute(2, 0, 1)
        relative_position_bias_38 = None
        relative_position_bias_39 = permute_90.contiguous()
        permute_90 = None
        unsqueeze_57 = relative_position_bias_39.unsqueeze(0)
        relative_position_bias_39 = None
        attn_95 = attn_94 + unsqueeze_57
        attn_94 = unsqueeze_57 = None
        view_246 = attn_95.view(1, 6, 16, 49, 49)
        attn_95 = None
        unsqueeze_58 = attn_mask_19.unsqueeze(1)
        attn_mask_19 = None
        unsqueeze_59 = unsqueeze_58.unsqueeze(0)
        unsqueeze_58 = None
        attn_96 = view_246 + unsqueeze_59
        view_246 = unsqueeze_59 = None
        attn_97 = attn_96.view(-1, 16, 49, 49)
        attn_96 = None
        attn_98 = torch.nn.functional.softmax(attn_97, -1, _stacklevel=5)
        attn_97 = None
        attn_99 = torch.nn.functional.dropout(attn_98, 0.0, False, False)
        attn_98 = None
        matmul_39 = attn_99 @ v_19
        attn_99 = v_19 = None
        transpose_42 = matmul_39.transpose(1, 2)
        matmul_39 = None
        x_244 = transpose_42.reshape(6, 49, 512)
        transpose_42 = None
        x_245 = torch._C._nn.linear(
            x_244,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_244 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_246 = torch.nn.functional.dropout(x_245, 0.0, False, False)
        x_245 = None
        attn_windows_19 = x_246.view(-1, 7, 7, 512)
        x_246 = None
        x_247 = attn_windows_19.view(1, 3, 2, 7, 7, -1)
        attn_windows_19 = None
        permute_91 = x_247.permute(0, 1, 3, 2, 4, 5)
        x_247 = None
        contiguous_88 = permute_91.contiguous()
        permute_91 = None
        x_248 = contiguous_88.view(1, 21, 14, -1)
        contiguous_88 = None
        x_249 = torch.roll(x_248, shifts=(3, 3), dims=(1, 2))
        x_248 = None
        getitem_99 = x_249[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_249 = None
        x_250 = getitem_99.contiguous()
        getitem_99 = None
        x_251 = x_250.view(1, 192, 512)
        x_250 = None
        x_252 = x_251 + output_18
        x_251 = output_18 = None
        x_253 = torch.nn.functional.layer_norm(
            x_252,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_norm2_parameters_bias_ = (None)
        input_96 = torch._C._nn.linear(
            x_253,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_253 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_97 = torch._C._nn.gelu(input_96, approximate="none")
        input_96 = None
        input_98 = torch.nn.functional.dropout(input_97, 0.0, False, False)
        input_97 = None
        input_99 = torch._C._nn.linear(
            input_98,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_98 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_15_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_100 = torch.nn.functional.dropout(input_99, 0.0, False, False)
        input_99 = None
        output_19 = x_252 + input_100
        x_252 = input_100 = None
        x_254 = torch.nn.functional.layer_norm(
            output_19,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm1_parameters_bias_ = (None)
        query_40 = x_254.view(1, 16, 12, 512)
        x_254 = None
        query_41 = torch._C._nn.pad(query_40, (0, 0, 0, 2, 0, 5), "constant", None)
        query_40 = None
        x_255 = query_41.view(1, 3, 7, 2, 7, 512)
        query_41 = None
        permute_92 = x_255.permute(0, 1, 3, 2, 4, 5)
        x_255 = None
        windows_60 = permute_92.contiguous()
        permute_92 = None
        windows_61 = windows_60.view(-1, 7, 7, 512)
        windows_60 = None
        query_windows_20 = windows_61.view(-1, 49, 512)
        windows_61 = None
        linear_82 = torch._C._nn.linear(
            query_windows_20,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_20 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_40 = linear_82.reshape(6, 49, 3, 16, 32)
        linear_82 = None
        qkv_20 = reshape_40.permute(2, 0, 3, 1, 4)
        reshape_40 = None
        q_40 = qkv_20[0]
        k_20 = qkv_20[1]
        v_20 = qkv_20[2]
        qkv_20 = None
        q_41 = q_40 * 0.1767766952966369
        q_40 = None
        transpose_43 = k_20.transpose(-2, -1)
        k_20 = None
        attn_100 = q_41 @ transpose_43
        q_41 = transpose_43 = None
        view_256 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_103 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_256
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_256
        ) = None
        relative_position_bias_40 = getitem_103.view(49, 49, -1)
        getitem_103 = None
        permute_94 = relative_position_bias_40.permute(2, 0, 1)
        relative_position_bias_40 = None
        relative_position_bias_41 = permute_94.contiguous()
        permute_94 = None
        unsqueeze_60 = relative_position_bias_41.unsqueeze(0)
        relative_position_bias_41 = None
        attn_101 = attn_100 + unsqueeze_60
        attn_100 = unsqueeze_60 = None
        attn_102 = torch.nn.functional.softmax(attn_101, -1, _stacklevel=5)
        attn_101 = None
        attn_103 = torch.nn.functional.dropout(attn_102, 0.0, False, False)
        attn_102 = None
        matmul_41 = attn_103 @ v_20
        attn_103 = v_20 = None
        transpose_44 = matmul_41.transpose(1, 2)
        matmul_41 = None
        x_256 = transpose_44.reshape(6, 49, 512)
        transpose_44 = None
        x_257 = torch._C._nn.linear(
            x_256,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_256 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_258 = torch.nn.functional.dropout(x_257, 0.0, False, False)
        x_257 = None
        attn_windows_20 = x_258.view(-1, 7, 7, 512)
        x_258 = None
        x_259 = attn_windows_20.view(1, 3, 2, 7, 7, -1)
        attn_windows_20 = None
        permute_95 = x_259.permute(0, 1, 3, 2, 4, 5)
        x_259 = None
        contiguous_92 = permute_95.contiguous()
        permute_95 = None
        x_260 = contiguous_92.view(1, 21, 14, -1)
        contiguous_92 = None
        getitem_104 = x_260[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_260 = None
        x_261 = getitem_104.contiguous()
        getitem_104 = None
        x_262 = x_261.view(1, 192, 512)
        x_261 = None
        x_263 = x_262 + output_19
        x_262 = output_19 = None
        x_264 = torch.nn.functional.layer_norm(
            x_263,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_norm2_parameters_bias_ = (None)
        input_101 = torch._C._nn.linear(
            x_264,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_264 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_102 = torch._C._nn.gelu(input_101, approximate="none")
        input_101 = None
        input_103 = torch.nn.functional.dropout(input_102, 0.0, False, False)
        input_102 = None
        input_104 = torch._C._nn.linear(
            input_103,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_103 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_16_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_105 = torch.nn.functional.dropout(input_104, 0.0, False, False)
        input_104 = None
        output_20 = x_263 + input_105
        x_263 = input_105 = None
        x_265 = torch.nn.functional.layer_norm(
            output_20,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm1_parameters_bias_ = (None)
        query_42 = x_265.view(1, 16, 12, 512)
        x_265 = None
        query_43 = torch._C._nn.pad(query_42, (0, 0, 0, 2, 0, 5), "constant", None)
        query_42 = None
        shifted_query_10 = torch.roll(query_43, shifts=(-3, -3), dims=(1, 2))
        query_43 = None
        img_mask_10 = torch.zeros((1, 21, 14, 1), device=device(type="cuda", index=0))
        img_mask_10[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_90 = img_mask_10
        setitem_90 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_91 = img_mask_10
        setitem_91 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_92 = img_mask_10
        setitem_92 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_93 = img_mask_10
        setitem_93 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_94 = img_mask_10
        setitem_94 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_95 = img_mask_10
        setitem_95 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_96 = img_mask_10
        setitem_96 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_97 = img_mask_10
        setitem_97 = None
        img_mask_10[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_98 = img_mask_10
        setitem_98 = None
        x_266 = img_mask_10.view(1, 3, 7, 2, 7, 1)
        img_mask_10 = None
        permute_96 = x_266.permute(0, 1, 3, 2, 4, 5)
        x_266 = None
        windows_62 = permute_96.contiguous()
        permute_96 = None
        windows_63 = windows_62.view(-1, 7, 7, 1)
        windows_62 = None
        mask_windows_10 = windows_63.view(-1, 49)
        windows_63 = None
        unsqueeze_61 = mask_windows_10.unsqueeze(1)
        unsqueeze_62 = mask_windows_10.unsqueeze(2)
        mask_windows_10 = None
        attn_mask_20 = unsqueeze_61 - unsqueeze_62
        unsqueeze_61 = unsqueeze_62 = None
        ne_10 = attn_mask_20 != 0
        masked_fill_20 = attn_mask_20.masked_fill(ne_10, -100.0)
        ne_10 = None
        eq_10 = attn_mask_20 == 0
        attn_mask_20 = None
        attn_mask_21 = masked_fill_20.masked_fill(eq_10, 0.0)
        masked_fill_20 = eq_10 = None
        x_267 = shifted_query_10.view(1, 3, 7, 2, 7, 512)
        shifted_query_10 = None
        permute_97 = x_267.permute(0, 1, 3, 2, 4, 5)
        x_267 = None
        windows_64 = permute_97.contiguous()
        permute_97 = None
        windows_65 = windows_64.view(-1, 7, 7, 512)
        windows_64 = None
        query_windows_21 = windows_65.view(-1, 49, 512)
        windows_65 = None
        linear_86 = torch._C._nn.linear(
            query_windows_21,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_21 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_42 = linear_86.reshape(6, 49, 3, 16, 32)
        linear_86 = None
        qkv_21 = reshape_42.permute(2, 0, 3, 1, 4)
        reshape_42 = None
        q_42 = qkv_21[0]
        k_21 = qkv_21[1]
        v_21 = qkv_21[2]
        qkv_21 = None
        q_43 = q_42 * 0.1767766952966369
        q_42 = None
        transpose_45 = k_21.transpose(-2, -1)
        k_21 = None
        attn_104 = q_43 @ transpose_45
        q_43 = transpose_45 = None
        view_269 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_108 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_269
        ]
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_269
        ) = None
        relative_position_bias_42 = getitem_108.view(49, 49, -1)
        getitem_108 = None
        permute_99 = relative_position_bias_42.permute(2, 0, 1)
        relative_position_bias_42 = None
        relative_position_bias_43 = permute_99.contiguous()
        permute_99 = None
        unsqueeze_63 = relative_position_bias_43.unsqueeze(0)
        relative_position_bias_43 = None
        attn_105 = attn_104 + unsqueeze_63
        attn_104 = unsqueeze_63 = None
        view_271 = attn_105.view(1, 6, 16, 49, 49)
        attn_105 = None
        unsqueeze_64 = attn_mask_21.unsqueeze(1)
        attn_mask_21 = None
        unsqueeze_65 = unsqueeze_64.unsqueeze(0)
        unsqueeze_64 = None
        attn_106 = view_271 + unsqueeze_65
        view_271 = unsqueeze_65 = None
        attn_107 = attn_106.view(-1, 16, 49, 49)
        attn_106 = None
        attn_108 = torch.nn.functional.softmax(attn_107, -1, _stacklevel=5)
        attn_107 = None
        attn_109 = torch.nn.functional.dropout(attn_108, 0.0, False, False)
        attn_108 = None
        matmul_43 = attn_109 @ v_21
        attn_109 = v_21 = None
        transpose_46 = matmul_43.transpose(1, 2)
        matmul_43 = None
        x_268 = transpose_46.reshape(6, 49, 512)
        transpose_46 = None
        x_269 = torch._C._nn.linear(
            x_268,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_268 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_270 = torch.nn.functional.dropout(x_269, 0.0, False, False)
        x_269 = None
        attn_windows_21 = x_270.view(-1, 7, 7, 512)
        x_270 = None
        x_271 = attn_windows_21.view(1, 3, 2, 7, 7, -1)
        attn_windows_21 = None
        permute_100 = x_271.permute(0, 1, 3, 2, 4, 5)
        x_271 = None
        contiguous_97 = permute_100.contiguous()
        permute_100 = None
        x_272 = contiguous_97.view(1, 21, 14, -1)
        contiguous_97 = None
        x_273 = torch.roll(x_272, shifts=(3, 3), dims=(1, 2))
        x_272 = None
        getitem_109 = x_273[
            (
                slice(None, None, None),
                slice(None, 16, None),
                slice(None, 12, None),
                slice(None, None, None),
            )
        ]
        x_273 = None
        x_274 = getitem_109.contiguous()
        getitem_109 = None
        x_275 = x_274.view(1, 192, 512)
        x_274 = None
        x_276 = x_275 + output_20
        x_275 = output_20 = None
        x_277 = torch.nn.functional.layer_norm(
            x_276,
            (512,),
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_norm2_parameters_bias_ = (None)
        input_106 = torch._C._nn.linear(
            x_277,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_277 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_107 = torch._C._nn.gelu(input_106, approximate="none")
        input_106 = None
        input_108 = torch.nn.functional.dropout(input_107, 0.0, False, False)
        input_107 = None
        input_109 = torch._C._nn.linear(
            input_108,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_108 = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_blocks_modules_17_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_110 = torch.nn.functional.dropout(input_109, 0.0, False, False)
        input_109 = None
        output_21 = x_276 + input_110
        x_276 = input_110 = None
        view_277 = output_21.view(1, 16, 12, 512)
        output_21 = None
        x_278 = view_277.permute([0, 3, 1, 2])
        view_277 = None
        x_279 = torch.nn.functional.unfold(x_278, (2, 2), (1, 1), (0, 0), (2, 2))
        x_278 = None
        x_280 = x_279.transpose(1, 2)
        x_279 = None
        x_281 = torch.nn.functional.layer_norm(
            x_280,
            (2048,),
            l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_bias_,
            1e-05,
        )
        x_280 = l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_norm_parameters_bias_ = (None)
        x_282 = torch._C._nn.linear(
            x_281,
            l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_reduction_parameters_weight_,
            None,
        )
        x_281 = l_self_modules_backbone_modules_stages_modules_2_modules_downsample_modules_reduction_parameters_weight_ = (None)
        x_283 = torch.nn.functional.layer_norm(
            x_282,
            (1024,),
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm1_parameters_bias_ = (None)
        query_44 = x_283.view(1, 8, 6, 1024)
        x_283 = None
        query_45 = torch._C._nn.pad(query_44, (0, 0, 0, 1, 0, 6), "constant", None)
        query_44 = None
        x_284 = query_45.view(1, 2, 7, 1, 7, 1024)
        query_45 = None
        permute_102 = x_284.permute(0, 1, 3, 2, 4, 5)
        x_284 = None
        windows_66 = permute_102.contiguous()
        permute_102 = None
        windows_67 = windows_66.view(-1, 7, 7, 1024)
        windows_66 = None
        query_windows_22 = windows_67.view(-1, 49, 1024)
        windows_67 = None
        linear_91 = torch._C._nn.linear(
            query_windows_22,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_22 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_44 = linear_91.reshape(2, 49, 3, 32, 32)
        linear_91 = None
        qkv_22 = reshape_44.permute(2, 0, 3, 1, 4)
        reshape_44 = None
        q_44 = qkv_22[0]
        k_22 = qkv_22[1]
        v_22 = qkv_22[2]
        qkv_22 = None
        q_45 = q_44 * 0.1767766952966369
        q_44 = None
        transpose_48 = k_22.transpose(-2, -1)
        k_22 = None
        attn_110 = q_45 @ transpose_48
        q_45 = transpose_48 = None
        view_282 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_113 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_282
        ]
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_282
        ) = None
        relative_position_bias_44 = getitem_113.view(49, 49, -1)
        getitem_113 = None
        permute_104 = relative_position_bias_44.permute(2, 0, 1)
        relative_position_bias_44 = None
        relative_position_bias_45 = permute_104.contiguous()
        permute_104 = None
        unsqueeze_66 = relative_position_bias_45.unsqueeze(0)
        relative_position_bias_45 = None
        attn_111 = attn_110 + unsqueeze_66
        attn_110 = unsqueeze_66 = None
        attn_112 = torch.nn.functional.softmax(attn_111, -1, _stacklevel=5)
        attn_111 = None
        attn_113 = torch.nn.functional.dropout(attn_112, 0.0, False, False)
        attn_112 = None
        matmul_45 = attn_113 @ v_22
        attn_113 = v_22 = None
        transpose_49 = matmul_45.transpose(1, 2)
        matmul_45 = None
        x_285 = transpose_49.reshape(2, 49, 1024)
        transpose_49 = None
        x_286 = torch._C._nn.linear(
            x_285,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_285 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_287 = torch.nn.functional.dropout(x_286, 0.0, False, False)
        x_286 = None
        attn_windows_22 = x_287.view(-1, 7, 7, 1024)
        x_287 = None
        x_288 = attn_windows_22.view(1, 2, 1, 7, 7, -1)
        attn_windows_22 = None
        permute_105 = x_288.permute(0, 1, 3, 2, 4, 5)
        x_288 = None
        contiguous_101 = permute_105.contiguous()
        permute_105 = None
        x_289 = contiguous_101.view(1, 14, 7, -1)
        contiguous_101 = None
        getitem_114 = x_289[
            (
                slice(None, None, None),
                slice(None, 8, None),
                slice(None, 6, None),
                slice(None, None, None),
            )
        ]
        x_289 = None
        x_290 = getitem_114.contiguous()
        getitem_114 = None
        x_291 = x_290.view(1, 48, 1024)
        x_290 = None
        x_292 = x_291 + x_282
        x_291 = x_282 = None
        x_293 = torch.nn.functional.layer_norm(
            x_292,
            (1024,),
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_norm2_parameters_bias_ = (None)
        input_111 = torch._C._nn.linear(
            x_293,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_293 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_112 = torch._C._nn.gelu(input_111, approximate="none")
        input_111 = None
        input_113 = torch.nn.functional.dropout(input_112, 0.0, False, False)
        input_112 = None
        input_114 = torch._C._nn.linear(
            input_113,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_113 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_0_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_115 = torch.nn.functional.dropout(input_114, 0.0, False, False)
        input_114 = None
        output_22 = x_292 + input_115
        x_292 = input_115 = None
        x_294 = torch.nn.functional.layer_norm(
            output_22,
            (1024,),
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm1_parameters_bias_ = (None)
        query_46 = x_294.view(1, 8, 6, 1024)
        x_294 = None
        query_47 = torch._C._nn.pad(query_46, (0, 0, 0, 1, 0, 6), "constant", None)
        query_46 = None
        shifted_query_11 = torch.roll(query_47, shifts=(-3, -3), dims=(1, 2))
        query_47 = None
        img_mask_11 = torch.zeros((1, 14, 7, 1), device=device(type="cuda", index=0))
        img_mask_11[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 0
        setitem_99 = img_mask_11
        setitem_99 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 1
        setitem_100 = img_mask_11
        setitem_100 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(0, -7, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 2
        setitem_101 = img_mask_11
        setitem_101 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 3
        setitem_102 = img_mask_11
        setitem_102 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 4
        setitem_103 = img_mask_11
        setitem_103 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(-7, -3, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 5
        setitem_104 = img_mask_11
        setitem_104 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(0, -7, None),
                slice(None, None, None),
            )
        ] = 6
        setitem_105 = img_mask_11
        setitem_105 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-7, -3, None),
                slice(None, None, None),
            )
        ] = 7
        setitem_106 = img_mask_11
        setitem_106 = None
        img_mask_11[
            (
                slice(None, None, None),
                slice(-3, None, None),
                slice(-3, None, None),
                slice(None, None, None),
            )
        ] = 8
        setitem_107 = img_mask_11
        setitem_107 = None
        x_295 = img_mask_11.view(1, 2, 7, 1, 7, 1)
        img_mask_11 = None
        permute_106 = x_295.permute(0, 1, 3, 2, 4, 5)
        x_295 = None
        windows_68 = permute_106.contiguous()
        permute_106 = None
        windows_69 = windows_68.view(-1, 7, 7, 1)
        windows_68 = None
        mask_windows_11 = windows_69.view(-1, 49)
        windows_69 = None
        unsqueeze_67 = mask_windows_11.unsqueeze(1)
        unsqueeze_68 = mask_windows_11.unsqueeze(2)
        mask_windows_11 = None
        attn_mask_22 = unsqueeze_67 - unsqueeze_68
        unsqueeze_67 = unsqueeze_68 = None
        ne_11 = attn_mask_22 != 0
        masked_fill_22 = attn_mask_22.masked_fill(ne_11, -100.0)
        ne_11 = None
        eq_11 = attn_mask_22 == 0
        attn_mask_22 = None
        attn_mask_23 = masked_fill_22.masked_fill(eq_11, 0.0)
        masked_fill_22 = eq_11 = None
        x_296 = shifted_query_11.view(1, 2, 7, 1, 7, 1024)
        shifted_query_11 = None
        permute_107 = x_296.permute(0, 1, 3, 2, 4, 5)
        x_296 = None
        windows_70 = permute_107.contiguous()
        permute_107 = None
        windows_71 = windows_70.view(-1, 7, 7, 1024)
        windows_70 = None
        query_windows_23 = windows_71.view(-1, 49, 1024)
        windows_71 = None
        linear_95 = torch._C._nn.linear(
            query_windows_23,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_,
        )
        query_windows_23 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_qkv_parameters_bias_ = (None)
        reshape_46 = linear_95.reshape(2, 49, 3, 32, 32)
        linear_95 = None
        qkv_23 = reshape_46.permute(2, 0, 3, 1, 4)
        reshape_46 = None
        q_46 = qkv_23[0]
        k_23 = qkv_23[1]
        v_23 = qkv_23[2]
        qkv_23 = None
        q_47 = q_46 * 0.1767766952966369
        q_46 = None
        transpose_50 = k_23.transpose(-2, -1)
        k_23 = None
        attn_114 = q_47 @ transpose_50
        q_47 = transpose_50 = None
        view_295 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_.view(
            -1
        )
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_buffers_relative_position_index_ = (
            None
        )
        getitem_118 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_[
            view_295
        ]
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_parameters_relative_position_bias_table_ = (
            view_295
        ) = None
        relative_position_bias_46 = getitem_118.view(49, 49, -1)
        getitem_118 = None
        permute_109 = relative_position_bias_46.permute(2, 0, 1)
        relative_position_bias_46 = None
        relative_position_bias_47 = permute_109.contiguous()
        permute_109 = None
        unsqueeze_69 = relative_position_bias_47.unsqueeze(0)
        relative_position_bias_47 = None
        attn_115 = attn_114 + unsqueeze_69
        attn_114 = unsqueeze_69 = None
        view_297 = attn_115.view(1, 2, 32, 49, 49)
        attn_115 = None
        unsqueeze_70 = attn_mask_23.unsqueeze(1)
        attn_mask_23 = None
        unsqueeze_71 = unsqueeze_70.unsqueeze(0)
        unsqueeze_70 = None
        attn_116 = view_297 + unsqueeze_71
        view_297 = unsqueeze_71 = None
        attn_117 = attn_116.view(-1, 32, 49, 49)
        attn_116 = None
        attn_118 = torch.nn.functional.softmax(attn_117, -1, _stacklevel=5)
        attn_117 = None
        attn_119 = torch.nn.functional.dropout(attn_118, 0.0, False, False)
        attn_118 = None
        matmul_47 = attn_119 @ v_23
        attn_119 = v_23 = None
        transpose_51 = matmul_47.transpose(1, 2)
        matmul_47 = None
        x_297 = transpose_51.reshape(2, 49, 1024)
        transpose_51 = None
        x_298 = torch._C._nn.linear(
            x_297,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_,
        )
        x_297 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_attn_modules_w_msa_modules_proj_parameters_bias_ = (None)
        x_299 = torch.nn.functional.dropout(x_298, 0.0, False, False)
        x_298 = None
        attn_windows_23 = x_299.view(-1, 7, 7, 1024)
        x_299 = None
        x_300 = attn_windows_23.view(1, 2, 1, 7, 7, -1)
        attn_windows_23 = None
        permute_110 = x_300.permute(0, 1, 3, 2, 4, 5)
        x_300 = None
        contiguous_106 = permute_110.contiguous()
        permute_110 = None
        x_301 = contiguous_106.view(1, 14, 7, -1)
        contiguous_106 = None
        x_302 = torch.roll(x_301, shifts=(3, 3), dims=(1, 2))
        x_301 = None
        getitem_119 = x_302[
            (
                slice(None, None, None),
                slice(None, 8, None),
                slice(None, 6, None),
                slice(None, None, None),
            )
        ]
        x_302 = None
        x_303 = getitem_119.contiguous()
        getitem_119 = None
        x_304 = x_303.view(1, 48, 1024)
        x_303 = None
        x_305 = x_304 + output_22
        x_304 = output_22 = None
        x_306 = torch.nn.functional.layer_norm(
            x_305,
            (1024,),
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_bias_,
            1e-05,
        )
        l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_norm2_parameters_bias_ = (None)
        input_116 = torch._C._nn.linear(
            x_306,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_,
        )
        x_306 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_0_modules_0_parameters_bias_ = (None)
        input_117 = torch._C._nn.gelu(input_116, approximate="none")
        input_116 = None
        input_118 = torch.nn.functional.dropout(input_117, 0.0, False, False)
        input_117 = None
        input_119 = torch._C._nn.linear(
            input_118,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_,
            l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_,
        )
        input_118 = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_weight_ = l_self_modules_backbone_modules_stages_modules_3_modules_blocks_modules_1_modules_ffn_modules_layers_modules_1_parameters_bias_ = (None)
        input_120 = torch.nn.functional.dropout(input_119, 0.0, False, False)
        input_119 = None
        output_23 = x_305 + input_120
        x_305 = input_120 = None
        out = torch.nn.functional.layer_norm(
            output_23,
            (1024,),
            l_self_modules_backbone_modules_norm3_parameters_weight_,
            l_self_modules_backbone_modules_norm3_parameters_bias_,
            1e-05,
        )
        output_23 = (
            l_self_modules_backbone_modules_norm3_parameters_weight_
        ) = l_self_modules_backbone_modules_norm3_parameters_bias_ = None
        view_303 = out.view(-1, 8, 6, 1024)
        out = None
        permute_111 = view_303.permute(0, 3, 1, 2)
        view_303 = None
        out_1 = permute_111.contiguous()
        permute_111 = None
        input_121 = torch.conv_transpose2d(
            out_1,
            l_self_modules_head_modules_deconv_layers_modules_0_parameters_weight_,
            None,
            (2, 2),
            (1, 1),
            (0, 0),
            1,
            (1, 1),
        )
        out_1 = (
            l_self_modules_head_modules_deconv_layers_modules_0_parameters_weight_
        ) = None
        input_122 = torch.nn.functional.batch_norm(
            input_121,
            l_self_modules_head_modules_deconv_layers_modules_1_buffers_running_mean_,
            l_self_modules_head_modules_deconv_layers_modules_1_buffers_running_var_,
            l_self_modules_head_modules_deconv_layers_modules_1_parameters_weight_,
            l_self_modules_head_modules_deconv_layers_modules_1_parameters_bias_,
            False,
            0.1,
            1e-05,
        )
        input_121 = (
            l_self_modules_head_modules_deconv_layers_modules_1_buffers_running_mean_
        ) = (
            l_self_modules_head_modules_deconv_layers_modules_1_buffers_running_var_
        ) = (
            l_self_modules_head_modules_deconv_layers_modules_1_parameters_weight_
        ) = l_self_modules_head_modules_deconv_layers_modules_1_parameters_bias_ = None
        input_123 = torch.nn.functional.relu(input_122, inplace=True)
        input_122 = None
        input_124 = torch.conv_transpose2d(
            input_123,
            l_self_modules_head_modules_deconv_layers_modules_3_parameters_weight_,
            None,
            (2, 2),
            (1, 1),
            (0, 0),
            1,
            (1, 1),
        )
        input_123 = (
            l_self_modules_head_modules_deconv_layers_modules_3_parameters_weight_
        ) = None
        input_125 = torch.nn.functional.batch_norm(
            input_124,
            l_self_modules_head_modules_deconv_layers_modules_4_buffers_running_mean_,
            l_self_modules_head_modules_deconv_layers_modules_4_buffers_running_var_,
            l_self_modules_head_modules_deconv_layers_modules_4_parameters_weight_,
            l_self_modules_head_modules_deconv_layers_modules_4_parameters_bias_,
            False,
            0.1,
            1e-05,
        )
        input_124 = (
            l_self_modules_head_modules_deconv_layers_modules_4_buffers_running_mean_
        ) = (
            l_self_modules_head_modules_deconv_layers_modules_4_buffers_running_var_
        ) = (
            l_self_modules_head_modules_deconv_layers_modules_4_parameters_weight_
        ) = l_self_modules_head_modules_deconv_layers_modules_4_parameters_bias_ = None
        input_126 = torch.nn.functional.relu(input_125, inplace=True)
        input_125 = None
        input_127 = torch.conv_transpose2d(
            input_126,
            l_self_modules_head_modules_deconv_layers_modules_6_parameters_weight_,
            None,
            (2, 2),
            (1, 1),
            (0, 0),
            1,
            (1, 1),
        )
        input_126 = (
            l_self_modules_head_modules_deconv_layers_modules_6_parameters_weight_
        ) = None
        input_128 = torch.nn.functional.batch_norm(
            input_127,
            l_self_modules_head_modules_deconv_layers_modules_7_buffers_running_mean_,
            l_self_modules_head_modules_deconv_layers_modules_7_buffers_running_var_,
            l_self_modules_head_modules_deconv_layers_modules_7_parameters_weight_,
            l_self_modules_head_modules_deconv_layers_modules_7_parameters_bias_,
            False,
            0.1,
            1e-05,
        )
        input_127 = (
            l_self_modules_head_modules_deconv_layers_modules_7_buffers_running_mean_
        ) = (
            l_self_modules_head_modules_deconv_layers_modules_7_buffers_running_var_
        ) = (
            l_self_modules_head_modules_deconv_layers_modules_7_parameters_weight_
        ) = l_self_modules_head_modules_deconv_layers_modules_7_parameters_bias_ = None
        input_129 = torch.nn.functional.relu(input_128, inplace=True)
        input_128 = None
        x_307 = torch.conv2d(
            input_129,
            l_self_modules_head_modules_final_layer_parameters_weight_,
            l_self_modules_head_modules_final_layer_parameters_bias_,
            (1, 1),
            (0, 0),
            (1, 1),
            1,
        )
        input_129 = (
            l_self_modules_head_modules_final_layer_parameters_weight_
        ) = l_self_modules_head_modules_final_layer_parameters_bias_ = None
        return (x_307,)
