class Program_weight_tensor_meta_L_waveforms_:
    name = "L_waveforms_"
    shape = [1, 64000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.997
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_weight_"
    shape = [512, 1, 10]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.214
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.030
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.032
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.664
    std = 0.556
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.102
    std = 0.142
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.721
    std = 0.384
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.195
    std = 0.180
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.013
    std = 0.150
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.618
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.198
    std = 0.191
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.150
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.505
    std = 0.228
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.154
    std = 0.198
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_weight_"
    shape = [512, 512, 2]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.152
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.371
    std = 0.225
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.128
    std = 0.238
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_weight_"
    shape = [512, 512, 2]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.134
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.099
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.253
    std = 0.141
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.048
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_weight_"
    shape = [1024, 512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.132
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.155
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original0_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original0_"
    shape = [1, 1, 128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.191
    std = 0.660
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original1_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original1_"
    shape = [1024, 64, 128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.082
    std = 0.337
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.114
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_rel_attn_embed_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_rel_attn_embed_parameters_weight_"
    shape = [320, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.769
    std = 0.809
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.032
    std = 0.186
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.298
    std = 0.367
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.372
    std = 1.138
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.217
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.138
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.066
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.159
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.016
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.225
    std = 0.808
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.043
    std = 1.784
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.229
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.103
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.183
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.015
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.120
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.028
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.103
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.166
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.015
    std = 0.169
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.002
    std = 0.694
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.077
    std = 1.176
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.209
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.110
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.180
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.014
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.030
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.177
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.193
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.904
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.664
    std = 0.746
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.185
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.106
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.186
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.027
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.178
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.209
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.659
    std = 0.370
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.119
    std = 1.433
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.114
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.180
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.110
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.190
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.018
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.110
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.176
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.017
    std = 0.234
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.095
    std = 0.132
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.050
    std = 1.249
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.114
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.198
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.017
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.200
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.040
    std = 0.213
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.766
    std = 0.005
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.184
    std = 1.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.166
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.209
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.022
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.115
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.199
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.018
    std = 0.222
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.226
    std = 0.791
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.602
    std = 1.868
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.115
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.147
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.220
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.036
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.193
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.244
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.838
    std = 0.336
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.559
    std = 1.542
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.186
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.119
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.237
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.034
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.210
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.012
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.836
    std = 0.414
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.554
    std = 1.342
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.169
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.114
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.247
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.036
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.212
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.019
    std = 0.184
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.758
    std = 0.746
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.481
    std = 1.567
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.115
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.232
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.059
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.206
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.021
    std = 0.211
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.828
    std = 0.426
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.211
    std = 1.696
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.199
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.236
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.049
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.225
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.206
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.570
    std = 0.248
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.362
    std = 1.737
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.187
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.237
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.059
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.220
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.182
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.170
    std = 0.663
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.194
    std = 1.625
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.195
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.121
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.235
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.057
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.223
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.832
    std = 0.590
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.432
    std = 1.488
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.161
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.275
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.039
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.130
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.230
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.013
    std = 0.180
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.677
    std = 0.327
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.566
    std = 1.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.169
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.101
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.369
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.015
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.130
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.017
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.226
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.179
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.817
    std = 0.538
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.840
    std = 2.097
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.120
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.218
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.128
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.570
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.023
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.010
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.173
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.247
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.160
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.629
    std = 0.455
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 2.421
    std = 1.801
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.186
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.166
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.734
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.045
    std = 0.240
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.136
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.206
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.247
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.151
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.580
    std = 0.401
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 2.462
    std = 1.472
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.250
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.142
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.161
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.641
    std = 0.106
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.028
    std = 0.188
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.030
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.183
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.281
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.184
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.348
    std = 0.343
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 3.840
    std = 3.167
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.262
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.151
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.166
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.864
    std = 0.110
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.046
    std = 0.218
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.137
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.051
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.136
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.235
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.300
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.137
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.575
    std = 0.483
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 2.763
    std = 2.225
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.298
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.155
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.150
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.042
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.040
    std = 0.224
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.136
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.060
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.137
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.233
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.328
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.062
    std = 0.923
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 2.543
    std = 1.921
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.343
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.173
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.144
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.236
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.042
    std = 0.249
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.072
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.211
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.401
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.392
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.028
    std = 0.142
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.768
    std = 0.307
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 3.584
    std = 4.559
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.140
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 3.549
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.143
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.744
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.035
    std = 0.334
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.134
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.078
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.657
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.106
    std = 1.195
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.021
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.509
    std = 0.312
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 16, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 9.485
    std = 8.363
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [3072, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.154
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.907
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.144
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.105
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.725
    std = 0.139
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.036
    std = 0.554
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.128
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.083
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.231
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.026
    data = None
