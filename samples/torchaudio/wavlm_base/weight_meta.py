class Program_weight_tensor_meta_L_waveforms_:
    name = "L_waveforms_"
    shape = [1, 64000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.995
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_weight_"
    shape = [512, 1, 10]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.194
    std = 0.409
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.002
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_weight_"
    shape = [512, 512, 2]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_weight_:
    name = "L_self_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_weight_"
    shape = [512, 512, 2]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.121
    std = 0.165
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_feature_projection_modules_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_feature_projection_modules_projection_parameters_weight_"
    shape = [768, 512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_feature_projection_modules_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_feature_projection_modules_projection_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.029
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original0_:
    name = "L_self_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original0_"
    shape = [1, 1, 128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.332
    std = 1.147
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original1_:
    name = "L_self_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original1_"
    shape = [768, 48, 128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.133
    std = 0.105
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.254
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layer_norm_parameters_bias_:
    name = (
        "L_self_modules_encoder_modules_transformer_modules_layer_norm_parameters_bias_"
    )
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_rel_attn_embed_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_rel_attn_embed_parameters_weight_"
    shape = [320, 12]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.441
    std = 0.702
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.927
    std = 0.130
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.628
    std = 0.555
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.152
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.202
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.011
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.071
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.205
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.819
    std = 0.272
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.233
    std = 0.964
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.145
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.242
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.017
    std = 0.153
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.047
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.213
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.147
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.762
    std = 0.244
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.194
    std = 1.132
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.262
    std = 0.115
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.186
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.032
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.220
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.165
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.725
    std = 0.412
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.063
    std = 1.110
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.254
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.012
    std = 0.154
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.036
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.222
    std = 0.105
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.024
    std = 0.146
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.779
    std = 0.251
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.429
    std = 1.421
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.024
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.249
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.139
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.039
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.224
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.022
    std = 0.158
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.766
    std = 0.280
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.695
    std = 1.581
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.260
    std = 0.101
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.148
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.038
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.231
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.028
    std = 0.149
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.682
    std = 0.327
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.933
    std = 1.556
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.135
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.269
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.148
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.096
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.037
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.232
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.015
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.637
    std = 0.230
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.767
    std = 1.426
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.136
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.280
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.155
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.098
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.041
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.139
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.235
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.137
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.464
    std = 0.257
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.769
    std = 1.926
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.136
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.373
    std = 0.119
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.198
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.045
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.098
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.166
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.249
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.434
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 2.300
    std = 2.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.157
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.426
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.213
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.046
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.171
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.269
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.011
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.011
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.410
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 2.001
    std = 1.817
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.165
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.344
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.149
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.063
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.147
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.258
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_weight_"
    shape = [8, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.016
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_gru_rel_pos_linear_parameters_bias_"
    shape = [8]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.697
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_parameters_gru_rel_pos_const_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_parameters_gru_rel_pos_const_"
    shape = [1, 12, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.768
    std = 1.487
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_weight_"
    shape = [2304, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_parameters_in_proj_bias_"
    shape = [2304]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.164
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_attention_modules_out_proj_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.263
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.022
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.107
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.330
    std = 0.128
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.048
    data = None
