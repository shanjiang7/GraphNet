class Program_weight_tensor_meta_L_waveforms_:
    name = "L_waveforms_"
    shape = [1, 80000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.999
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_weight_"
    shape = [512, 1, 10]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.023
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.289
    std = 0.432
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_0_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.054
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.142
    std = 0.130
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.772
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_1_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.203
    std = 0.184
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.093
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.709
    std = 0.323
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_2_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.249
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.107
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.059
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.607
    std = 0.251
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_3_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.215
    std = 0.159
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_weight_"
    shape = [512, 512, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.048
    std = 0.108
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.530
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_4_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.197
    std = 0.170
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_weight_"
    shape = [512, 512, 2]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.072
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.480
    std = 0.209
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_5_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.205
    std = 0.205
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_weight_"
    shape = [512, 512, 2]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.106
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.085
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.384
    std = 0.274
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_feature_extractor_modules_conv_layers_modules_6_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.244
    std = 0.152
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.683
    std = 0.357
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_layer_norm_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.083
    std = 0.302
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_weight_"
    shape = [1024, 512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_feature_projection_modules_projection_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.017
    std = 0.154
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original0_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original0_"
    shape = [1, 1, 128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.285
    std = 0.834
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original1_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_modules_parametrizations_modules_weight_parameters_original1_"
    shape = [1024, 64, 128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_pos_conv_embed_modules_conv_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.229
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.152
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.357
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.001
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.152
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.080
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_0_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.249
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.350
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.235
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.038
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_1_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.270
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.320
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.253
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.037
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_2_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.297
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.260
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.035
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_3_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.305
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.292
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.261
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.039
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_4_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.317
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.275
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.023
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.253
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.047
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_5_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.299
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.268
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.040
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_6_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.295
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.291
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.271
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.037
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_7_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.304
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.292
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.271
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.041
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_8_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.308
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.309
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.310
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.034
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_9_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.308
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.267
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.320
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.034
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_10_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.303
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.011
    std = 0.290
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.320
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.037
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.098
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_11_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.329
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.210
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.394
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.109
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.031
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.103
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_12_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.342
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.244
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.383
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.034
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_13_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.349
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.228
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.343
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.041
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_14_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.354
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.011
    std = 0.224
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.103
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.312
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.046
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_15_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.344
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.219
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.148
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.305
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.051
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_16_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.397
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.193
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.211
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.114
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.325
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.059
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_17_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.405
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.181
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.155
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.122
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.336
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.054
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_18_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.411
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.300
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.371
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.053
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_19_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.487
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.031
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.145
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.060
    std = 1.636
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.145
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.391
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.051
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_20_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.504
    std = 0.105
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.162
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.050
    std = 1.108
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.553
    std = 0.181
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.048
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_21_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.478
    std = 0.188
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.153
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.030
    std = 1.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.101
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.555
    std = 0.188
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.010
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.061
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_22_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.317
    std = 0.116
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_q_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_q_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_q_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_q_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_k_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_k_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_k_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_k_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_v_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_v_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_v_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_v_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_out_proj_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_out_proj_parameters_weight_"
    shape = [1024, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_out_proj_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_attention_modules_out_proj_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.340
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_final_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_weight_"
    shape = [4096, 1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_intermediate_dense_parameters_bias_"
    shape = [4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.063
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_weight_"
    shape = [1024, 4096]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layers_modules_23_modules_feed_forward_modules_output_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_weight_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_weight_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.165
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_bias_:
    name = "L_self_modules_model_modules_encoder_modules_transformer_modules_layer_norm_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None
