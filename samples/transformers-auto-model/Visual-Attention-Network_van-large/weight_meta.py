class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [64, 3, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_pixel_values_:
    name = "L_pixel_values_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -1.986
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.016
    std = 0.466
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.174
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.178
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.207
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.474
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.287
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.173
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.483
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [128, 64, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.278
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.198
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.474
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.197
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.473
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.285
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.204
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.468
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.287
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_4_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [320, 128, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.287
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.277
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.473
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.280
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.468
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.285
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.478
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.285
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.287
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.475
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.472
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_10_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.475
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_11_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.466
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_12_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.473
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_13_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.278
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_14_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.472
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_15_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.205
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.472
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_16_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_17_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_18_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.467
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_19_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_20_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_21_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.277
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.204
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.474
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_22_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_23_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.473
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_24_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_25_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_26_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [512, 320, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [512, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [2048, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [2048, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [512, 2048, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [512, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [2048, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [2048, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [512, 2048, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [512, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [2048, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [2048, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [512, 2048, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
