class Program_weight_tensor_meta_L_inputs_embeds_:
    name = "L_inputs_embeds_"
    shape = [1, 2, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_attention_mask_:
    name = "L_attention_mask_"
    shape = [1, 2]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [1, 1]


class Program_weight_tensor_meta_L_self_modules_rotary_emb_buffers_inv_freq_:
    name = "L_self_modules_rotary_emb_buffers_inv_freq_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.143
    std = 0.275
    data = [
        1.000000,
        0.562341,
        0.316228,
        0.177828,
        0.100000,
        0.056234,
        0.031623,
        0.017783,
        0.010000,
        0.005623,
        0.003162,
        0.001778,
        0.001000,
        0.000562,
        0.000316,
        0.000178,
    ]


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_0_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_1_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_2_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_3_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_4_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_5_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_6_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_7_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_8_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_9_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_10_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_11_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_12_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_13_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_14_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_15_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_16_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_17_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_18_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_19_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_20_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_21_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_22_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_23_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_24_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_25_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_26_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_26_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_26_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_27_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_27_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_27_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_28_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_28_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_28_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_29_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_29_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_29_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_30_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_30_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_30_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_input_layernorm_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_input_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_input_layernorm_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_input_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_q_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_q_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_q_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_q_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_k_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_k_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_k_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_k_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_v_proj_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_v_proj_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_v_proj_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_v_proj_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_dense_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_dense_parameters_weight_"
    shape = [2560, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_self_attn_modules_dense_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_self_attn_modules_dense_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_mlp_modules_fc1_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_mlp_modules_fc1_parameters_weight_"
    shape = [10240, 2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_mlp_modules_fc1_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_mlp_modules_fc1_parameters_bias_"
    shape = [10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_mlp_modules_fc2_parameters_weight_:
    name = "L_self_modules_layers_modules_31_modules_mlp_modules_fc2_parameters_weight_"
    shape = [2560, 10240]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_layers_modules_31_modules_mlp_modules_fc2_parameters_bias_:
    name = "L_self_modules_layers_modules_31_modules_mlp_modules_fc2_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_final_layernorm_parameters_weight_:
    name = "L_self_modules_final_layernorm_parameters_weight_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_final_layernorm_parameters_bias_:
    name = "L_self_modules_final_layernorm_parameters_bias_"
    shape = [2560]
    dtype = "torch.float16"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
