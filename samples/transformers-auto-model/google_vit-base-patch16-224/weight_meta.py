class Program_weight_tensor_meta_L_pixel_values_:
    name = "L_pixel_values_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.577
    data = None


class Program_weight_tensor_meta_object_getattribute_L_self_config_num_hidden_layers_:
    name = "object_getattribute_L_self_config_num_hidden_layers_"
    shape = []
    dtype = "torch.int64"
    device = "cpu"
    mean = None
    std = None
    data = [4]


class Program_weight_tensor_meta_L_self_modules_vit_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_:
    name = "L_self_modules_vit_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_"
    shape = [768, 3, 16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_:
    name = "L_self_modules_vit_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.193
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_embeddings_parameters_cls_token_:
    name = "L_self_modules_vit_modules_embeddings_parameters_cls_token_"
    shape = [1, 1, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_embeddings_parameters_position_embeddings_:
    name = "L_self_modules_vit_modules_embeddings_parameters_position_embeddings_"
    shape = [1, 197, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.144
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.129
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.014
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.127
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.128
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.243
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.238
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.026
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.073
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.174
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.102
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.260
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.258
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.070
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.230
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.195
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.279
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.065
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.257
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.319
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.066
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.278
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.171
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.342
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.067
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.297
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.167
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.375
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.066
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.317
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.162
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.411
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.066
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.356
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.141
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.468
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.065
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.395
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.593
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.062
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.099
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.449
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.009
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.027
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.119
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.029
    std = 0.098
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.159
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.060
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.101
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.529
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.014
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.822
    std = 0.149
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.306
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.063
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.168
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.699
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_before_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.012
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.115
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_attention_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.098
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.116
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.091
    std = 0.091
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_layernorm_after_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.066
    std = 0.211
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.088
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.121
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_vit_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.359
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_layernorm_parameters_weight_:
    name = "L_self_modules_vit_modules_layernorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.915
    std = 0.120
    data = None


class Program_weight_tensor_meta_L_self_modules_vit_modules_layernorm_parameters_bias_:
    name = "L_self_modules_vit_modules_layernorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.019
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_classifier_parameters_weight_:
    name = "L_self_modules_classifier_parameters_weight_"
    shape = [1000, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.030
    data = None


class Program_weight_tensor_meta_L_self_modules_classifier_parameters_bias_:
    name = "L_self_modules_classifier_parameters_bias_"
    shape = [1000]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.017
    data = None
