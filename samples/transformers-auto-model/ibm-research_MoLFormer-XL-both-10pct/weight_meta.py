class Program_weight_tensor_meta_dict_getitem_L_stack0_list_dict_keys_L_stack0_0_:
    name = "dict_getitem_L_stack0_list_dict_keys_L_stack0_0_"
    shape = [1, 16, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 1.000
    data = None


class Program_weight_tensor_meta_L_self_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_attention_mask_:
    name = "L_attention_mask_"
    shape = [1, 16]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
