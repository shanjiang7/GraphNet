class Program_weight_tensor_meta_L_input_ids_:
    name = "L_input_ids_"
    shape = [1, 15]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [
        0,
        6524,
        11727,
        24447,
        83,
        11814,
        47,
        125663,
        181135,
        43315,
        6,
        41382,
        7,
        5,
        2,
    ]


class Program_weight_tensor_meta_L_self_modules_embeddings_buffers_token_type_ids_:
    name = "L_self_modules_embeddings_buffers_token_type_ids_"
    shape = [1, 514]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
    ]


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_word_embeddings_parameters_weight_:
    name = "L_self_modules_embeddings_modules_word_embeddings_parameters_weight_"
    shape = [250002, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.154
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_:
    name = "L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_"
    shape = [1, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_position_embeddings_parameters_weight_:
    name = "L_self_modules_embeddings_modules_position_embeddings_parameters_weight_"
    shape = [514, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_embeddings_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.311
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_embeddings_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_attention_mask_:
    name = "L_attention_mask_"
    shape = [1, 15]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.111
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.407
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.006
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.530
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.113
    std = 0.117
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.014
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.086
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.458
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.029
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.246
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.011
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.554
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.135
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.015
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.067
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.529
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.011
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.223
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.013
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.604
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.122
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.015
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.071
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.569
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.011
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.206
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.646
    std = 0.128
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.121
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.016
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.072
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.570
    std = 0.110
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.011
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.011
    std = 0.219
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.032
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.613
    std = 0.193
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.111
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.017
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.075
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.542
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.224
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.038
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.646
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.117
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.017
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.079
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.547
    std = 0.121
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.024
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.060
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.636
    std = 0.193
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.111
    std = 0.065
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.016
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.078
    std = 0.093
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.551
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_6_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.227
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.656
    std = 0.185
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.109
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.015
    std = 0.064
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.093
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.081
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.590
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_7_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.023
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.195
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.100
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.595
    std = 0.198
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.061
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.088
    std = 0.108
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.085
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.584
    std = 0.118
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_8_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.028
    std = 0.033
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.206
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.103
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.022
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.587
    std = 0.174
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.067
    std = 0.055
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.080
    std = 0.097
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.636
    std = 0.086
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_9_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.037
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.221
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.115
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.011
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.578
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.066
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.059
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.666
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_10_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.025
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.070
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.010
    std = 0.205
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.074
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.006
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.602
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.060
    std = 0.080
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.057
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.041
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.627
    std = 0.101
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_11_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.040
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_pooler_modules_dense_parameters_weight_:
    name = "L_self_modules_pooler_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_pooler_modules_dense_parameters_bias_:
    name = "L_self_modules_pooler_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
