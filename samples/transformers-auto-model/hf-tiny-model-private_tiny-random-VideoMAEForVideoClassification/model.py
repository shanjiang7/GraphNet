import torch

from torch import device


class GraphModule(torch.nn.Module):
    def forward(
        self,
        s59: torch.SymInt,
        L_pixel_values_: torch.Tensor,
        L_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_embeddings_position_embeddings: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_q_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_v_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_scaling: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_q_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_v_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_scaling: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_q_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_v_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_scaling: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_q_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_v_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_scaling: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_q_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_v_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_scaling: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_eps: torch.Tensor,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dropout_p: torch.Tensor,
        L_self_modules_fc_norm_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_fc_norm_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_fc_norm_eps: torch.Tensor,
        L_self_modules_classifier_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_classifier_parameters_bias_: torch.nn.parameter.Parameter,
    ):
        l_pixel_values_ = L_pixel_values_
        l_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_ = L_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_
        l_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_ = L_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_
        l_self_modules_videomae_modules_embeddings_position_embeddings = (
            L_self_modules_videomae_modules_embeddings_position_embeddings
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_q_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_q_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_v_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_v_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_scaling = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_scaling
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_q_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_q_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_v_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_v_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_scaling = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_scaling
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_q_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_q_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_v_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_v_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_scaling = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_scaling
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_q_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_q_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_v_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_v_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_scaling = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_scaling
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_q_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_q_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_v_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_v_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_scaling = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_scaling
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dropout_p
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_eps = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_eps
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_ = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dropout_p = L_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dropout_p
        l_self_modules_fc_norm_parameters_weight_ = (
            L_self_modules_fc_norm_parameters_weight_
        )
        l_self_modules_fc_norm_parameters_bias_ = (
            L_self_modules_fc_norm_parameters_bias_
        )
        l_self_modules_fc_norm_eps = L_self_modules_fc_norm_eps
        l_self_modules_classifier_parameters_weight_ = (
            L_self_modules_classifier_parameters_weight_
        )
        l_self_modules_classifier_parameters_bias_ = (
            L_self_modules_classifier_parameters_bias_
        )
        pixel_values = l_pixel_values_.permute(0, 2, 1, 3, 4)
        l_pixel_values_ = None
        conv3d = torch.conv3d(
            pixel_values,
            l_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_,
            l_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_,
            (2, 2, 2),
            (0, 0, 0),
            (1, 1, 1),
            1,
        )
        pixel_values = l_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_weight_ = l_self_modules_videomae_modules_embeddings_modules_patch_embeddings_modules_projection_parameters_bias_ = (None)
        flatten = conv3d.flatten(2)
        conv3d = None
        embeddings = flatten.transpose(1, 2)
        flatten = None
        detach = l_self_modules_videomae_modules_embeddings_position_embeddings.detach()
        l_self_modules_videomae_modules_embeddings_position_embeddings = None
        type_as = detach.type_as(embeddings)
        detach = None
        to = type_as.to(device=device(type="cuda", index=0), copy=True)
        type_as = None
        embeddings_1 = embeddings + to
        embeddings = to = None
        item = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_eps = (
            None
        )
        layer_norm = torch.nn.functional.layer_norm(
            embeddings_1,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_,
            item,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_before_parameters_bias_ = (item) = (
            None
        )
        k_bias = torch.zeros_like(
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_v_bias_,
            requires_grad=False,
        )
        keys = torch._C._nn.linear(
            input=layer_norm,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_,
            bias=k_bias,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_key_parameters_weight_ = (
            k_bias
        ) = None
        values = torch._C._nn.linear(
            input=layer_norm,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_v_bias_,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_value_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_v_bias_ = (None)
        queries = torch._C._nn.linear(
            input=layer_norm,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_q_bias_,
        )
        layer_norm = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_modules_query_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_parameters_q_bias_ = (None)
        view = keys.view(1, -1, 4, 8)
        keys = None
        key_layer = view.transpose(1, 2)
        view = None
        view_1 = values.view(1, -1, 4, 8)
        values = None
        value_layer = view_1.transpose(1, 2)
        view_1 = None
        view_2 = queries.view(1, -1, 4, 8)
        queries = None
        query_layer = view_2.transpose(1, 2)
        view_2 = None
        query = query_layer.contiguous()
        query_layer = None
        key = key_layer.contiguous()
        key_layer = None
        value = value_layer.contiguous()
        value_layer = None
        item_1 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_scaling.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_attention_scaling = (
            None
        )
        attn_output = torch._C._nn.scaled_dot_product_attention(
            query,
            key,
            value,
            attn_mask=None,
            dropout_p=0.0,
            scale=item_1,
            is_causal=False,
        )
        query = key = value = item_1 = None
        transpose_4 = attn_output.transpose(1, 2)
        attn_output = None
        attn_output_1 = transpose_4.contiguous()
        transpose_4 = None
        context_layer = attn_output_1.reshape((1, 25, 32))
        attn_output_1 = None
        hidden_states = torch._C._nn.linear(
            context_layer,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_,
        )
        context_layer = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_ = (None)
        item_2 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_1 = torch.nn.functional.dropout(
            hidden_states, item_2, False, False
        )
        hidden_states = item_2 = None
        hidden_states_2 = hidden_states_1 + embeddings_1
        hidden_states_1 = embeddings_1 = None
        item_3 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_eps = (
            None
        )
        layer_output = torch.nn.functional.layer_norm(
            hidden_states_2,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_,
            item_3,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_layernorm_after_parameters_bias_ = (item_3) = (
            None
        )
        hidden_states_3 = torch._C._nn.linear(
            layer_output,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_,
        )
        layer_output = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_ = (None)
        hidden_states_4 = torch._C._nn.gelu(hidden_states_3)
        hidden_states_3 = None
        hidden_states_5 = torch._C._nn.linear(
            hidden_states_4,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_,
        )
        hidden_states_4 = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_ = (None)
        item_4 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_0_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_6 = torch.nn.functional.dropout(
            hidden_states_5, item_4, False, False
        )
        hidden_states_5 = item_4 = None
        hidden_states_7 = hidden_states_6 + hidden_states_2
        hidden_states_6 = hidden_states_2 = None
        item_5 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_eps = (
            None
        )
        layer_norm_2 = torch.nn.functional.layer_norm(
            hidden_states_7,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_,
            item_5,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_before_parameters_bias_ = (item_5) = (
            None
        )
        k_bias_1 = torch.zeros_like(
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_v_bias_,
            requires_grad=False,
        )
        keys_1 = torch._C._nn.linear(
            input=layer_norm_2,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_,
            bias=k_bias_1,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_key_parameters_weight_ = (
            k_bias_1
        ) = None
        values_1 = torch._C._nn.linear(
            input=layer_norm_2,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_v_bias_,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_value_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_v_bias_ = (None)
        queries_1 = torch._C._nn.linear(
            input=layer_norm_2,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_q_bias_,
        )
        layer_norm_2 = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_modules_query_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_parameters_q_bias_ = (None)
        view_3 = keys_1.view(1, -1, 4, 8)
        keys_1 = None
        key_layer_1 = view_3.transpose(1, 2)
        view_3 = None
        view_4 = values_1.view(1, -1, 4, 8)
        values_1 = None
        value_layer_1 = view_4.transpose(1, 2)
        view_4 = None
        view_5 = queries_1.view(1, -1, 4, 8)
        queries_1 = None
        query_layer_1 = view_5.transpose(1, 2)
        view_5 = None
        query_1 = query_layer_1.contiguous()
        query_layer_1 = None
        key_1 = key_layer_1.contiguous()
        key_layer_1 = None
        value_1 = value_layer_1.contiguous()
        value_layer_1 = None
        item_6 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_scaling.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_attention_scaling = (
            None
        )
        attn_output_2 = torch._C._nn.scaled_dot_product_attention(
            query_1,
            key_1,
            value_1,
            attn_mask=None,
            dropout_p=0.0,
            scale=item_6,
            is_causal=False,
        )
        query_1 = key_1 = value_1 = item_6 = None
        transpose_8 = attn_output_2.transpose(1, 2)
        attn_output_2 = None
        attn_output_3 = transpose_8.contiguous()
        transpose_8 = None
        context_layer_1 = attn_output_3.reshape((1, 25, 32))
        attn_output_3 = None
        hidden_states_8 = torch._C._nn.linear(
            context_layer_1,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_,
        )
        context_layer_1 = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_ = (None)
        item_7 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_9 = torch.nn.functional.dropout(
            hidden_states_8, item_7, False, False
        )
        hidden_states_8 = item_7 = None
        hidden_states_10 = hidden_states_9 + hidden_states_7
        hidden_states_9 = hidden_states_7 = None
        item_8 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_eps = (
            None
        )
        layer_output_1 = torch.nn.functional.layer_norm(
            hidden_states_10,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_,
            item_8,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_layernorm_after_parameters_bias_ = (item_8) = (
            None
        )
        hidden_states_11 = torch._C._nn.linear(
            layer_output_1,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_,
        )
        layer_output_1 = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_ = (None)
        hidden_states_12 = torch._C._nn.gelu(hidden_states_11)
        hidden_states_11 = None
        hidden_states_13 = torch._C._nn.linear(
            hidden_states_12,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_,
        )
        hidden_states_12 = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_ = (None)
        item_9 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_1_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_14 = torch.nn.functional.dropout(
            hidden_states_13, item_9, False, False
        )
        hidden_states_13 = item_9 = None
        hidden_states_15 = hidden_states_14 + hidden_states_10
        hidden_states_14 = hidden_states_10 = None
        item_10 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_eps = (
            None
        )
        layer_norm_4 = torch.nn.functional.layer_norm(
            hidden_states_15,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_,
            item_10,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_before_parameters_bias_ = (item_10) = (
            None
        )
        k_bias_2 = torch.zeros_like(
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_v_bias_,
            requires_grad=False,
        )
        keys_2 = torch._C._nn.linear(
            input=layer_norm_4,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_,
            bias=k_bias_2,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_key_parameters_weight_ = (
            k_bias_2
        ) = None
        values_2 = torch._C._nn.linear(
            input=layer_norm_4,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_v_bias_,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_value_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_v_bias_ = (None)
        queries_2 = torch._C._nn.linear(
            input=layer_norm_4,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_q_bias_,
        )
        layer_norm_4 = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_modules_query_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_parameters_q_bias_ = (None)
        view_6 = keys_2.view(1, -1, 4, 8)
        keys_2 = None
        key_layer_2 = view_6.transpose(1, 2)
        view_6 = None
        view_7 = values_2.view(1, -1, 4, 8)
        values_2 = None
        value_layer_2 = view_7.transpose(1, 2)
        view_7 = None
        view_8 = queries_2.view(1, -1, 4, 8)
        queries_2 = None
        query_layer_2 = view_8.transpose(1, 2)
        view_8 = None
        query_2 = query_layer_2.contiguous()
        query_layer_2 = None
        key_2 = key_layer_2.contiguous()
        key_layer_2 = None
        value_2 = value_layer_2.contiguous()
        value_layer_2 = None
        item_11 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_scaling.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_attention_scaling = (
            None
        )
        attn_output_4 = torch._C._nn.scaled_dot_product_attention(
            query_2,
            key_2,
            value_2,
            attn_mask=None,
            dropout_p=0.0,
            scale=item_11,
            is_causal=False,
        )
        query_2 = key_2 = value_2 = item_11 = None
        transpose_12 = attn_output_4.transpose(1, 2)
        attn_output_4 = None
        attn_output_5 = transpose_12.contiguous()
        transpose_12 = None
        context_layer_2 = attn_output_5.reshape((1, 25, 32))
        attn_output_5 = None
        hidden_states_16 = torch._C._nn.linear(
            context_layer_2,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_,
        )
        context_layer_2 = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_ = (None)
        item_12 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_17 = torch.nn.functional.dropout(
            hidden_states_16, item_12, False, False
        )
        hidden_states_16 = item_12 = None
        hidden_states_18 = hidden_states_17 + hidden_states_15
        hidden_states_17 = hidden_states_15 = None
        item_13 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_eps = (
            None
        )
        layer_output_2 = torch.nn.functional.layer_norm(
            hidden_states_18,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_,
            item_13,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_layernorm_after_parameters_bias_ = (item_13) = (
            None
        )
        hidden_states_19 = torch._C._nn.linear(
            layer_output_2,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_,
        )
        layer_output_2 = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_ = (None)
        hidden_states_20 = torch._C._nn.gelu(hidden_states_19)
        hidden_states_19 = None
        hidden_states_21 = torch._C._nn.linear(
            hidden_states_20,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_,
        )
        hidden_states_20 = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_ = (None)
        item_14 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_2_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_22 = torch.nn.functional.dropout(
            hidden_states_21, item_14, False, False
        )
        hidden_states_21 = item_14 = None
        hidden_states_23 = hidden_states_22 + hidden_states_18
        hidden_states_22 = hidden_states_18 = None
        item_15 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_eps = (
            None
        )
        layer_norm_6 = torch.nn.functional.layer_norm(
            hidden_states_23,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_,
            item_15,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_before_parameters_bias_ = (item_15) = (
            None
        )
        k_bias_3 = torch.zeros_like(
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_v_bias_,
            requires_grad=False,
        )
        keys_3 = torch._C._nn.linear(
            input=layer_norm_6,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_,
            bias=k_bias_3,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_key_parameters_weight_ = (
            k_bias_3
        ) = None
        values_3 = torch._C._nn.linear(
            input=layer_norm_6,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_v_bias_,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_value_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_v_bias_ = (None)
        queries_3 = torch._C._nn.linear(
            input=layer_norm_6,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_q_bias_,
        )
        layer_norm_6 = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_modules_query_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_parameters_q_bias_ = (None)
        view_9 = keys_3.view(1, -1, 4, 8)
        keys_3 = None
        key_layer_3 = view_9.transpose(1, 2)
        view_9 = None
        view_10 = values_3.view(1, -1, 4, 8)
        values_3 = None
        value_layer_3 = view_10.transpose(1, 2)
        view_10 = None
        view_11 = queries_3.view(1, -1, 4, 8)
        queries_3 = None
        query_layer_3 = view_11.transpose(1, 2)
        view_11 = None
        query_3 = query_layer_3.contiguous()
        query_layer_3 = None
        key_3 = key_layer_3.contiguous()
        key_layer_3 = None
        value_3 = value_layer_3.contiguous()
        value_layer_3 = None
        item_16 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_scaling.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_attention_scaling = (
            None
        )
        attn_output_6 = torch._C._nn.scaled_dot_product_attention(
            query_3,
            key_3,
            value_3,
            attn_mask=None,
            dropout_p=0.0,
            scale=item_16,
            is_causal=False,
        )
        query_3 = key_3 = value_3 = item_16 = None
        transpose_16 = attn_output_6.transpose(1, 2)
        attn_output_6 = None
        attn_output_7 = transpose_16.contiguous()
        transpose_16 = None
        context_layer_3 = attn_output_7.reshape((1, 25, 32))
        attn_output_7 = None
        hidden_states_24 = torch._C._nn.linear(
            context_layer_3,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_,
        )
        context_layer_3 = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_ = (None)
        item_17 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_25 = torch.nn.functional.dropout(
            hidden_states_24, item_17, False, False
        )
        hidden_states_24 = item_17 = None
        hidden_states_26 = hidden_states_25 + hidden_states_23
        hidden_states_25 = hidden_states_23 = None
        item_18 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_eps = (
            None
        )
        layer_output_3 = torch.nn.functional.layer_norm(
            hidden_states_26,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_,
            item_18,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_layernorm_after_parameters_bias_ = (item_18) = (
            None
        )
        hidden_states_27 = torch._C._nn.linear(
            layer_output_3,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_,
        )
        layer_output_3 = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_ = (None)
        hidden_states_28 = torch._C._nn.gelu(hidden_states_27)
        hidden_states_27 = None
        hidden_states_29 = torch._C._nn.linear(
            hidden_states_28,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_,
        )
        hidden_states_28 = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_ = (None)
        item_19 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_3_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_30 = torch.nn.functional.dropout(
            hidden_states_29, item_19, False, False
        )
        hidden_states_29 = item_19 = None
        hidden_states_31 = hidden_states_30 + hidden_states_26
        hidden_states_30 = hidden_states_26 = None
        item_20 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_eps = (
            None
        )
        layer_norm_8 = torch.nn.functional.layer_norm(
            hidden_states_31,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_,
            item_20,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_before_parameters_bias_ = (item_20) = (
            None
        )
        k_bias_4 = torch.zeros_like(
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_v_bias_,
            requires_grad=False,
        )
        keys_4 = torch._C._nn.linear(
            input=layer_norm_8,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_,
            bias=k_bias_4,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_key_parameters_weight_ = (
            k_bias_4
        ) = None
        values_4 = torch._C._nn.linear(
            input=layer_norm_8,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_v_bias_,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_value_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_v_bias_ = (None)
        queries_4 = torch._C._nn.linear(
            input=layer_norm_8,
            weight=l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_,
            bias=l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_q_bias_,
        )
        layer_norm_8 = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_modules_query_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_parameters_q_bias_ = (None)
        view_12 = keys_4.view(1, -1, 4, 8)
        keys_4 = None
        key_layer_4 = view_12.transpose(1, 2)
        view_12 = None
        view_13 = values_4.view(1, -1, 4, 8)
        values_4 = None
        value_layer_4 = view_13.transpose(1, 2)
        view_13 = None
        view_14 = queries_4.view(1, -1, 4, 8)
        queries_4 = None
        query_layer_4 = view_14.transpose(1, 2)
        view_14 = None
        query_4 = query_layer_4.contiguous()
        query_layer_4 = None
        key_4 = key_layer_4.contiguous()
        key_layer_4 = None
        value_4 = value_layer_4.contiguous()
        value_layer_4 = None
        item_21 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_scaling.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_attention_scaling = (
            None
        )
        attn_output_8 = torch._C._nn.scaled_dot_product_attention(
            query_4,
            key_4,
            value_4,
            attn_mask=None,
            dropout_p=0.0,
            scale=item_21,
            is_causal=False,
        )
        query_4 = key_4 = value_4 = item_21 = None
        transpose_20 = attn_output_8.transpose(1, 2)
        attn_output_8 = None
        attn_output_9 = transpose_20.contiguous()
        transpose_20 = None
        context_layer_4 = attn_output_9.reshape((1, 25, 32))
        attn_output_9 = None
        hidden_states_32 = torch._C._nn.linear(
            context_layer_4,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_,
        )
        context_layer_4 = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_ = (None)
        item_22 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_33 = torch.nn.functional.dropout(
            hidden_states_32, item_22, False, False
        )
        hidden_states_32 = item_22 = None
        hidden_states_34 = hidden_states_33 + hidden_states_31
        hidden_states_33 = hidden_states_31 = None
        item_23 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_eps.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_eps = (
            None
        )
        layer_output_4 = torch.nn.functional.layer_norm(
            hidden_states_34,
            (32,),
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_,
            item_23,
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_layernorm_after_parameters_bias_ = (item_23) = (
            None
        )
        hidden_states_35 = torch._C._nn.linear(
            layer_output_4,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_,
        )
        layer_output_4 = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_ = (None)
        hidden_states_36 = torch._C._nn.gelu(hidden_states_35)
        hidden_states_35 = None
        hidden_states_37 = torch._C._nn.linear(
            hidden_states_36,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_,
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_,
        )
        hidden_states_36 = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_ = l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_ = (None)
        item_24 = (
            l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dropout_p.item()
        )
        l_self_modules_videomae_modules_encoder_modules_layer_modules_4_modules_output_modules_dropout_p = (
            None
        )
        hidden_states_38 = torch.nn.functional.dropout(
            hidden_states_37, item_24, False, False
        )
        hidden_states_37 = item_24 = None
        hidden_states_39 = hidden_states_38 + hidden_states_34
        hidden_states_38 = hidden_states_34 = None
        mean = hidden_states_39.mean(1)
        hidden_states_39 = None
        item_25 = l_self_modules_fc_norm_eps.item()
        l_self_modules_fc_norm_eps = None
        sequence_output = torch.nn.functional.layer_norm(
            mean,
            (32,),
            l_self_modules_fc_norm_parameters_weight_,
            l_self_modules_fc_norm_parameters_bias_,
            item_25,
        )
        mean = (
            l_self_modules_fc_norm_parameters_weight_
        ) = l_self_modules_fc_norm_parameters_bias_ = item_25 = None
        logits = torch._C._nn.linear(
            sequence_output,
            l_self_modules_classifier_parameters_weight_,
            l_self_modules_classifier_parameters_bias_,
        )
        sequence_output = (
            l_self_modules_classifier_parameters_weight_
        ) = l_self_modules_classifier_parameters_bias_ = None
        return (logits,)
