class Program_weight_tensor_meta_L_stack0_0_:
    name = "L_stack0_0_"
    shape = [1, 1024, 261]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.026
    std = 0.733
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_parameters_latents_:
    name = "L_self_modules_embeddings_parameters_latents_"
    shape = [10, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_"
    shape = [261]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_"
    shape = [261]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 261]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 261]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_weight_"
    shape = [80, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_bias_"
    shape = [80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_weight_"
    shape = [80, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_bias_"
    shape = [80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_weight_"
    shape = [80, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_bias_"
    shape = [80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_output_position_encodings_parameters_position_embeddings_:
    name = "L_self_modules_decoder_modules_decoder_modules_output_position_encodings_parameters_position_embeddings_"
    shape = [1, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.018
    data = [
        -0.008924,
        0.004520,
        0.015481,
        -0.006212,
        0.002875,
        -0.008362,
        0.036762,
        0.005362,
        0.026317,
        -0.007159,
        -0.036784,
        -0.004037,
        -0.013471,
        0.031348,
        0.005639,
        0.005902,
        -0.031632,
        -0.007781,
        -0.004648,
        -0.005566,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_weight_:
    name = (
        "L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_weight_"
    )
    shape = [3, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.022
    data = [
        0.028681,
        0.005194,
        0.029836,
        -0.044068,
        0.025449,
        -0.013126,
        0.044157,
        0.021151,
        -0.012244,
        0.018111,
        -0.008838,
        0.015279,
        -0.059178,
        -0.022229,
        0.028377,
        -0.001784,
        -0.012895,
        -0.003295,
        -0.005008,
        0.017276,
        -0.031073,
        0.006107,
        0.009448,
        0.003623,
        -0.001383,
        -0.007632,
        -0.043962,
        0.006175,
        0.002248,
        0.005773,
        0.015859,
        0.023643,
        0.033644,
        0.014008,
        0.006422,
        0.024558,
        0.009753,
        0.022174,
        -0.021022,
        0.007002,
        0.018620,
        0.007982,
        0.059191,
        0.011560,
        -0.013005,
        -0.015582,
        0.017318,
        -0.019232,
        0.029719,
        0.003482,
        0.003771,
        0.006940,
        -0.034798,
        0.015296,
        0.008977,
        -0.028775,
        -0.002056,
        0.016101,
        0.020489,
        0.011389,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_bias_"
    shape = [3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [0.000000, 0.000000, 0.000000]
