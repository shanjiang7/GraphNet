dynamic_dim_constraint_symbols = []

dynamic_dim_constraint_symbol2example_value = {}

dynamic_dim_constraint_relations = []

dynamic_dim_constraint_input_shapes = [
    ([1, 18], "L_attention_mask_"),
    ([1, 18], "L_input_ids_"),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_0_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_0_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_0_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_0_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_10_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_10_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_10_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_10_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_11_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_11_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_11_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_11_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_12_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_12_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_12_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_12_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_13_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_13_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_13_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_13_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_14_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_14_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_14_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_14_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_15_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_15_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_15_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_15_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_16_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_16_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_16_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_16_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_17_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_17_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_17_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_17_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_18_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_18_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_18_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_18_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_19_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_19_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_19_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_19_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_1_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_1_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_1_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_1_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_20_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_20_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_20_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_20_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_21_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_21_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_21_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_21_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_22_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_22_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_22_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_22_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_23_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_23_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_23_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_23_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_2_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_2_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_2_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_2_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_3_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_3_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_3_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_3_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_4_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_4_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_4_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_4_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_5_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_5_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_5_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_5_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_6_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_6_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_6_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_6_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_7_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_7_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_7_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_7_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_8_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_8_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_8_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_8_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_input_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_input_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_mlp_modules_dense_4h_to_h_parameters_bias_",
    ),
    (
        [1024, 4096],
        "L_self_modules_transformer_modules_h_modules_9_modules_mlp_modules_dense_4h_to_h_parameters_weight_",
    ),
    (
        [4096],
        "L_self_modules_transformer_modules_h_modules_9_modules_mlp_modules_dense_h_to_4h_parameters_bias_",
    ),
    (
        [4096, 1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_mlp_modules_dense_h_to_4h_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_post_attention_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_post_attention_layernorm_parameters_weight_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_self_attention_modules_dense_parameters_bias_",
    ),
    (
        [1024, 1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_self_attention_modules_dense_parameters_weight_",
    ),
    (
        [3072],
        "L_self_modules_transformer_modules_h_modules_9_modules_self_attention_modules_query_key_value_parameters_bias_",
    ),
    (
        [3072, 1024],
        "L_self_modules_transformer_modules_h_modules_9_modules_self_attention_modules_query_key_value_parameters_weight_",
    ),
    ([1024], "L_self_modules_transformer_modules_ln_f_parameters_bias_"),
    ([1024], "L_self_modules_transformer_modules_ln_f_parameters_weight_"),
    (
        [1024],
        "L_self_modules_transformer_modules_word_embeddings_layernorm_parameters_bias_",
    ),
    (
        [1024],
        "L_self_modules_transformer_modules_word_embeddings_layernorm_parameters_weight_",
    ),
    (
        [250880, 1024],
        "L_self_modules_transformer_modules_word_embeddings_parameters_weight_",
    ),
]
