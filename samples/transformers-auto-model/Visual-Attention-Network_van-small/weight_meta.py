class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [64, 3, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_pixel_values_:
    name = "L_pixel_values_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -1.986
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.175
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.481
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.286
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.204
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.178
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.179
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.479
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [128, 64, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.285
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.126
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.473
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [128, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.278
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [128, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [128, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.124
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 128, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [128, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.125
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_weight_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_bias_"
    shape = [128]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [320, 128, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.278
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.198
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [320, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [320, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.205
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_"
    shape = [320, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_var_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1280, 320, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.039
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1280, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.479
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1280]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [320, 1280, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.079
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_weight_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_bias_"
    shape = [320]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [512, 320, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.283
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [512, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [2048, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [2048, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.473
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [512, 2048, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [512, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [512, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [2048, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [2048, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.471
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [2048]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [512, 2048, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
