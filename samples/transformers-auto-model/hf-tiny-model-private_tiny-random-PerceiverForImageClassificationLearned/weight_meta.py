class Program_weight_tensor_meta_L_stack0_0_:
    name = "L_stack0_0_"
    shape = [1, 1024, 512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_parameters_latents_:
    name = "L_self_modules_embeddings_parameters_latents_"
    shape = [10, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_weight_"
    shape = [80, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense1_parameters_bias_"
    shape = [80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_encoder_modules_cross_attention_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_weight_"
    shape = [80, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense1_parameters_bias_"
    shape = [80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_0_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_weight_"
    shape = [80, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense1_parameters_bias_"
    shape = [80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 80]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_encoder_modules_self_attends_modules_1_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_output_position_encodings_parameters_position_embeddings_:
    name = "L_self_modules_decoder_modules_decoder_modules_output_position_encodings_parameters_position_embeddings_"
    shape = [1, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.019
    data = [
        -0.003601,
        0.026426,
        0.017290,
        -0.011395,
        0.033659,
        0.010905,
        -0.008028,
        -0.006517,
        0.012684,
        -0.001443,
        -0.002703,
        -0.011549,
        0.006531,
        0.004453,
        -0.008824,
        0.035614,
        0.019448,
        -0.036439,
        0.035776,
        -0.005519,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_layernorm2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_weight_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_layernorm_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense1_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_weight_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_weight_"
    shape = [20, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_decoding_cross_attention_modules_mlp_modules_dense2_parameters_bias_"
    shape = [20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_weight_:
    name = (
        "L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_weight_"
    )
    shape = [3, 20]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.019
    data = [
        0.006502,
        0.025948,
        0.021233,
        -0.036946,
        0.003752,
        -0.046810,
        0.027476,
        0.024025,
        -0.011493,
        -0.014463,
        0.009046,
        0.013568,
        0.027874,
        -0.010145,
        -0.007805,
        -0.009907,
        0.026799,
        0.022345,
        -0.017190,
        -0.003218,
        -0.022770,
        -0.013771,
        0.003462,
        -0.030950,
        -0.003025,
        0.001099,
        -0.010374,
        -0.003415,
        -0.000410,
        0.008782,
        0.025296,
        -0.015687,
        -0.008604,
        -0.023173,
        0.005547,
        0.012840,
        0.000331,
        -0.050241,
        -0.004858,
        -0.037741,
        -0.032584,
        0.027369,
        0.003037,
        -0.027829,
        0.005852,
        0.010463,
        -0.029258,
        -0.004914,
        -0.007742,
        -0.010712,
        -0.031307,
        0.017362,
        -0.006953,
        0.015517,
        -0.019186,
        -0.000996,
        -0.010307,
        0.011006,
        -0.007186,
        0.003146,
    ]


class Program_weight_tensor_meta_L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_bias_:
    name = "L_self_modules_decoder_modules_decoder_modules_final_layer_parameters_bias_"
    shape = [3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [0.000000, 0.000000, 0.000000]
