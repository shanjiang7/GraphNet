class Program_weight_tensor_meta_L_input_ids_:
    name = "L_input_ids_"
    shape = [1, 11]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [0, 45288, 15721, 16, 341, 7, 14660, 38163, 36386, 4, 2]


class Program_weight_tensor_meta_L_self_modules_embeddings_buffers_token_type_ids_:
    name = "L_self_modules_embeddings_buffers_token_type_ids_"
    shape = [1, 514]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
    ]


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_word_embeddings_parameters_weight_:
    name = "L_self_modules_embeddings_modules_word_embeddings_parameters_weight_"
    shape = [50265, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.011
    std = 0.130
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_:
    name = "L_self_modules_embeddings_modules_token_type_embeddings_parameters_weight_"
    shape = [1, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_position_embeddings_parameters_weight_:
    name = "L_self_modules_embeddings_modules_position_embeddings_parameters_weight_"
    shape = [514, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_embeddings_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.349
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_embeddings_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_embeddings_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_attention_mask_:
    name = "L_attention_mask_"
    shape = [1, 11]
    dtype = "torch.int64"
    device = "cuda:0"
    mean = None
    std = None
    data = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.015
    std = 0.362
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.104
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.001
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.040
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.541
    std = 0.094
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.102
    std = 0.182
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.100
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.047
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.082
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.557
    std = 0.123
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_0_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.033
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.021
    std = 0.174
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.003
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.034
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.043
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.682
    std = 0.143
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.094
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.010
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.093
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.050
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.090
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.627
    std = 0.139
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_1_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.035
    std = 0.053
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.075
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.138
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.072
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.002
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.763
    std = 0.142
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.079
    std = 0.066
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.082
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.078
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.692
    std = 0.139
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_2_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.032
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.076
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.092
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.073
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.017
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.028
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.756
    std = 0.144
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.065
    std = 0.061
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.057
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.073
    std = 0.095
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.046
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.062
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.734
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_3_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.034
    std = 0.035
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.071
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.129
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.069
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.025
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.048
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.026
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.779
    std = 0.131
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.079
    std = 0.051
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.049
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.068
    std = 0.084
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.740
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_4_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.035
    std = 0.042
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.068
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_query_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.145
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.067
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_key_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.013
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.052
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_self_modules_value_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.015
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.083
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.651
    std = 0.077
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_attention_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.084
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_weight_"
    shape = [3072, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.008
    std = 0.045
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_intermediate_modules_dense_parameters_bias_"
    shape = [3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.054
    std = 0.054
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_weight_"
    shape = [768, 3072]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.058
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_weight_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_weight_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.717
    std = 0.114
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_bias_:
    name = "L_self_modules_encoder_modules_layer_modules_5_modules_output_modules_LayerNorm_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.043
    std = 0.031
    data = None


class Program_weight_tensor_meta_L_self_modules_pooler_modules_dense_parameters_weight_:
    name = "L_self_modules_pooler_modules_dense_parameters_weight_"
    shape = [768, 768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_pooler_modules_dense_parameters_bias_:
    name = "L_self_modules_pooler_modules_dense_parameters_bias_"
    shape = [768]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
