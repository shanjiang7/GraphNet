class Program_weight_tensor_meta_L_pixel_values_:
    name = "L_pixel_values_"
    shape = [1, 3, 64, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_weight_"
    shape = [16, 3, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_weight_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_before_parameters_weight_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_before_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [16, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [16, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [16, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.018
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [16, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_after_parameters_weight_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_layernorm_after_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_weight_"
    shape = [64, 16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_output_modules_dense_parameters_weight_"
    shape = [16, 64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_output_modules_dense_parameters_bias_"
    shape = [16]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_weight_"
    shape = [48, 16, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_before_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_before_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [48, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [48, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [48, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_after_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_layernorm_after_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_weight_"
    shape = [192, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_bias_"
    shape = [192]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_output_modules_dense_parameters_weight_"
    shape = [48, 192]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_output_modules_dense_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_before_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_before_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [48, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [48, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [48, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [48, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_after_parameters_weight_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_layernorm_after_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_weight_"
    shape = [192, 48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_bias_"
    shape = [192]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_output_modules_dense_parameters_weight_"
    shape = [48, 192]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_output_modules_dense_parameters_bias_"
    shape = [48]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_weight_"
    shape = [96, 48, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_projection_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embedding_modules_convolution_embeddings_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_parameters_cls_token_:
    name = "L_self_modules_encoder_modules_stages_modules_2_parameters_cls_token_"
    shape = [1, 1, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_5_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_6_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_7_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.019
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_8_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_before_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_before_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_before_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_before_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_key_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_query_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_convolution_parameters_weight_"
    shape = [96, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.021
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_mean_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_buffers_running_var_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_convolution_projection_value_modules_convolution_projection_modules_normalization_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_query_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_query_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_query_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_query_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_key_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_key_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_key_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_key_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_value_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_value_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_value_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_attention_modules_projection_value_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_output_modules_dense_parameters_weight_"
    shape = [96, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_attention_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_after_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_after_parameters_weight_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_after_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_layernorm_after_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_intermediate_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_intermediate_modules_dense_parameters_weight_"
    shape = [384, 96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_intermediate_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_intermediate_modules_dense_parameters_bias_"
    shape = [384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_output_modules_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_output_modules_dense_parameters_weight_"
    shape = [96, 384]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.020
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_output_modules_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_9_modules_output_modules_dense_parameters_bias_"
    shape = [96]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
