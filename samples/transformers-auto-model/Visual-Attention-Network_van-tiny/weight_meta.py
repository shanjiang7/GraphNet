class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [32, 3, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.036
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_pixel_values_:
    name = "L_pixel_values_"
    shape = [1, 3, 224, 224]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -1.986
    std = 0.133
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.010
    std = 0.242
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [32, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.009
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [32, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.205
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.242
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.246
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = [
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [256, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [256, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.016
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [32, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.250
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = [
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.018
    std = 0.253
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [32, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.010
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [32, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.207
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.244
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.256
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = [
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [256, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [256, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.016
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [32, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.004
    std = 0.246
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = [
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.258
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [32, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.008
    std = 0.284
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [32, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.207
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.258
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [32, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.254
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = [
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [256, 32, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.087
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [256, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.013
    std = 0.469
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [32, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.245
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = [
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
        0.010000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_weight_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = [
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
        1.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_0_modules_normalization_parameters_bias_"
    shape = [32]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = [
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
        0.000000,
    ]


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [64, 32, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.059
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.279
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.002
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.179
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.472
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.007
    std = 0.289
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.206
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.005
    std = 0.174
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.177
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.470
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.178
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [64, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.012
    std = 0.276
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [64, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.205
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.176
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [64, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.178
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [512, 64, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.063
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [512, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.474
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [512]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [64, 512, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.178
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_weight_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_1_modules_normalization_parameters_bias_"
    shape = [64]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [160, 64, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.037
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [160, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.285
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [160, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.204
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.113
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.111
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [640, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [640, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.467
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [160, 640, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [160, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.005
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [160, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [640, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [640, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.476
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [160, 640, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_pre_normomalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [160, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [160, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.201
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.111
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_modules_post_projection_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_attention_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_post_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [640, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [640, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.002
    std = 0.462
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [160, 640, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_2_modules_mlp_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_pre_normomalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [160, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.280
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [160, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.006
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.111
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.111
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_modules_post_projection_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_attention_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_post_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [640, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [640, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.007
    std = 0.465
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [160, 640, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_3_modules_mlp_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_pre_normomalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [160, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [160, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.001
    std = 0.200
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_weight_"
    shape = [160, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_modules_post_projection_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_attention_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_mean_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_buffers_running_var_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_post_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [640, 160, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.056
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [640, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.006
    std = 0.463
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [640]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [160, 640, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.112
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_layers_modules_4_modules_mlp_scaling_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_weight_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_2_modules_normalization_parameters_bias_"
    shape = [160]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_weight_"
    shape = [256, 160, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.029
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_convolution_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_mean_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_buffers_running_var_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_embeddings_modules_normalization_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_mean_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_buffers_running_var_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_pre_normomalization_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [256, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [256, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.003
    std = 0.281
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [256, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.202
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [256, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_weight_"
    shape = [256, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_modules_post_projection_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_attention_scaling_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_mean_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_buffers_running_var_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_post_normalization_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.475
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [256, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_0_modules_mlp_scaling_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_mean_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_buffers_running_var_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_pre_normomalization_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_weight_"
    shape = [256, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.089
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_pre_projection_modules_conv_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_weight_"
    shape = [256, 1, 5, 5]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.282
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_weight_"
    shape = [256, 1, 7, 7]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.004
    std = 0.203
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_depth_wise_dilated_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_weight_"
    shape = [256, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.001
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_attention_layer_modules_attention_modules_point_wise_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_weight_"
    shape = [256, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_modules_post_projection_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_attention_scaling_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_mean_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_var_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_buffers_running_var_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None
    min_val = 0


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_post_normalization_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_weight_"
    shape = [1024, 256, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = -0.000
    std = 0.044
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_in_dense_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_weight_"
    shape = [1024, 1, 3, 3]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.003
    std = 0.465
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_depth_wise_parameters_bias_"
    shape = [1024]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_weight_"
    shape = [256, 1024, 1, 1]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.088
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_modules_out_dense_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_layers_modules_1_modules_mlp_scaling_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.010
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_weight_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_weight_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 1.000
    std = 0.000
    data = None


class Program_weight_tensor_meta_L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_bias_:
    name = "L_self_modules_encoder_modules_stages_modules_3_modules_normalization_parameters_bias_"
    shape = [256]
    dtype = "torch.float32"
    device = "cuda:0"
    mean = 0.000
    std = 0.000
    data = None
