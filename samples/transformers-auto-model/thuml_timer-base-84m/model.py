import torch

from torch import device


class GraphModule(torch.nn.Module):
    def forward(
        self,
        L_input_ids_: torch.Tensor,
        L_self_modules_model_modules_embed_layer_modules_emb_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_cos_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_sin_cached_: torch.Tensor,
        L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_o_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_gate_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_up_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_down_proj_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_norm_parameters_weight_: torch.nn.parameter.Parameter,
        L_self_modules_model_modules_norm_parameters_bias_: torch.nn.parameter.Parameter,
        L_self_modules_lm_heads_modules_0_parameters_weight_: torch.nn.parameter.Parameter,
    ):
        l_input_ids_ = L_input_ids_
        l_self_modules_model_modules_embed_layer_modules_emb_parameters_weight_ = (
            L_self_modules_model_modules_embed_layer_modules_emb_parameters_weight_
        )
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_cos_cached_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_sin_cached_
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_o_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_o_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_bias_
        )
        l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_gate_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_gate_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_up_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_up_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_down_proj_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_down_proj_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_weight_ = L_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_weight_
        l_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_bias_ = (
            L_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_bias_
        )
        l_self_modules_model_modules_norm_parameters_weight_ = (
            L_self_modules_model_modules_norm_parameters_weight_
        )
        l_self_modules_model_modules_norm_parameters_bias_ = (
            L_self_modules_model_modules_norm_parameters_bias_
        )
        l_self_modules_lm_heads_modules_0_parameters_weight_ = (
            L_self_modules_lm_heads_modules_0_parameters_weight_
        )
        hidden_state = l_input_ids_.unfold(dimension=-1, size=96, step=96)
        l_input_ids_ = None
        inputs_embeds = torch._C._nn.linear(
            hidden_state,
            l_self_modules_model_modules_embed_layer_modules_emb_parameters_weight_,
            None,
        )
        hidden_state = (
            l_self_modules_model_modules_embed_layer_modules_emb_parameters_weight_
        ) = None
        position_ids = torch.arange(
            0, 30, dtype=torch.int64, device=device(type="cuda", index=0)
        )
        position_ids_1 = position_ids.view(-1, 30)
        position_ids = None
        mask = torch.full(
            (30, 30), -3.4028234663852886e38, device=device(type="cuda", index=0)
        )
        mask_cond = torch.arange(30, device=device(type="cuda", index=0))
        add = mask_cond + 1
        view_1 = add.view(30, 1)
        add = None
        lt = mask_cond < view_1
        mask_cond = view_1 = None
        masked_fill_ = mask.masked_fill_(lt, 0)
        lt = masked_fill_ = None
        mask_1 = mask.to(torch.float32)
        mask = None
        getitem = mask_1[(None, None, slice(None, None, None), slice(None, None, None))]
        mask_1 = None
        causal_4d_mask = getitem.expand(1, 1, 30, 30)
        getitem = None
        query_states = torch._C._nn.linear(
            inputs_embeds,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states = torch._C._nn.linear(
            inputs_embeds,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states = torch._C._nn.linear(
            inputs_embeds,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_2 = query_states.view(1, 30, 8, 128)
        query_states = None
        query_states_1 = view_2.transpose(1, 2)
        view_2 = None
        view_3 = key_states.view(1, 30, 8, 128)
        key_states = None
        key_states_1 = view_3.transpose(1, 2)
        view_3 = None
        view_4 = value_states.view(1, 30, 8, 128)
        value_states = None
        value_states_1 = view_4.transpose(1, 2)
        view_4 = None
        getitem_1 = l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos = getitem_1.to(dtype=torch.float32)
        getitem_1 = None
        getitem_2 = l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin = getitem_2.to(dtype=torch.float32)
        getitem_2 = None
        getitem_3 = cos[position_ids_1]
        cos = None
        cos_1 = getitem_3.unsqueeze(1)
        getitem_3 = None
        getitem_4 = sin[position_ids_1]
        sin = None
        sin_1 = getitem_4.unsqueeze(1)
        getitem_4 = None
        mul = query_states_1 * cos_1
        x1 = query_states_1[(Ellipsis, slice(None, 64, None))]
        x2 = query_states_1[(Ellipsis, slice(64, None, None))]
        query_states_1 = None
        neg = -x2
        x2 = None
        cat = torch.cat((neg, x1), dim=-1)
        neg = x1 = None
        mul_1 = cat * sin_1
        cat = None
        q_embed = mul + mul_1
        mul = mul_1 = None
        mul_2 = key_states_1 * cos_1
        cos_1 = None
        x1_1 = key_states_1[(Ellipsis, slice(None, 64, None))]
        x2_1 = key_states_1[(Ellipsis, slice(64, None, None))]
        key_states_1 = None
        neg_1 = -x2_1
        x2_1 = None
        cat_1 = torch.cat((neg_1, x1_1), dim=-1)
        neg_1 = x1_1 = None
        mul_3 = cat_1 * sin_1
        cat_1 = sin_1 = None
        k_embed = mul_2 + mul_3
        mul_2 = mul_3 = None
        attn_output = torch._C._nn.scaled_dot_product_attention(
            q_embed, k_embed, value_states_1, causal_4d_mask, dropout_p=0.0
        )
        q_embed = k_embed = value_states_1 = None
        transpose_3 = attn_output.transpose(1, 2)
        attn_output = None
        attn_output_1 = transpose_3.contiguous()
        transpose_3 = None
        attn_output_2 = attn_output_1.reshape(1, 30, 1024)
        attn_output_1 = None
        attn_output_3 = torch._C._nn.linear(
            attn_output_2,
            l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_2 = l_self_modules_model_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states = inputs_embeds + attn_output_3
        inputs_embeds = attn_output_3 = None
        hidden_states_1 = torch.nn.functional.layer_norm(
            hidden_states,
            (1024,),
            l_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states = l_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_0_modules_norm1_parameters_bias_
        ) = None
        linear_5 = torch._C._nn.linear(
            hidden_states_1,
            l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu = torch.nn.functional.silu(linear_5, inplace=False)
        linear_5 = None
        linear_6 = torch._C._nn.linear(
            hidden_states_1,
            l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_4 = silu * linear_6
        silu = linear_6 = None
        hidden_states_2 = torch._C._nn.linear(
            mul_4,
            l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_4 = l_self_modules_model_modules_layers_modules_0_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_3 = hidden_states_1 + hidden_states_2
        hidden_states_1 = hidden_states_2 = None
        hidden_states_4 = torch.nn.functional.layer_norm(
            hidden_states_3,
            (1024,),
            l_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_3 = l_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_0_modules_norm2_parameters_bias_
        ) = None
        query_states_2 = torch._C._nn.linear(
            hidden_states_4,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_2 = torch._C._nn.linear(
            hidden_states_4,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_2 = torch._C._nn.linear(
            hidden_states_4,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_5 = query_states_2.view(1, 30, 8, 128)
        query_states_2 = None
        query_states_3 = view_5.transpose(1, 2)
        view_5 = None
        view_6 = key_states_2.view(1, 30, 8, 128)
        key_states_2 = None
        key_states_3 = view_6.transpose(1, 2)
        view_6 = None
        view_7 = value_states_2.view(1, 30, 8, 128)
        value_states_2 = None
        value_states_3 = view_7.transpose(1, 2)
        view_7 = None
        getitem_9 = l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_2 = getitem_9.to(dtype=torch.float32)
        getitem_9 = None
        getitem_10 = l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_2 = getitem_10.to(dtype=torch.float32)
        getitem_10 = None
        getitem_11 = cos_2[position_ids_1]
        cos_2 = None
        cos_3 = getitem_11.unsqueeze(1)
        getitem_11 = None
        getitem_12 = sin_2[position_ids_1]
        sin_2 = None
        sin_3 = getitem_12.unsqueeze(1)
        getitem_12 = None
        mul_5 = query_states_3 * cos_3
        x1_2 = query_states_3[(Ellipsis, slice(None, 64, None))]
        x2_2 = query_states_3[(Ellipsis, slice(64, None, None))]
        query_states_3 = None
        neg_2 = -x2_2
        x2_2 = None
        cat_2 = torch.cat((neg_2, x1_2), dim=-1)
        neg_2 = x1_2 = None
        mul_6 = cat_2 * sin_3
        cat_2 = None
        q_embed_1 = mul_5 + mul_6
        mul_5 = mul_6 = None
        mul_7 = key_states_3 * cos_3
        cos_3 = None
        x1_3 = key_states_3[(Ellipsis, slice(None, 64, None))]
        x2_3 = key_states_3[(Ellipsis, slice(64, None, None))]
        key_states_3 = None
        neg_3 = -x2_3
        x2_3 = None
        cat_3 = torch.cat((neg_3, x1_3), dim=-1)
        neg_3 = x1_3 = None
        mul_8 = cat_3 * sin_3
        cat_3 = sin_3 = None
        k_embed_1 = mul_7 + mul_8
        mul_7 = mul_8 = None
        attn_output_4 = torch._C._nn.scaled_dot_product_attention(
            q_embed_1, k_embed_1, value_states_3, causal_4d_mask, dropout_p=0.0
        )
        q_embed_1 = k_embed_1 = value_states_3 = None
        transpose_7 = attn_output_4.transpose(1, 2)
        attn_output_4 = None
        attn_output_5 = transpose_7.contiguous()
        transpose_7 = None
        attn_output_6 = attn_output_5.reshape(1, 30, 1024)
        attn_output_5 = None
        attn_output_7 = torch._C._nn.linear(
            attn_output_6,
            l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_6 = l_self_modules_model_modules_layers_modules_1_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_5 = hidden_states_4 + attn_output_7
        hidden_states_4 = attn_output_7 = None
        hidden_states_6 = torch.nn.functional.layer_norm(
            hidden_states_5,
            (1024,),
            l_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_5 = l_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_1_modules_norm1_parameters_bias_
        ) = None
        linear_12 = torch._C._nn.linear(
            hidden_states_6,
            l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_1 = torch.nn.functional.silu(linear_12, inplace=False)
        linear_12 = None
        linear_13 = torch._C._nn.linear(
            hidden_states_6,
            l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_9 = silu_1 * linear_13
        silu_1 = linear_13 = None
        hidden_states_7 = torch._C._nn.linear(
            mul_9,
            l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_9 = l_self_modules_model_modules_layers_modules_1_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_8 = hidden_states_6 + hidden_states_7
        hidden_states_6 = hidden_states_7 = None
        hidden_states_9 = torch.nn.functional.layer_norm(
            hidden_states_8,
            (1024,),
            l_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_8 = l_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_1_modules_norm2_parameters_bias_
        ) = None
        query_states_4 = torch._C._nn.linear(
            hidden_states_9,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_4 = torch._C._nn.linear(
            hidden_states_9,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_4 = torch._C._nn.linear(
            hidden_states_9,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_8 = query_states_4.view(1, 30, 8, 128)
        query_states_4 = None
        query_states_5 = view_8.transpose(1, 2)
        view_8 = None
        view_9 = key_states_4.view(1, 30, 8, 128)
        key_states_4 = None
        key_states_5 = view_9.transpose(1, 2)
        view_9 = None
        view_10 = value_states_4.view(1, 30, 8, 128)
        value_states_4 = None
        value_states_5 = view_10.transpose(1, 2)
        view_10 = None
        getitem_17 = l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_4 = getitem_17.to(dtype=torch.float32)
        getitem_17 = None
        getitem_18 = l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_4 = getitem_18.to(dtype=torch.float32)
        getitem_18 = None
        getitem_19 = cos_4[position_ids_1]
        cos_4 = None
        cos_5 = getitem_19.unsqueeze(1)
        getitem_19 = None
        getitem_20 = sin_4[position_ids_1]
        sin_4 = None
        sin_5 = getitem_20.unsqueeze(1)
        getitem_20 = None
        mul_10 = query_states_5 * cos_5
        x1_4 = query_states_5[(Ellipsis, slice(None, 64, None))]
        x2_4 = query_states_5[(Ellipsis, slice(64, None, None))]
        query_states_5 = None
        neg_4 = -x2_4
        x2_4 = None
        cat_4 = torch.cat((neg_4, x1_4), dim=-1)
        neg_4 = x1_4 = None
        mul_11 = cat_4 * sin_5
        cat_4 = None
        q_embed_2 = mul_10 + mul_11
        mul_10 = mul_11 = None
        mul_12 = key_states_5 * cos_5
        cos_5 = None
        x1_5 = key_states_5[(Ellipsis, slice(None, 64, None))]
        x2_5 = key_states_5[(Ellipsis, slice(64, None, None))]
        key_states_5 = None
        neg_5 = -x2_5
        x2_5 = None
        cat_5 = torch.cat((neg_5, x1_5), dim=-1)
        neg_5 = x1_5 = None
        mul_13 = cat_5 * sin_5
        cat_5 = sin_5 = None
        k_embed_2 = mul_12 + mul_13
        mul_12 = mul_13 = None
        attn_output_8 = torch._C._nn.scaled_dot_product_attention(
            q_embed_2, k_embed_2, value_states_5, causal_4d_mask, dropout_p=0.0
        )
        q_embed_2 = k_embed_2 = value_states_5 = None
        transpose_11 = attn_output_8.transpose(1, 2)
        attn_output_8 = None
        attn_output_9 = transpose_11.contiguous()
        transpose_11 = None
        attn_output_10 = attn_output_9.reshape(1, 30, 1024)
        attn_output_9 = None
        attn_output_11 = torch._C._nn.linear(
            attn_output_10,
            l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_10 = l_self_modules_model_modules_layers_modules_2_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_10 = hidden_states_9 + attn_output_11
        hidden_states_9 = attn_output_11 = None
        hidden_states_11 = torch.nn.functional.layer_norm(
            hidden_states_10,
            (1024,),
            l_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_10 = l_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_2_modules_norm1_parameters_bias_
        ) = None
        linear_19 = torch._C._nn.linear(
            hidden_states_11,
            l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_2 = torch.nn.functional.silu(linear_19, inplace=False)
        linear_19 = None
        linear_20 = torch._C._nn.linear(
            hidden_states_11,
            l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_14 = silu_2 * linear_20
        silu_2 = linear_20 = None
        hidden_states_12 = torch._C._nn.linear(
            mul_14,
            l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_14 = l_self_modules_model_modules_layers_modules_2_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_13 = hidden_states_11 + hidden_states_12
        hidden_states_11 = hidden_states_12 = None
        hidden_states_14 = torch.nn.functional.layer_norm(
            hidden_states_13,
            (1024,),
            l_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_13 = l_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_2_modules_norm2_parameters_bias_
        ) = None
        query_states_6 = torch._C._nn.linear(
            hidden_states_14,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_6 = torch._C._nn.linear(
            hidden_states_14,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_6 = torch._C._nn.linear(
            hidden_states_14,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_11 = query_states_6.view(1, 30, 8, 128)
        query_states_6 = None
        query_states_7 = view_11.transpose(1, 2)
        view_11 = None
        view_12 = key_states_6.view(1, 30, 8, 128)
        key_states_6 = None
        key_states_7 = view_12.transpose(1, 2)
        view_12 = None
        view_13 = value_states_6.view(1, 30, 8, 128)
        value_states_6 = None
        value_states_7 = view_13.transpose(1, 2)
        view_13 = None
        getitem_25 = l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_6 = getitem_25.to(dtype=torch.float32)
        getitem_25 = None
        getitem_26 = l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_6 = getitem_26.to(dtype=torch.float32)
        getitem_26 = None
        getitem_27 = cos_6[position_ids_1]
        cos_6 = None
        cos_7 = getitem_27.unsqueeze(1)
        getitem_27 = None
        getitem_28 = sin_6[position_ids_1]
        sin_6 = None
        sin_7 = getitem_28.unsqueeze(1)
        getitem_28 = None
        mul_15 = query_states_7 * cos_7
        x1_6 = query_states_7[(Ellipsis, slice(None, 64, None))]
        x2_6 = query_states_7[(Ellipsis, slice(64, None, None))]
        query_states_7 = None
        neg_6 = -x2_6
        x2_6 = None
        cat_6 = torch.cat((neg_6, x1_6), dim=-1)
        neg_6 = x1_6 = None
        mul_16 = cat_6 * sin_7
        cat_6 = None
        q_embed_3 = mul_15 + mul_16
        mul_15 = mul_16 = None
        mul_17 = key_states_7 * cos_7
        cos_7 = None
        x1_7 = key_states_7[(Ellipsis, slice(None, 64, None))]
        x2_7 = key_states_7[(Ellipsis, slice(64, None, None))]
        key_states_7 = None
        neg_7 = -x2_7
        x2_7 = None
        cat_7 = torch.cat((neg_7, x1_7), dim=-1)
        neg_7 = x1_7 = None
        mul_18 = cat_7 * sin_7
        cat_7 = sin_7 = None
        k_embed_3 = mul_17 + mul_18
        mul_17 = mul_18 = None
        attn_output_12 = torch._C._nn.scaled_dot_product_attention(
            q_embed_3, k_embed_3, value_states_7, causal_4d_mask, dropout_p=0.0
        )
        q_embed_3 = k_embed_3 = value_states_7 = None
        transpose_15 = attn_output_12.transpose(1, 2)
        attn_output_12 = None
        attn_output_13 = transpose_15.contiguous()
        transpose_15 = None
        attn_output_14 = attn_output_13.reshape(1, 30, 1024)
        attn_output_13 = None
        attn_output_15 = torch._C._nn.linear(
            attn_output_14,
            l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_14 = l_self_modules_model_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_15 = hidden_states_14 + attn_output_15
        hidden_states_14 = attn_output_15 = None
        hidden_states_16 = torch.nn.functional.layer_norm(
            hidden_states_15,
            (1024,),
            l_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_15 = l_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_3_modules_norm1_parameters_bias_
        ) = None
        linear_26 = torch._C._nn.linear(
            hidden_states_16,
            l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_3 = torch.nn.functional.silu(linear_26, inplace=False)
        linear_26 = None
        linear_27 = torch._C._nn.linear(
            hidden_states_16,
            l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_19 = silu_3 * linear_27
        silu_3 = linear_27 = None
        hidden_states_17 = torch._C._nn.linear(
            mul_19,
            l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_19 = l_self_modules_model_modules_layers_modules_3_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_18 = hidden_states_16 + hidden_states_17
        hidden_states_16 = hidden_states_17 = None
        hidden_states_19 = torch.nn.functional.layer_norm(
            hidden_states_18,
            (1024,),
            l_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_18 = l_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_3_modules_norm2_parameters_bias_
        ) = None
        query_states_8 = torch._C._nn.linear(
            hidden_states_19,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_8 = torch._C._nn.linear(
            hidden_states_19,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_8 = torch._C._nn.linear(
            hidden_states_19,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_14 = query_states_8.view(1, 30, 8, 128)
        query_states_8 = None
        query_states_9 = view_14.transpose(1, 2)
        view_14 = None
        view_15 = key_states_8.view(1, 30, 8, 128)
        key_states_8 = None
        key_states_9 = view_15.transpose(1, 2)
        view_15 = None
        view_16 = value_states_8.view(1, 30, 8, 128)
        value_states_8 = None
        value_states_9 = view_16.transpose(1, 2)
        view_16 = None
        getitem_33 = l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_8 = getitem_33.to(dtype=torch.float32)
        getitem_33 = None
        getitem_34 = l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_8 = getitem_34.to(dtype=torch.float32)
        getitem_34 = None
        getitem_35 = cos_8[position_ids_1]
        cos_8 = None
        cos_9 = getitem_35.unsqueeze(1)
        getitem_35 = None
        getitem_36 = sin_8[position_ids_1]
        sin_8 = None
        sin_9 = getitem_36.unsqueeze(1)
        getitem_36 = None
        mul_20 = query_states_9 * cos_9
        x1_8 = query_states_9[(Ellipsis, slice(None, 64, None))]
        x2_8 = query_states_9[(Ellipsis, slice(64, None, None))]
        query_states_9 = None
        neg_8 = -x2_8
        x2_8 = None
        cat_8 = torch.cat((neg_8, x1_8), dim=-1)
        neg_8 = x1_8 = None
        mul_21 = cat_8 * sin_9
        cat_8 = None
        q_embed_4 = mul_20 + mul_21
        mul_20 = mul_21 = None
        mul_22 = key_states_9 * cos_9
        cos_9 = None
        x1_9 = key_states_9[(Ellipsis, slice(None, 64, None))]
        x2_9 = key_states_9[(Ellipsis, slice(64, None, None))]
        key_states_9 = None
        neg_9 = -x2_9
        x2_9 = None
        cat_9 = torch.cat((neg_9, x1_9), dim=-1)
        neg_9 = x1_9 = None
        mul_23 = cat_9 * sin_9
        cat_9 = sin_9 = None
        k_embed_4 = mul_22 + mul_23
        mul_22 = mul_23 = None
        attn_output_16 = torch._C._nn.scaled_dot_product_attention(
            q_embed_4, k_embed_4, value_states_9, causal_4d_mask, dropout_p=0.0
        )
        q_embed_4 = k_embed_4 = value_states_9 = None
        transpose_19 = attn_output_16.transpose(1, 2)
        attn_output_16 = None
        attn_output_17 = transpose_19.contiguous()
        transpose_19 = None
        attn_output_18 = attn_output_17.reshape(1, 30, 1024)
        attn_output_17 = None
        attn_output_19 = torch._C._nn.linear(
            attn_output_18,
            l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_18 = l_self_modules_model_modules_layers_modules_4_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_20 = hidden_states_19 + attn_output_19
        hidden_states_19 = attn_output_19 = None
        hidden_states_21 = torch.nn.functional.layer_norm(
            hidden_states_20,
            (1024,),
            l_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_20 = l_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_4_modules_norm1_parameters_bias_
        ) = None
        linear_33 = torch._C._nn.linear(
            hidden_states_21,
            l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_4 = torch.nn.functional.silu(linear_33, inplace=False)
        linear_33 = None
        linear_34 = torch._C._nn.linear(
            hidden_states_21,
            l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_24 = silu_4 * linear_34
        silu_4 = linear_34 = None
        hidden_states_22 = torch._C._nn.linear(
            mul_24,
            l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_24 = l_self_modules_model_modules_layers_modules_4_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_23 = hidden_states_21 + hidden_states_22
        hidden_states_21 = hidden_states_22 = None
        hidden_states_24 = torch.nn.functional.layer_norm(
            hidden_states_23,
            (1024,),
            l_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_23 = l_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_4_modules_norm2_parameters_bias_
        ) = None
        query_states_10 = torch._C._nn.linear(
            hidden_states_24,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_10 = torch._C._nn.linear(
            hidden_states_24,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_10 = torch._C._nn.linear(
            hidden_states_24,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_17 = query_states_10.view(1, 30, 8, 128)
        query_states_10 = None
        query_states_11 = view_17.transpose(1, 2)
        view_17 = None
        view_18 = key_states_10.view(1, 30, 8, 128)
        key_states_10 = None
        key_states_11 = view_18.transpose(1, 2)
        view_18 = None
        view_19 = value_states_10.view(1, 30, 8, 128)
        value_states_10 = None
        value_states_11 = view_19.transpose(1, 2)
        view_19 = None
        getitem_41 = l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_10 = getitem_41.to(dtype=torch.float32)
        getitem_41 = None
        getitem_42 = l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_10 = getitem_42.to(dtype=torch.float32)
        getitem_42 = None
        getitem_43 = cos_10[position_ids_1]
        cos_10 = None
        cos_11 = getitem_43.unsqueeze(1)
        getitem_43 = None
        getitem_44 = sin_10[position_ids_1]
        sin_10 = None
        sin_11 = getitem_44.unsqueeze(1)
        getitem_44 = None
        mul_25 = query_states_11 * cos_11
        x1_10 = query_states_11[(Ellipsis, slice(None, 64, None))]
        x2_10 = query_states_11[(Ellipsis, slice(64, None, None))]
        query_states_11 = None
        neg_10 = -x2_10
        x2_10 = None
        cat_10 = torch.cat((neg_10, x1_10), dim=-1)
        neg_10 = x1_10 = None
        mul_26 = cat_10 * sin_11
        cat_10 = None
        q_embed_5 = mul_25 + mul_26
        mul_25 = mul_26 = None
        mul_27 = key_states_11 * cos_11
        cos_11 = None
        x1_11 = key_states_11[(Ellipsis, slice(None, 64, None))]
        x2_11 = key_states_11[(Ellipsis, slice(64, None, None))]
        key_states_11 = None
        neg_11 = -x2_11
        x2_11 = None
        cat_11 = torch.cat((neg_11, x1_11), dim=-1)
        neg_11 = x1_11 = None
        mul_28 = cat_11 * sin_11
        cat_11 = sin_11 = None
        k_embed_5 = mul_27 + mul_28
        mul_27 = mul_28 = None
        attn_output_20 = torch._C._nn.scaled_dot_product_attention(
            q_embed_5, k_embed_5, value_states_11, causal_4d_mask, dropout_p=0.0
        )
        q_embed_5 = k_embed_5 = value_states_11 = None
        transpose_23 = attn_output_20.transpose(1, 2)
        attn_output_20 = None
        attn_output_21 = transpose_23.contiguous()
        transpose_23 = None
        attn_output_22 = attn_output_21.reshape(1, 30, 1024)
        attn_output_21 = None
        attn_output_23 = torch._C._nn.linear(
            attn_output_22,
            l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_22 = l_self_modules_model_modules_layers_modules_5_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_25 = hidden_states_24 + attn_output_23
        hidden_states_24 = attn_output_23 = None
        hidden_states_26 = torch.nn.functional.layer_norm(
            hidden_states_25,
            (1024,),
            l_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_25 = l_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_5_modules_norm1_parameters_bias_
        ) = None
        linear_40 = torch._C._nn.linear(
            hidden_states_26,
            l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_5 = torch.nn.functional.silu(linear_40, inplace=False)
        linear_40 = None
        linear_41 = torch._C._nn.linear(
            hidden_states_26,
            l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_29 = silu_5 * linear_41
        silu_5 = linear_41 = None
        hidden_states_27 = torch._C._nn.linear(
            mul_29,
            l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_29 = l_self_modules_model_modules_layers_modules_5_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_28 = hidden_states_26 + hidden_states_27
        hidden_states_26 = hidden_states_27 = None
        hidden_states_29 = torch.nn.functional.layer_norm(
            hidden_states_28,
            (1024,),
            l_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_28 = l_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_5_modules_norm2_parameters_bias_
        ) = None
        query_states_12 = torch._C._nn.linear(
            hidden_states_29,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_12 = torch._C._nn.linear(
            hidden_states_29,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_12 = torch._C._nn.linear(
            hidden_states_29,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_20 = query_states_12.view(1, 30, 8, 128)
        query_states_12 = None
        query_states_13 = view_20.transpose(1, 2)
        view_20 = None
        view_21 = key_states_12.view(1, 30, 8, 128)
        key_states_12 = None
        key_states_13 = view_21.transpose(1, 2)
        view_21 = None
        view_22 = value_states_12.view(1, 30, 8, 128)
        value_states_12 = None
        value_states_13 = view_22.transpose(1, 2)
        view_22 = None
        getitem_49 = l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_12 = getitem_49.to(dtype=torch.float32)
        getitem_49 = None
        getitem_50 = l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_12 = getitem_50.to(dtype=torch.float32)
        getitem_50 = None
        getitem_51 = cos_12[position_ids_1]
        cos_12 = None
        cos_13 = getitem_51.unsqueeze(1)
        getitem_51 = None
        getitem_52 = sin_12[position_ids_1]
        sin_12 = None
        sin_13 = getitem_52.unsqueeze(1)
        getitem_52 = None
        mul_30 = query_states_13 * cos_13
        x1_12 = query_states_13[(Ellipsis, slice(None, 64, None))]
        x2_12 = query_states_13[(Ellipsis, slice(64, None, None))]
        query_states_13 = None
        neg_12 = -x2_12
        x2_12 = None
        cat_12 = torch.cat((neg_12, x1_12), dim=-1)
        neg_12 = x1_12 = None
        mul_31 = cat_12 * sin_13
        cat_12 = None
        q_embed_6 = mul_30 + mul_31
        mul_30 = mul_31 = None
        mul_32 = key_states_13 * cos_13
        cos_13 = None
        x1_13 = key_states_13[(Ellipsis, slice(None, 64, None))]
        x2_13 = key_states_13[(Ellipsis, slice(64, None, None))]
        key_states_13 = None
        neg_13 = -x2_13
        x2_13 = None
        cat_13 = torch.cat((neg_13, x1_13), dim=-1)
        neg_13 = x1_13 = None
        mul_33 = cat_13 * sin_13
        cat_13 = sin_13 = None
        k_embed_6 = mul_32 + mul_33
        mul_32 = mul_33 = None
        attn_output_24 = torch._C._nn.scaled_dot_product_attention(
            q_embed_6, k_embed_6, value_states_13, causal_4d_mask, dropout_p=0.0
        )
        q_embed_6 = k_embed_6 = value_states_13 = None
        transpose_27 = attn_output_24.transpose(1, 2)
        attn_output_24 = None
        attn_output_25 = transpose_27.contiguous()
        transpose_27 = None
        attn_output_26 = attn_output_25.reshape(1, 30, 1024)
        attn_output_25 = None
        attn_output_27 = torch._C._nn.linear(
            attn_output_26,
            l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_26 = l_self_modules_model_modules_layers_modules_6_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_30 = hidden_states_29 + attn_output_27
        hidden_states_29 = attn_output_27 = None
        hidden_states_31 = torch.nn.functional.layer_norm(
            hidden_states_30,
            (1024,),
            l_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_30 = l_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_6_modules_norm1_parameters_bias_
        ) = None
        linear_47 = torch._C._nn.linear(
            hidden_states_31,
            l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_6 = torch.nn.functional.silu(linear_47, inplace=False)
        linear_47 = None
        linear_48 = torch._C._nn.linear(
            hidden_states_31,
            l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_34 = silu_6 * linear_48
        silu_6 = linear_48 = None
        hidden_states_32 = torch._C._nn.linear(
            mul_34,
            l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_34 = l_self_modules_model_modules_layers_modules_6_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_33 = hidden_states_31 + hidden_states_32
        hidden_states_31 = hidden_states_32 = None
        hidden_states_34 = torch.nn.functional.layer_norm(
            hidden_states_33,
            (1024,),
            l_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_33 = l_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_6_modules_norm2_parameters_bias_
        ) = None
        query_states_14 = torch._C._nn.linear(
            hidden_states_34,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_q_proj_parameters_bias_ = (None)
        key_states_14 = torch._C._nn.linear(
            hidden_states_34,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_k_proj_parameters_bias_ = (None)
        value_states_14 = torch._C._nn.linear(
            hidden_states_34,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_,
        )
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_weight_ = l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_v_proj_parameters_bias_ = (None)
        view_23 = query_states_14.view(1, 30, 8, 128)
        query_states_14 = None
        query_states_15 = view_23.transpose(1, 2)
        view_23 = None
        view_24 = key_states_14.view(1, 30, 8, 128)
        key_states_14 = None
        key_states_15 = view_24.transpose(1, 2)
        view_24 = None
        view_25 = value_states_14.view(1, 30, 8, 128)
        value_states_14 = None
        value_states_15 = view_25.transpose(1, 2)
        view_25 = None
        getitem_57 = l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_cos_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_cos_cached_ = (
            None
        )
        cos_14 = getitem_57.to(dtype=torch.float32)
        getitem_57 = None
        getitem_58 = l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_sin_cached_[
            slice(None, 30, None)
        ]
        l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_rotary_emb_buffers_sin_cached_ = (
            None
        )
        sin_14 = getitem_58.to(dtype=torch.float32)
        getitem_58 = None
        getitem_59 = cos_14[position_ids_1]
        cos_14 = None
        cos_15 = getitem_59.unsqueeze(1)
        getitem_59 = None
        getitem_60 = sin_14[position_ids_1]
        sin_14 = position_ids_1 = None
        sin_15 = getitem_60.unsqueeze(1)
        getitem_60 = None
        mul_35 = query_states_15 * cos_15
        x1_14 = query_states_15[(Ellipsis, slice(None, 64, None))]
        x2_14 = query_states_15[(Ellipsis, slice(64, None, None))]
        query_states_15 = None
        neg_14 = -x2_14
        x2_14 = None
        cat_14 = torch.cat((neg_14, x1_14), dim=-1)
        neg_14 = x1_14 = None
        mul_36 = cat_14 * sin_15
        cat_14 = None
        q_embed_7 = mul_35 + mul_36
        mul_35 = mul_36 = None
        mul_37 = key_states_15 * cos_15
        cos_15 = None
        x1_15 = key_states_15[(Ellipsis, slice(None, 64, None))]
        x2_15 = key_states_15[(Ellipsis, slice(64, None, None))]
        key_states_15 = None
        neg_15 = -x2_15
        x2_15 = None
        cat_15 = torch.cat((neg_15, x1_15), dim=-1)
        neg_15 = x1_15 = None
        mul_38 = cat_15 * sin_15
        cat_15 = sin_15 = None
        k_embed_7 = mul_37 + mul_38
        mul_37 = mul_38 = None
        attn_output_28 = torch._C._nn.scaled_dot_product_attention(
            q_embed_7, k_embed_7, value_states_15, causal_4d_mask, dropout_p=0.0
        )
        q_embed_7 = k_embed_7 = value_states_15 = causal_4d_mask = None
        transpose_31 = attn_output_28.transpose(1, 2)
        attn_output_28 = None
        attn_output_29 = transpose_31.contiguous()
        transpose_31 = None
        attn_output_30 = attn_output_29.reshape(1, 30, 1024)
        attn_output_29 = None
        attn_output_31 = torch._C._nn.linear(
            attn_output_30,
            l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_o_proj_parameters_weight_,
            None,
        )
        attn_output_30 = l_self_modules_model_modules_layers_modules_7_modules_self_attn_modules_o_proj_parameters_weight_ = (None)
        hidden_states_35 = hidden_states_34 + attn_output_31
        hidden_states_34 = attn_output_31 = None
        hidden_states_36 = torch.nn.functional.layer_norm(
            hidden_states_35,
            (1024,),
            l_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_weight_,
            l_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_bias_,
            1e-05,
        )
        hidden_states_35 = l_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_7_modules_norm1_parameters_bias_
        ) = None
        linear_54 = torch._C._nn.linear(
            hidden_states_36,
            l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_gate_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_gate_proj_parameters_weight_ = (
            None
        )
        silu_7 = torch.nn.functional.silu(linear_54, inplace=False)
        linear_54 = None
        linear_55 = torch._C._nn.linear(
            hidden_states_36,
            l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_up_proj_parameters_weight_,
            None,
        )
        l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_up_proj_parameters_weight_ = (
            None
        )
        mul_39 = silu_7 * linear_55
        silu_7 = linear_55 = None
        hidden_states_37 = torch._C._nn.linear(
            mul_39,
            l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_down_proj_parameters_weight_,
            None,
        )
        mul_39 = l_self_modules_model_modules_layers_modules_7_modules_ffn_layer_modules_down_proj_parameters_weight_ = (None)
        hidden_states_38 = hidden_states_36 + hidden_states_37
        hidden_states_36 = hidden_states_37 = None
        hidden_states_39 = torch.nn.functional.layer_norm(
            hidden_states_38,
            (1024,),
            l_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_weight_,
            l_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_bias_,
            1e-05,
        )
        hidden_states_38 = l_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_weight_ = (
            l_self_modules_model_modules_layers_modules_7_modules_norm2_parameters_bias_
        ) = None
        hidden_states_40 = torch.nn.functional.layer_norm(
            hidden_states_39,
            (1024,),
            l_self_modules_model_modules_norm_parameters_weight_,
            l_self_modules_model_modules_norm_parameters_bias_,
            1e-05,
        )
        hidden_states_39 = (
            l_self_modules_model_modules_norm_parameters_weight_
        ) = l_self_modules_model_modules_norm_parameters_bias_ = None
        linear_57 = torch._C._nn.linear(
            hidden_states_40, l_self_modules_lm_heads_modules_0_parameters_weight_, None
        )
        hidden_states_40 = l_self_modules_lm_heads_modules_0_parameters_weight_ = None
        predictions = linear_57[(slice(None, None, None), -1, slice(None, None, None))]
        linear_57 = None
        return (predictions,)
